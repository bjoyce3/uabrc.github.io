{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to UAB Research Computing Docs \u00b6 UAB Research Computing (RC) is a group of IT and data scientists dedicated technical support for researchers at UAB, specifically related to cloud and cluster computing. The main resources run by UAB RC are the Cheaha cluster computing platform and UAB Cloud (coming soon!). Both of these resources are freely available to use by any researcher or instructor at UAB. Contact Us \u00b6 To create a support ticket please reach out to us via email at support@listserv.uab.edu. You can also visit us in our Zoom office hours held weekly: Mondays 10:00 AM to 12:00 PM: Zoom Thursdays 10:00 AM to 12:00 PM: Zoom For additional information about support please see Support","title":"Home"},{"location":"#welcome-to-uab-research-computing-docs","text":"UAB Research Computing (RC) is a group of IT and data scientists dedicated technical support for researchers at UAB, specifically related to cloud and cluster computing. The main resources run by UAB RC are the Cheaha cluster computing platform and UAB Cloud (coming soon!). Both of these resources are freely available to use by any researcher or instructor at UAB.","title":"Welcome to UAB Research Computing Docs"},{"location":"#contact-us","text":"To create a support ticket please reach out to us via email at support@listserv.uab.edu. You can also visit us in our Zoom office hours held weekly: Mondays 10:00 AM to 12:00 PM: Zoom Thursdays 10:00 AM to 12:00 PM: Zoom For additional information about support please see Support","title":"Contact Us"},{"location":"account_management/gitlab_user/","text":"UAB GitLab Overview and Registration \u00b6 Welcome to UAB GitLab! This is a UAB-specific GitLab . GitLab is similar to GitHub , but hosted here at UAB on secure servers. GitLab Use Cases \u00b6 For Researchers \u00b6 GitLab can be used: For reproducibility Analysis and software code can be kept in one, central repository everyone can use instead of spread across multiple computers/places. Code can be versioned and tracked as it changes over time. Software versions can be recorded, virtual environments can be documented, and containers can be recorded to help future-proof analyses. Collaboration GitLab is a central place to create code, edit, and track needed code changes (issues) with your lab and collaborators. Multiple people can use, modify, and merge changes in code while communicating with the broader team all along the way. Security Unlimited private repositories for internal code projects. Set behind UAB authentication. For Software Developers (and Researchers!) \u00b6 UAB GitLab is useful for software developers. It is a single application for the entire software development lifecycle. From project planning and source code management to continuous integration (CI) and continuous deployment (CD), monitoring, and security. Our GitLab instance may be found at https://gitlab.rc.uab.edu . UAB GitLab Registration \u00b6 UAB-Affiliated Researcher Registration \u00b6 If you are a UAB affiliated researcher and have a BlazerId, you may create an account by logging in at the site above using the ldap tab. Please use your single sign-on (SSO) credentials. Please use BlazerID and password instead of UABMC credentials Please use your BlazerID and BlazerID password for UAB GitLab. UABMC credentials are a different sign in system and will likely not work. Central IT groups like Research Computing do not have a way to access UABMC credentials. UABMC Researcher Registration \u00b6 Please use your BlazerID and BlazerID credentials to sign in following the directions for UAB-Affiliated Researchers. UABMC credentials should not be used for UAB GitLab. XIAS External Collaborator Registration \u00b6 If you are a collaborator with a XIAS account you'll need to follow a different procedure. Ensure that your sponsor has included https://gitlab.rc.uab.edu in the list of approved URIs on the XIAS configuration page. Email support@listserv.uab.edu providing your full name, XIAS account email address, and sponsor. UAB Research Computing will create the account. You will recieve an email from gitlab.rc.uab.edu with a link to create a password. Navigate to https://gitlab.rc.uab.edu . Click the Standard tab. In the Username or email field type the part of your XIAS email address before the @ symbol. Do not include the @ symbol or anything after it. Fill out the Password field with the GitLab password you created in Step #4. Click Sign in . Warning XIAS account researchers can only be granted access if their sponsor adds the GitLab URL to the list of approved URIs. Please see XIAS Sites for more information.","title":"UAB GitLab Overview and Registration"},{"location":"account_management/gitlab_user/#uab-gitlab-overview-and-registration","text":"Welcome to UAB GitLab! This is a UAB-specific GitLab . GitLab is similar to GitHub , but hosted here at UAB on secure servers.","title":"UAB GitLab Overview and Registration"},{"location":"account_management/gitlab_user/#gitlab-use-cases","text":"","title":"GitLab Use Cases"},{"location":"account_management/gitlab_user/#for-researchers","text":"GitLab can be used: For reproducibility Analysis and software code can be kept in one, central repository everyone can use instead of spread across multiple computers/places. Code can be versioned and tracked as it changes over time. Software versions can be recorded, virtual environments can be documented, and containers can be recorded to help future-proof analyses. Collaboration GitLab is a central place to create code, edit, and track needed code changes (issues) with your lab and collaborators. Multiple people can use, modify, and merge changes in code while communicating with the broader team all along the way. Security Unlimited private repositories for internal code projects. Set behind UAB authentication.","title":"For Researchers"},{"location":"account_management/gitlab_user/#for-software-developers-and-researchers","text":"UAB GitLab is useful for software developers. It is a single application for the entire software development lifecycle. From project planning and source code management to continuous integration (CI) and continuous deployment (CD), monitoring, and security. Our GitLab instance may be found at https://gitlab.rc.uab.edu .","title":"For Software Developers (and Researchers!)"},{"location":"account_management/gitlab_user/#uab-gitlab-registration","text":"","title":"UAB GitLab Registration"},{"location":"account_management/gitlab_user/#uab-affiliated-researcher-registration","text":"If you are a UAB affiliated researcher and have a BlazerId, you may create an account by logging in at the site above using the ldap tab. Please use your single sign-on (SSO) credentials. Please use BlazerID and password instead of UABMC credentials Please use your BlazerID and BlazerID password for UAB GitLab. UABMC credentials are a different sign in system and will likely not work. Central IT groups like Research Computing do not have a way to access UABMC credentials.","title":"UAB-Affiliated Researcher Registration"},{"location":"account_management/gitlab_user/#uabmc-researcher-registration","text":"Please use your BlazerID and BlazerID credentials to sign in following the directions for UAB-Affiliated Researchers. UABMC credentials should not be used for UAB GitLab.","title":"UABMC Researcher Registration"},{"location":"account_management/gitlab_user/#xias-external-collaborator-registration","text":"If you are a collaborator with a XIAS account you'll need to follow a different procedure. Ensure that your sponsor has included https://gitlab.rc.uab.edu in the list of approved URIs on the XIAS configuration page. Email support@listserv.uab.edu providing your full name, XIAS account email address, and sponsor. UAB Research Computing will create the account. You will recieve an email from gitlab.rc.uab.edu with a link to create a password. Navigate to https://gitlab.rc.uab.edu . Click the Standard tab. In the Username or email field type the part of your XIAS email address before the @ symbol. Do not include the @ symbol or anything after it. Fill out the Password field with the GitLab password you created in Step #4. Click Sign in . Warning XIAS account researchers can only be granted access if their sponsor adds the GitLab URL to the list of approved URIs. Please see XIAS Sites for more information.","title":"XIAS External Collaborator Registration"},{"location":"account_management/uab_user/","text":"UAB User Instructions \u00b6 These instructions are for users at UAB to request their own accounts on Cheaha using the Open OnDemand web portal. Navigate to https://rc.uab.edu , authenticate with your UAB credentials, and if you do not have a Cheaha account, you will see the page shown below: Your BlazerID and full name will already be filled in based on your authentication credentials. Please fill out a reason for needing a Cheaha account and press Create Account . Your account should be created and ready to use. UABMC Emails \u00b6 Cheaha does not support use of uabmc emails and identities for login credentials. In order to use Cheaha, you will need either a Blazer ID or access through XIAS .","title":"UAB User Instructions"},{"location":"account_management/uab_user/#uab-user-instructions","text":"These instructions are for users at UAB to request their own accounts on Cheaha using the Open OnDemand web portal. Navigate to https://rc.uab.edu , authenticate with your UAB credentials, and if you do not have a Cheaha account, you will see the page shown below: Your BlazerID and full name will already be filled in based on your authentication credentials. Please fill out a reason for needing a Cheaha account and press Create Account . Your account should be created and ready to use.","title":"UAB User Instructions"},{"location":"account_management/uab_user/#uabmc-emails","text":"Cheaha does not support use of uabmc emails and identities for login credentials. In order to use Cheaha, you will need either a Blazer ID or access through XIAS .","title":"UABMC Emails"},{"location":"account_management/xias_guest/","text":"Guest Instructions \u00b6 These instructions are for guests who have been registered by UAB faculty and staff to use internal UAB resources. Once a request for a XIAS account has been made by your UAB sponsor, you will need to follow these instructions to complete the XIAS registration and obtain access to UAB resources. All of the links used on this page are available at the UAB XIAS Guest Users page. Create Account \u00b6 The first email you receive should be a notification that a request has been made to add you as a XIAS user. This email will include the project(s)/site(s) you're being added to. The next email you receive should contain instructions on how to register your account. This email may take an hour or so to arrive after the first. It will contain an invite code that you must enter at the XIAS website, along with the email address used to register you. Navigate to the link in the email. Please practice good internet hygiene and copy the link text, instead of clicking the link! As of the time of writing the link will be to the UAB XIAS Guest Users page. Once at the main page, click the \"Enter Invite or Reset Code\" link. You will be taken to the \"Register XIAS Account\" page. Enter the email address used to register you for a XIAS account, and the code from the email you received with registration instructions. Then click proceed. Enter your first and last names, then click proceed. Enter a password that will be used with your XIAS account. This password can be changed later, and your account can be recovered if the password is lost. Click proceed. You will be taken to a confirmation page. If everything is acceptable, click proceed. Otherwise click edit next to the incorrect field. Your XIAS email cannot be changed. If the email is not correct you will need to communicate with your sponsor to start the entire process over from the beginning. You should be taken to a page indicating success. Please carefully read the page and follow any instructions. If you do not see a success page, please contact your sponsor about next steps. Following this step, your account registration is complete and you should be able to access the resources you have been granted permission to use. Most internal UAB systems use a Single Sign-On (SSO) to simplify and standardize logging in. For those sites that don't you will need to activate your account manually. To manually activate accounts for resources that do not use SSO click the \"Activate (Sync) Accounts\" link on the left hand navigation pane. Fill out the form using the email used to register the XIAS account and the current password. Change Password and Recover From Lost Password \u00b6 To change your password, or recover your account in case of a lost password, please click the \"Change XIAS Password\" link in the left hand panel of the main page. Once there, follow the instructions on the form. Resend Invite Code \u00b6 If your invite code has expired, you can have a new invite code sent to you by clicking the \"Resend Invite Code\" link in the left hand panel of the main page. Once there, follow the instructions on the form. Guest IT Info \u00b6 For more information on UAB IT policies and other useful and helpful information, please click the \"UABIT Guest User info\" link.","title":"Guest Instructions"},{"location":"account_management/xias_guest/#guest-instructions","text":"These instructions are for guests who have been registered by UAB faculty and staff to use internal UAB resources. Once a request for a XIAS account has been made by your UAB sponsor, you will need to follow these instructions to complete the XIAS registration and obtain access to UAB resources. All of the links used on this page are available at the UAB XIAS Guest Users page.","title":"Guest Instructions"},{"location":"account_management/xias_guest/#create-account","text":"The first email you receive should be a notification that a request has been made to add you as a XIAS user. This email will include the project(s)/site(s) you're being added to. The next email you receive should contain instructions on how to register your account. This email may take an hour or so to arrive after the first. It will contain an invite code that you must enter at the XIAS website, along with the email address used to register you. Navigate to the link in the email. Please practice good internet hygiene and copy the link text, instead of clicking the link! As of the time of writing the link will be to the UAB XIAS Guest Users page. Once at the main page, click the \"Enter Invite or Reset Code\" link. You will be taken to the \"Register XIAS Account\" page. Enter the email address used to register you for a XIAS account, and the code from the email you received with registration instructions. Then click proceed. Enter your first and last names, then click proceed. Enter a password that will be used with your XIAS account. This password can be changed later, and your account can be recovered if the password is lost. Click proceed. You will be taken to a confirmation page. If everything is acceptable, click proceed. Otherwise click edit next to the incorrect field. Your XIAS email cannot be changed. If the email is not correct you will need to communicate with your sponsor to start the entire process over from the beginning. You should be taken to a page indicating success. Please carefully read the page and follow any instructions. If you do not see a success page, please contact your sponsor about next steps. Following this step, your account registration is complete and you should be able to access the resources you have been granted permission to use. Most internal UAB systems use a Single Sign-On (SSO) to simplify and standardize logging in. For those sites that don't you will need to activate your account manually. To manually activate accounts for resources that do not use SSO click the \"Activate (Sync) Accounts\" link on the left hand navigation pane. Fill out the form using the email used to register the XIAS account and the current password.","title":"Create Account"},{"location":"account_management/xias_guest/#change-password-and-recover-from-lost-password","text":"To change your password, or recover your account in case of a lost password, please click the \"Change XIAS Password\" link in the left hand panel of the main page. Once there, follow the instructions on the form.","title":"Change Password and Recover From Lost Password"},{"location":"account_management/xias_guest/#resend-invite-code","text":"If your invite code has expired, you can have a new invite code sent to you by clicking the \"Resend Invite Code\" link in the left hand panel of the main page. Once there, follow the instructions on the form.","title":"Resend Invite Code"},{"location":"account_management/xias_guest/#guest-it-info","text":"For more information on UAB IT policies and other useful and helpful information, please click the \"UABIT Guest User info\" link.","title":"Guest IT Info"},{"location":"account_management/xias_sites/","text":"Creating a UAB XIAS Project/Site \u00b6 XIAS Project/Sites, or simply sites, tie external users to specific resources at UAB. By connecting people to the resource they use, UAB can maintain security and accountability. Creating a site is the first step to giving access to external collaborators, and the process can be thought of as \"create once, use many times\". All sites must have an expiration date for security reasons. To create a site you'll need at least one Uniform Resource Identifier (URI) relating to resources used by the site. If you aren't sure what URI(s) to list for your site, please contact UserServices@uab.edu . To start go to the UAB XIAS Project/Site Management Webpage . ![!UAB XIAS Project/Site Management Webpage with Manage Projects/Sites selected and a New button available./xias_sites_add_000.png) Click \"New\" to open a form for creating a new Project/Site. Fill in the form. All fields are required. Short name for project/site - A memorable name for your project or site. Longer description - A complete yet concise description of the project or site and its resources. Start date - The start date, can be today. End date - An expiration date for the project or site. URIs - One or more uniform resource locators (URIs) associated with the site, to increase accountability. Click \"Add\" to submit the form. You should be taken to a page summarizing the created Project/Site. When you visit the \"Manage Projects/Sites\" page in the future, you will see a table with the newly created Project/Site listed. Click \"View\" to return to the page seen in the previous step. Click \"Edit\" to return to the form from [link]. Click \"Users\" to manage users for this site.","title":"Creating a UAB XIAS Project/Site"},{"location":"account_management/xias_sites/#creating-a-uab-xias-projectsite","text":"XIAS Project/Sites, or simply sites, tie external users to specific resources at UAB. By connecting people to the resource they use, UAB can maintain security and accountability. Creating a site is the first step to giving access to external collaborators, and the process can be thought of as \"create once, use many times\". All sites must have an expiration date for security reasons. To create a site you'll need at least one Uniform Resource Identifier (URI) relating to resources used by the site. If you aren't sure what URI(s) to list for your site, please contact UserServices@uab.edu . To start go to the UAB XIAS Project/Site Management Webpage . ![!UAB XIAS Project/Site Management Webpage with Manage Projects/Sites selected and a New button available./xias_sites_add_000.png) Click \"New\" to open a form for creating a new Project/Site. Fill in the form. All fields are required. Short name for project/site - A memorable name for your project or site. Longer description - A complete yet concise description of the project or site and its resources. Start date - The start date, can be today. End date - An expiration date for the project or site. URIs - One or more uniform resource locators (URIs) associated with the site, to increase accountability. Click \"Add\" to submit the form. You should be taken to a page summarizing the created Project/Site. When you visit the \"Manage Projects/Sites\" page in the future, you will see a table with the newly created Project/Site listed. Click \"View\" to return to the page seen in the previous step. Click \"Edit\" to return to the form from [link]. Click \"Users\" to manage users for this site.","title":"Creating a UAB XIAS Project/Site"},{"location":"account_management/xias_users/","text":"Managing UAB XIAS Users \u00b6 UAB XIAS User management allow UAB faculty and staff to grant external collaborators access to specific resources on the internal UAB network. All XIAS users must be connected with at least one site, so you'll need to create one at the UAB XIAS User Management Webpage . All XIAS Users must also have an expiration date. Adding Users \u00b6 Before adding users, have a list of user emails handy for the site you wish to add users to, as well as expiration dates for each user. To start go to the UAB XIAS User Management Webpage . Select the Project/Site you wish to add users to from the drop down box. Click \"Register\" to open a form for adding new users. Fill in the form. All fields are required. Checkbox list - Leave the site checked. End date - An expiration date for the users being added. Cannot be longer than the end date for the selected Project/Site. Text box - Enter a list of e-mail addresses for users to add. Click \"Submit\" to move to a confirmation page. Check the emails are correct and click \"Add\" to submit the information Emails will be sent to all email addresses for next steps. You will be redirected to the UAB XIAS User Management Webpage, which should now have the text \"Registration successful.\" near the top. To complete their registration, please direct your external collaborators to the UAB XIAS Guest Users page . When they have completed their registration, you should receive an email like the following. Discovering and Managing Users \u00b6 There are two ways to discover XIAS users you are currently sponsoring. The first is to search by email address. The second is to list all users associated with a site. Discovering Users \u00b6 To locate users by e-mail address: type their email into the \"Locate specific user(s) by e-mail address\" text field on the \"Manage Users\" page. To manage users by site: select the site from the drop-down box and click the \"List\" button. The page will reload with a table containing name, email, and start and end dates. The end date is when the XIAS user registration expires. To change the end date for user(s), click the \"Sel\" checkbox next to their names, enter a date in the \"Change end date for selected users to\" text field, and click \"Update\". Revoking User Privileges \u00b6 Warning THIS INFORMATION IS PENDING TESTING Users cannot have their XIAS account deleted. However, privileges may be revoked. To revoke user privileges, follow the instructions for managing users by site. Update the desired user(s)' end date to a date earlier than the current date. If you need to urgently revoke privileges \u00b6 please also notify UAB IT by emailing AskIT@uab.edu as soon as possible. Please be clear about what is needed and when.","title":"Managing UAB XIAS Users"},{"location":"account_management/xias_users/#managing-uab-xias-users","text":"UAB XIAS User management allow UAB faculty and staff to grant external collaborators access to specific resources on the internal UAB network. All XIAS users must be connected with at least one site, so you'll need to create one at the UAB XIAS User Management Webpage . All XIAS Users must also have an expiration date.","title":"Managing UAB XIAS Users"},{"location":"account_management/xias_users/#adding-users","text":"Before adding users, have a list of user emails handy for the site you wish to add users to, as well as expiration dates for each user. To start go to the UAB XIAS User Management Webpage . Select the Project/Site you wish to add users to from the drop down box. Click \"Register\" to open a form for adding new users. Fill in the form. All fields are required. Checkbox list - Leave the site checked. End date - An expiration date for the users being added. Cannot be longer than the end date for the selected Project/Site. Text box - Enter a list of e-mail addresses for users to add. Click \"Submit\" to move to a confirmation page. Check the emails are correct and click \"Add\" to submit the information Emails will be sent to all email addresses for next steps. You will be redirected to the UAB XIAS User Management Webpage, which should now have the text \"Registration successful.\" near the top. To complete their registration, please direct your external collaborators to the UAB XIAS Guest Users page . When they have completed their registration, you should receive an email like the following.","title":"Adding Users"},{"location":"account_management/xias_users/#discovering-and-managing-users","text":"There are two ways to discover XIAS users you are currently sponsoring. The first is to search by email address. The second is to list all users associated with a site.","title":"Discovering and Managing Users"},{"location":"account_management/xias_users/#discovering-users","text":"To locate users by e-mail address: type their email into the \"Locate specific user(s) by e-mail address\" text field on the \"Manage Users\" page. To manage users by site: select the site from the drop-down box and click the \"List\" button. The page will reload with a table containing name, email, and start and end dates. The end date is when the XIAS user registration expires. To change the end date for user(s), click the \"Sel\" checkbox next to their names, enter a date in the \"Change end date for selected users to\" text field, and click \"Update\".","title":"Discovering Users"},{"location":"account_management/xias_users/#revoking-user-privileges","text":"Warning THIS INFORMATION IS PENDING TESTING Users cannot have their XIAS account deleted. However, privileges may be revoked. To revoke user privileges, follow the instructions for managing users by site. Update the desired user(s)' end date to a date earlier than the current date.","title":"Revoking User Privileges"},{"location":"account_management/xias_users/#if-you-need-to-urgently-revoke-privileges","text":"please also notify UAB IT by emailing AskIT@uab.edu as soon as possible. Please be clear about what is needed and when.","title":"If you need to urgently revoke privileges"},{"location":"cheaha/conda/","text":"Anaconda \u00b6 Python is a high level programming language that is widely used in many branches of science. The scientific python ecosystem is available to researchers as Anaconda modules on Cheaha. Modules for both python 2 and python 3 are installed. In order to see the different versions of each, use: module spider Anaconda Loading Anaconda \u00b6 When planning a project, you should have an idea of which python version you need to use. Python 3 is the current standard and is used by the Anaconda3 modules. After loading one of the modules, use python --version to check the version number. To see all of the Anaconda versions installed on Cheaha, use the command module spider Anaconda . Specific versions of Python can be installed in virtual environments regardless of the version of Python in the Anaconda module. Libraries and Virtual Environments \u00b6 Anaconda virtual environments are self-contained environments with necessary packages for specific projects. It is recommended to have a separate environment for each project you have. This solves cases where different projects have dependencies on different versions of the same package. New virtual environments include a few very common libraries such as scikit-learn, pandas, numpy, and scipy by default. However, most projects will need to install some external libraries as well using pip or conda . Here, we will go through instructions for creating and managing Anaconda environments including installing new libraries. More complete information on this process can be found at the Anaconda documentation . Create an Environment \u00b6 In order to create a basic environment with the default packages, use the conda create command: # create a base environment. Replace <env> with an environment name conda create -n <env> If you are trying to replicate a pipeline or analysis from another person, you can also recreate an environment using a YAML file, if they have provided one. To replicate an environment using a YAML file, use: # replicate an environment from a YAML file named env.yml conda create -n <env> -f <path/to/env.yml> By default, all of your conda environments are stored in /home/<user>/.conda/envs . Activate an Environment \u00b6 From here, you can activate the environment using either source or conda : # activate the virtual environment using source source activate <env> # or using conda conda activate <env> To know your environment has loaded, the command line should look like: (<env>) [blazerid@c0XXX ~]$ Once the environment is activated, you are allowed to install whichever python libraries you need for your analysis. Install Libraries \u00b6 The base package manager for python is pip . The basic way to use pip is (replace \\<package> with the package name, omitting \\<>): # install most recent version of a package pip install \\< package \\> # install a specific version pip install \\< package \\> == version # install a list of pacakges from a text file pip install -r packages.txt pip searches various package indexes like PyPi or local project directories. If the package you need isn't found there, it may be available in an online Anaconda channel (same as index). To install from there, use the conda install command. # install most recent version of a package conda install \\< package \\> # install a specific version conda install \\< package \\> = version # install from a specific conda channel conda install -c \\< channel \\> \\< package \\> Generally, if a package needs to be downloaded from a specific conda channel, it will mention that in its installation instructions. Running Command-Line Python \u00b6 Python code can be run an individual commands from the command line. In order to access a python terminal, use the python or python3 command in the terminal window. The prompt will be replaced with >>> . Execute any commands here. exit() will return you to the normal command line. Executing scripts is the more common use case than executing individual commands interactively. To execute a script from the command line: python \\< script.py \\> Any optional inputs the script has can be listed after the name of the script. Note When Anaconda3 is loaded in your environment, the python and python3 commands both refer to Python version 3.X.X (whatever minor version is loaded). However, when Anaconda3 is not loaded, python will refer to the base Python 2.7.5 instead. Be sure to load Anaconda3 before running python , or always use python3 for disambiguation. Deactivating an Environment \u00b6 An environment can be deactivated using either source or conda : # Using source source deactivate # Using conda conda deactivate Anaconda may say that using source deactivate is deprecated, but environment will still be deactivated. Closing the terminal will also close out the environment. Exporting an Environment \u00b6 To easily share environments with other researchers or replicate it on a new machine, it is useful to create an environment YAML file. You can do this using: # activate the environment if it is not active already conda activate \\< env \\> # export the environment to a YAML file conda env export \\> env.yml","title":"Anaconda"},{"location":"cheaha/conda/#anaconda","text":"Python is a high level programming language that is widely used in many branches of science. The scientific python ecosystem is available to researchers as Anaconda modules on Cheaha. Modules for both python 2 and python 3 are installed. In order to see the different versions of each, use: module spider Anaconda","title":"Anaconda"},{"location":"cheaha/conda/#loading-anaconda","text":"When planning a project, you should have an idea of which python version you need to use. Python 3 is the current standard and is used by the Anaconda3 modules. After loading one of the modules, use python --version to check the version number. To see all of the Anaconda versions installed on Cheaha, use the command module spider Anaconda . Specific versions of Python can be installed in virtual environments regardless of the version of Python in the Anaconda module.","title":"Loading Anaconda"},{"location":"cheaha/conda/#libraries-and-virtual-environments","text":"Anaconda virtual environments are self-contained environments with necessary packages for specific projects. It is recommended to have a separate environment for each project you have. This solves cases where different projects have dependencies on different versions of the same package. New virtual environments include a few very common libraries such as scikit-learn, pandas, numpy, and scipy by default. However, most projects will need to install some external libraries as well using pip or conda . Here, we will go through instructions for creating and managing Anaconda environments including installing new libraries. More complete information on this process can be found at the Anaconda documentation .","title":"Libraries and Virtual Environments"},{"location":"cheaha/conda/#create-an-environment","text":"In order to create a basic environment with the default packages, use the conda create command: # create a base environment. Replace <env> with an environment name conda create -n <env> If you are trying to replicate a pipeline or analysis from another person, you can also recreate an environment using a YAML file, if they have provided one. To replicate an environment using a YAML file, use: # replicate an environment from a YAML file named env.yml conda create -n <env> -f <path/to/env.yml> By default, all of your conda environments are stored in /home/<user>/.conda/envs .","title":"Create an Environment"},{"location":"cheaha/conda/#activate-an-environment","text":"From here, you can activate the environment using either source or conda : # activate the virtual environment using source source activate <env> # or using conda conda activate <env> To know your environment has loaded, the command line should look like: (<env>) [blazerid@c0XXX ~]$ Once the environment is activated, you are allowed to install whichever python libraries you need for your analysis.","title":"Activate an Environment"},{"location":"cheaha/conda/#install-libraries","text":"The base package manager for python is pip . The basic way to use pip is (replace \\<package> with the package name, omitting \\<>): # install most recent version of a package pip install \\< package \\> # install a specific version pip install \\< package \\> == version # install a list of pacakges from a text file pip install -r packages.txt pip searches various package indexes like PyPi or local project directories. If the package you need isn't found there, it may be available in an online Anaconda channel (same as index). To install from there, use the conda install command. # install most recent version of a package conda install \\< package \\> # install a specific version conda install \\< package \\> = version # install from a specific conda channel conda install -c \\< channel \\> \\< package \\> Generally, if a package needs to be downloaded from a specific conda channel, it will mention that in its installation instructions.","title":"Install Libraries"},{"location":"cheaha/conda/#running-command-line-python","text":"Python code can be run an individual commands from the command line. In order to access a python terminal, use the python or python3 command in the terminal window. The prompt will be replaced with >>> . Execute any commands here. exit() will return you to the normal command line. Executing scripts is the more common use case than executing individual commands interactively. To execute a script from the command line: python \\< script.py \\> Any optional inputs the script has can be listed after the name of the script. Note When Anaconda3 is loaded in your environment, the python and python3 commands both refer to Python version 3.X.X (whatever minor version is loaded). However, when Anaconda3 is not loaded, python will refer to the base Python 2.7.5 instead. Be sure to load Anaconda3 before running python , or always use python3 for disambiguation.","title":"Running Command-Line Python"},{"location":"cheaha/conda/#deactivating-an-environment","text":"An environment can be deactivated using either source or conda : # Using source source deactivate # Using conda conda deactivate Anaconda may say that using source deactivate is deprecated, but environment will still be deactivated. Closing the terminal will also close out the environment.","title":"Deactivating an Environment"},{"location":"cheaha/conda/#exporting-an-environment","text":"To easily share environments with other researchers or replicate it on a new machine, it is useful to create an environment YAML file. You can do this using: # activate the environment if it is not active already conda activate \\< env \\> # export the environment to a YAML file conda env export \\> env.yml","title":"Exporting an Environment"},{"location":"cheaha/getting_started/","text":"Getting Started \u00b6 Cheaha is a cluster computing environment for UAB researchers. Information about the history and future plans for Cheaha is available on the Cheaha page. Access (Cluster Account Request) \u00b6 To get started using Cheaha , simply visit our Open OnDemand portal at https://rc.uab.edu . This is the primary entry point for Cheaha and provides access to all cluster services directly from your web browser, including graphical desktops, Jupyter Notebooks, and even the traditional command-line. If you don't already have an account, you will be prompted to create one the first time you log into the portal. If you are creating an account, please share some of your interests in using Cheaha as this help us understand the science interests of our users. Please note : Usage of Cheaha is governed by UAB's Acceptable Use Policy (AUP) for computer resources. External Collaborator \u00b6 To request an account for an external collaborator, please follow the steps here. Login \u00b6 Overview \u00b6 Once your account has been created, you'll receive an email containing your user ID, generally your Blazer ID. You can log into Cheaha via your web browser using the new web-based HPC experience. You can also log into Cheaha via a traditional SSH client. Most UAB Windows workstations already have an SSH client installed, possibly named SSH Secure Shell Client or PuTTY . Linux and Mac OS X systems should have an SSH client installed by default. Usage of Cheaha is governed by UAB's Acceptable Use Policy (AUP) for computer and network resources. Client Configuration \u00b6 This section will cover steps to configure Windows, Linux and Mac OS X clients to connect to Cheaha. The official DNS name of Cheaha's frontend machine is cheaha.rc.uab.edu . If you want to refer to the machine as cheaha , you'll have to either add the \"rc.uab.edu\" to you computer's DNS search path. On Unix-derived systems (Linux, Mac) you can edit your computers /etc/resolv.conf as follows (you'll need administrator access to edit this file) search rc.uab.edu Or you can customize your SSH configuration to use the short name \"cheaha\" as a connection name. On systems using OpenSSH you can add the following to your ~/.ssh/config file Host cheaha Hostname cheaha.rc.uab.edu Linux \u00b6 Linux systems, regardless of the flavor (RedHat, SuSE, Ubuntu, etc...), should already have an SSH client on the system as part of the default install. Start a terminal (on RedHat click Applications -> Accessories -> Terminal, on Ubuntu Ctrl+Alt+T) At the prompt, enter the following command to connect to Cheaha ( Replace blazerid with your Cheaha userid ) ssh blazerid@cheaha.rc.uab.edu Mac OS X \u00b6 Mac OS X is a Unix operating system (BSD) and has a built in ssh client. Start a terminal (click Finder, type Terminal and double click on Terminal under the Applications category) At the prompt, enter the following command to connect to Cheaha ( Replace blazerid with your Cheaha userid ) ssh blazerid@cheaha.rc.uab.edu Windows \u00b6 There are many SSH clients available for Windows, some commercial and some that are free (GPL). This section will cover two clients that are commonly found on UAB Windows systems. MobaXterm \u00b6 MobaXterm is a free (also available for a price in a Profession version) suite of SSH tools. Of the Windows clients we've used, MobaXterm is the easiest to use and feature complete. Features include (but not limited to): SSH client (in a handy web browser like tabbed interface) Embedded Cygwin (which allows Windows users to run many Linux commands like grep, rsync, sed) Remote file system browser (graphical SFTP) X11 forwarding for remotely displaying graphical content from Cheaha Installs without requiring Windows Administrator rights Start MobaXterm and click the Session toolbar button (top left). Click SSH for the session type, enter the following information and click OK. Once finished, double click cheaha.rc.uab.edu in the list of Saved sessions under PuTTY sessions: Field Cheaha Settings Remote host cheaha.rc.uab.edu Port 22 PuTTY \u00b6 PuTTY is a free suite of SSH and telnet tools written and maintained by Simon Tatham . PuTTY supports SSH, secure FTP (SFTP), and X forwarding (XTERM) among other tools. Start PuTTY (Click START -> All Programs -> PuTTY -> PuTTY). The 'PuTTY Configuration' window will open Use these settings for each of the clusters that you would like to configure Field Cheaha Settings Host Name (or IP address) cheaha.rc.uab.edu Port 22 Protocol SSH Saved Sessions cheaha.rc.uab.edu Click Save to save the configuration, repeat the previous steps for the other clusters The next time you start PuTTY, simply double click on the cluster name under the 'Saved Sessions' list SSH Secure Shell Client \u00b6 SSH Secure Shell is a commercial application that is installed on many Windows workstations on campus and can be configured as follows: Start the program (Click START -> All Programs -> SSH Secure Shell -> Secure Shell Client). The 'default - SSH Secure Shell' window will open Click File -> Profiles -> Add Profile to open the 'Add Profile' window Type in the name of the cluster (for example: cheaha) in the field and click 'Add to Profiles' Click File -> Profiles -> Edit Profiles to open the 'Profiles' window Single click on your new profile name Use these settings for the clusters Field Cheaha Settings Host name cheaha.rc.uab.edu User name blazerid (insert your blazerid here) Port 22 Protocol SSH Encryption algorithm MAC algorithm Compression Terminal answerback vt100 Leave 'Connect through firewall' and 'Request tunnels only' unchecked Click OK to save the configuration, repeat the previous steps for the other clusters The next time you start SSH Secure Shell, click 'Profiles' and click the cluster name Logging in to Cheaha \u00b6 No matter which client you use to connect to the Cheaha, the first time you connect, the SSH client should display a message asking if you would like to import the hosts public key. Answer Yes to this question. Connect to Cheaha using one of the methods listed above Answer Yes to import the cluster's public key Enter your BlazerID password After successfully logging in for the first time, You may see the following message just press ENTER for the next three prompts, don't type any passphrases! It doesn ' t appear that you have set up your ssh key. This process will make the files: /home/joeuser/.ssh/id_rsa.pub /home/joeuser/.ssh/id_rsa /home/joeuser/.ssh/authorized_keys Generating public/private rsa key pair. Enter file in which to save the key ( /home/joeuser/.ssh/id_rsa ) : Enter file in which to save the key (/home/joeuser/.ssh/id_rsa): Press Enter Enter passphrase (empty for no passphrase): Press Enter Enter same passphrase again: Press Enter Your identification has been saved in /home/joeuser/.ssh/id_rsa. Your public key has been saved in /home/joeuser/.ssh/id_rsa.pub. The key fingerprint is: f6:xx:xx:xx:xx:dd:9a:79:7b:83:xx:f9:d7:a7:d6:27 joeuser@cheaha.rc.uab.edu Users without a blazerid (collaborators from other universities) \u00b6 If you were issued a temporary password, enter it (Passwords are CaSE SensitivE!!!) You should see a message similar to this You are required to change your password immediately ( password aged ) WARNING: Your password has expired. You must change your password now and login again! Changing password for user joeuser. Changing password for joeuser ( current ) UNIX password: (current) UNIX password: Enter your temporary password at this prompt and press enter New UNIX password: Enter your new strong password and press enter Retype new UNIX password: Enter your new strong password again and press enter After you enter your new password for the second time and press enter, the shell may exit automatically. If it doesn't, type exit and press enter Log in again, this time use your new password Congratulations, you should now have a command prompt and be ready to start submitting jobs !!! Hardware \u00b6 See Hardware for more information. Cluster Software \u00b6 BrightCM 7.2 CentOS 7.2 x86_64 Slurm 15.08 Queuing System \u00b6 All work on Cheaha must be submitted to our queuing system ( Slurm ) . A common mistake made by new users is to run 'jobs' on the login node. This section gives a basic overview of what a queuing system is and why we use it. What is a queuing system? \u00b6 Software that gives users fair allocation of the cluster's resources Schedules jobs based using resource requests (the following are commonly requested resources, there are many more that are available) Number of processors (often referred to as \"slots\") Maximum memory (RAM) required per slot Maximum run time Common queuing systems: Slurm Sun Grid Engine (Also know as SGE, OGE, GE) OpenPBS Torque LSF (load sharing facility) Slurm is a queue management system and stands for Simple Linux Utility for Resource Management. Slurm was developed at the Lawrence Livermore National Lab and currently runs some of the largest compute clusters in the world. Slurm is now the primary job manager on Cheaha, it replaces SUN Grid Engine ([ SGE ]) the job manager used earlier. Instructions of using SLURM and writing SLURM scripts for jobs submission on Cheaha can be found here . Typical Workflow \u00b6 Stage data to $USER_SCRATCH (your scratch directory) Research how to run your code in \"batch\" mode. Batch mode typically means the ability to run it from the command line without requiring any interaction from the user. Identify the appropriate resources needed to run the job. The following are mandatory resource requests for all jobs on Cheaha Maximum memory (RAM) required per slot Maximum runtime Write a job script specifying queuing system parameters, resource requests and commands to run program Submit script to queuing system (sbatch script.job) Monitor job (squeue) Review the results and resubmit as necessary Clean up the scratch directory by moving or deleting the data off of the cluster Resource Requests \u00b6 Accurate resource requests are extremely important to the health of the over all cluster. In order for Cheaha to operate properly, the queing system must know how much runtime and RAM each job will need. Mandatory Resource Requests \u00b6 -t, --time= Set a limit on the total run time of the job allocation. If the requested time limit exceeds the partition's time limit, the job will be left in a PENDING state (possibly indefinitely). For Array jobs, this represents the maximum run time for each task For serial or parallel jobs, this represents the maximum run time for the entire job --mem-per-cpu= Mimimum memory required per allocated CPU in MegaBytes. Other Common Resource Requests \u00b6 -N, --nodes= Request that a minimum of minnodes nodes be allocated to this job. A maximum node count may also be specified with maxnodes. If only one number is specified, this is used as both the minimum and maximum node count. -n, --ntasks= sbatch does not launch tasks, it requests an allocation of resources and submits a batch script. This option advises the Slurm controller that job steps run within the allocation will launch a maximum of number tasks and to provide for sufficient resources. The default is one task per node --mem= Specify the real memory required per node in MegaBytes. -c, --cpus-per-task= Advise the Slurm controller that ensuing job steps will require ncpus number of processors per task. Without this option, the controller will just try to allocate one processor per task. -p, --partition= Request a specific partition for the resource allocation. Available partitions are: express(max 2 hrs), short(max 12 hrs), medium(max 50 hrs), long(max 150 hrs), sinteractive(0-2 hrs) Submitting Jobs \u00b6 Batch Jobs are submitted on Cheaha by using the \"sbatch\" command. The full manual for sbtach is available by running the following command man sbatch Job Script File Format \u00b6 To submit a job to the queuing systems, you will first define your job in a script (a text file) and then submit that script to the queuing system. The script file needs to be formatted as a UNIX file , not a Windows or Mac text file. In geek speak, this means that the end of line (EOL) character should be a line feed (LF) rather than a carriage return line feed (CRLF) for Windows or carriage return (CR) for Mac. If you submit a job script formatted as a Windows or Mac text file, your job will likely fail with misleading messages, for example that the path specified does not exist. Windows Notepad does not have the ability to save files using the UNIX file format. Do NOT use Notepad to create files intended for use on the clusters. Instead use one of the alternative text editors listed in the following section. Converting Files to UNIX Format \u00b6 Dos2Unix Method \u00b6 The lines below that begin with $ are commands, the $ represents the command prompt and should not be typed! The dos2unix program can be used to convert Windows text files to UNIX files with a simple command. After you have copied the file to your home directory on the cluster, you can identify that the file is a Windows file by executing the following (Windows uses CR LF as the line terminator, where UNIX uses only LF and Mac uses only CR): $ file testfile.txt testfile.txt: ASCII text, with CRLF line terminators Now, convert the file to UNIX $ dos2unix testfile.txt dos2unix: converting file testfile.txt to UNIX format ... Verify the conversion using the file command $ file testfile.txt testfile.txt: ASCII text Alternative Windows Text Editors \u00b6 There are many good text editors available for Windows that have the capability to save files using the UNIX file format. Here are a few: [ Geany ] is an excellent free text editor for Windows and Linux that supports Windows, UNIX and Mac file formats, syntax highlighting and many programming features. To convert from Windows to UNIX click Document click Set Line Endings and then Convert and Set to LF (Unix) [ Notepad++ ] is a great free Windows text editor that supports Windows, UNIX and Mac file formats, syntax highlighting and many programming features. To convert from Windows to UNIX click Format and then click Convert to UNIX Format [ TextPad ] is another excellent Windows text editor. TextPad is not free, however. Example Batch Job Script \u00b6 A shared cluster environment like Cheaha uses a job scheduler to run tasks on the cluster to provide optimal resource sharing among users. Cheaha uses a job scheduling system call Slurm to schedule and manage jobs. A user needs to tell Slurm about resource requirements (e.g. CPU, memory) so that it can schedule jobs effectively. These resource requirements along with actual application code can be specified in a single file commonly referred as 'Job Script/File'. Following is a simple job script that prints job number and hostname. Note: Jobs must request the appropriate partition (ex: --partition=short ) to satisfy the jobs resource request (maximum runtime, number of compute nodes, etc...) #!/bin/bash # #SBATCH --job-name=test #SBATCH --output=res.txt #SBATCH --ntasks=1 #SBATCH --partition=express #SBATCH --time=10:00 #SBATCH --mem-per-cpu=100 #SBATCH --mail-type=FAIL #SBATCH --mail-user=YOUR_EMAIL_ADDRESS srun hostname srun sleep 60 Lines starting with '#SBATCH' have a special meaning in the Slurm world. Slurm specific configuration options are specified after the '#SBATCH' characters. Above configuration options are useful for most job scripts and for additional configuration options refer to Slurm commands manual. A job script is submitted to the cluster using Slurm specific commands. There are many commands available, but following three commands are the most common: sbatch - to submit job scancel - to delete job squeue - to view job status We can submit above job script using sbatch command: $ sbatch HelloCheaha.sh Submitted batch job 52707 When the job script is submitted, Slurm queues it up and assigns it a job number (e.g. 52707 in above example). The job number is available inside job script using environment variable $JOB_ID. This variable can be used inside job script to create job related directory structure or file names. Interactive Resources \u00b6 Login Node (the host that you connected to when you setup the SSH connection to Cheaha) is supposed to be used for submitting jobs and/or lighter prep work required for the job scripts. Do not run heavy computations on the login node . If you have a heavier workload to prepare for a batch job (eg. compiling code or other manipulations of data) or your compute application requires interactive control, you should request a dedicated interactive node for this work. Interactive resources are requested by submitting an \"interactive\" job to the scheduler. Interactive jobs will provide you a command line on a compute resource that you can use just like you would the command line on the login node. The difference is that the scheduler has dedicated the requested resources to your job and you can run your interactive commands without having to worry about impacting other users on the login node. Interactive jobs, that can be run on command line, are requested with the srun command. srun --ntasks = 1 --cpus-per-task = 4 --mem-per-cpu = 4096 --time = 08 :00:00 --partition = medium --job-name = JOB_NAME --pty /bin/bash This command requests for 4 cores (--cpus-per-task) for a single task (--ntasks) with each cpu requesting size 4GB of RAM (--mem-per-cpu) for 8 hrs (--time). More advanced interactive scenarios to support graphical applications are available using VNC or X11 tunneling X-Win32 2014 for Windows Interactive jobs that requires running a graphical application, are requested with the sinteractive command, via Terminal on your VNC window. sinteractive --ntasks = 1 --cpus-per-task = 4 --mem-per-cpu = 4096 --time = 08 :00:00 --partition = medium --job-name = JOB_NAME Please note, sinteractive starts your shell in a screen session. Screen is a terminal emulator that is designed to make it possible to detach and reattach a session. This feature can mostly be ignored. If you application uses ctrl-a as a special command sequence (e.g. Emacs), however, you may find the application doesn't receive this special character. When using screen, you need to type ctrl-a a (ctrl-a followed by a single \"a\" key press) to send a ctrl-a to your application. Screen uses ctrl-a as it's own command character, so this special sequence issues the command to screen to \"send ctrl-a to my app\". Learn more about screen from it's documentation . Storage \u00b6 Privacy \u00b6 Do not store sensitive information on this filesystem. It is not encrypted. Note that your data will be stored on the cluster filesystem, and while not accessible to ordinary users, it could be accessible to the cluster administrator(s). File and Directory Permissions \u00b6 The default permissions for all user data storage locations described below are as follows. In these descriptions, the \"$USER\" variable should be replaced with the user's account name string: /home/$USER - the owner ($USER) of the directory can read, write/delete, and list files. No other users or groups have permissions to this directory. /data/user/$USER - the owner ($USER) of the directory can read, write/delete, and list files. No other users or groups have permissions to this directory. /scratch/$USER - the owner ($USER) of the directory can read, write/delete, and list files. No other users or groups have permissions to this directory. /data/projects/ - a PI can request project space for their lab or specific collaborations. The project directory is created with the PI/requestor as the user-owner and a dedicated collaboration group as the group-owner. The PI and all members of the dedicated collaboration group have can read, write/delete, and list files. No privileges are granted to other users of the system. Additional controls can be implemented via access control lists (ACLs). The PI/requestor can modify the ACLs to allow additional access to specific users. These permissions are the default configuration. While it is possible to modify these permissions or change the group owner of a file to any group to which a user belongs, users are encouraged to work within the default configuration and contact support@listserv.uab.edu if the default permissions are not adequate. Setting up a collaboration group and associated project directory can address most collaboration need while keep data access restricted to the minimum necessary users for the collaboration. Additional background on Linux file system permissions can be found here: https://its.unc.edu/research-computing/techdocs/how-to-use-unix-and-linux-file-permissions/ https://www.rc.fas.harvard.edu/resources/documentation/linux/unix-permissions/ https://hpc.nih.gov/storage/permissions.html No Automatic Backups \u00b6 There is no automatic back up of any user data on the cluster in home, data, or scratch. At this time, all user data back up processes are defined and managed by each user and/or lab. Given that data backup demands vary widely between different users, groups, and research domains, this approach enables those who are most familiar with the data to make appropriate decisions based on their specific needs. For example, if a group is working with a large shared data set that is a local copy of a data set maintained authoritatively at a national data bank, maintaining a local backup is unlikely to be a productive use of limited storage resources, since this data could potentially be restored from the authoritative source. If, however, you are maintaining a unique source of data of which yours is the only copy, then maintaining a backup is critical if you value that data set. It's worth noting that while this \"uniqueness\" criteria may not apply to the data you analyze, it may readily apply to the codes that define your analysis pipelines. An often recommended backup policy is the 3-2-1 rule: maintain three copies of data, on two different media, with one copy off-site. You can read more about the 3-2-1 rule here . In the case of your application codes, using revision control tools during development provides an easy way to maintain a second copy, makes for a good software development process, and can help achieve reproducible research goals. Please review the data storage options provided by UAB IT for maintaining copies of your data. In choosing among these options, you should also be aware of UAB's data classification rules and requirements for security requirements for sensitive and restricted data storage. Given the importance of backup, Research Computing continues to explore options to facilitate data backup workflows from the cluster. Please contact us if you have questions or would like to discuss specific data backup scenarios. A good guide for thinking about your backup strategy might be: \"If you aren't managing a data back up process, then you have no backup data.\" Home directories \u00b6 Your home directory on Cheaha is NFS-mounted to the compute nodes as /home/$USER or $HOME. It is acceptable to use your home directory as a location to store job scripts and custom code. You are responsible for keeping your home directory under 10GB in size! The home directory must not be used to store large amounts of data. Please use $USER_SCRATCH for actively used data sets and $USER_DATA for storage of non scratch data. Scratch \u00b6 Research Computing policy requires that all bulky input and output must be located on the scratch space. The home directory is intended to store your job scripts, log files, libraries and other supporting files. Important Information: Scratch space (network and local) is not backed up . Research Computing expects each user to keep their scratch areas clean. The cluster scratch area are not to be used for archiving data. Cheaha has two types of scratch space, network mounted and local. Network scratch ($USER_SCRATCH) is available on the login node and each compute node. This storage is a GPFS high performance file system providing roughly 4.7PB of usable storage. This should be your jobs primary working directory, unless the job would benefit from local scratch (see below). Local scratch is physically located on each compute node and is not accessible to the other nodes (including the login node). This space is useful if the job performs a lot of file I/O. Most of the jobs that run on our clusters do not fall into this category. Because the local scratch is inaccessible outside the job, it is important to note that you must move any data between local scratch to your network accessible scratch within your job. For example, step 1 in the job could be to copy the input from $USER_SCRATCH to ${USER_SCRATCH}, step 2 code execution, step 3 move the data back to $USER_SCRATCH. Network Scratch \u00b6 Network scratch is available using the environment variable $USER_SCRATCH or directly by /data/scratch/$USER It is advisable to use the environment variable whenever possible rather than the hard coded path. Local Scratch \u00b6 Each compute node has a local scratch directory that is accessible via the variable $LOCAL_SCRATCH . If your job performs a lot of file I/O, the job should use $LOCAL_SCRATCH rather than $USER_SCRATCH to prevent bogging down the network scratch file system. The amount of scratch space available is approximately 800GB. The $LOCAL_SCRATCH is a special temporary directory and it's important to note that this directory is deleted when the job completes, so the job script has to move the results to $USER_SCRATCH or other location prior to the job exiting. Note that $LOCAL_SCRATCH is only useful for jobs in which all processes run on the same compute node, so MPI jobs are not candidates for this solution. The following is an array job example that uses $LOCAL_SCRATCH by transferring the inputs into $LOCAL_SCRATCH at the beginning of the script and the result out of $LOCAL_SCRATCH at the end of the script. #!/bin/bash #SBATCH --array=1-10 #SBATCH --share #SBATCH --partition=express # # Name your job to make it easier for you to track # #SBATCH --job-name=R_array_job # # Set your error and output files # #SBATCH --error=R_array_job.err #SBATCH --output=R_array_job.out #SBATCH --ntasks=1 # # Tell the scheduler only need 10 minutes and the appropriate partition # #SBATCH --time=00:10:00 #SBATCH --mem-per-cpu=256 # # Set your email address and request notification when you job is complete or if it fails # #SBATCH --mail-type=FAIL #SBATCH --mail-user=YOUR_EMAIL_ADDRESS module load R/3.2.0-goolf-1.7.20 echo \"TMPDIR: $LOCAL_SCRATCH \" cd $LOCAL_SCRATCH # Create a working directory under the special scheduler local scratch directory # using the array job's taskID mdkir $SLURM_ARRAY_TASK_ID cd $SLURM_ARRAY_TASK_ID # Next copy the input data to the local scratch echo \"Copying input data from network scratch to $LOCAL_SCRATCH / $SLURM_ARRAY_TASK_ID - $( date ) # The input data in this case has a numerical file extension that # matches $SLURM_ARRAY_TASK_ID cp -a $USER_SCRATCH /GeneData/INP*. $SLURM_ARRAY_TASK_ID ./ echo \" copied input data from network scratch to $LOCAL_SCRATCH / $SLURM_ARRAY_TASK_ID - $( date ) someapp -S 1 -D 10 -i INP*. $SLURM_ARRAY_TASK_ID -o geneapp.out. $SLURM_ARRAY_TASK_ID # Lastly copy the results back to network scratch echo \"Copying results from local $LOCAL_SCRATCH / $SLURM_ARRAY_TASK_ID to network - $( date ) cp -a geneapp.out. $SLURM_ARRAY_TASK_ID $USER_SCRATCH /GeneData/ echo \" Copied results from local $LOCAL_SCRATCH / $SLURM_ARRAY_TASK_ID to network - $( date ) Project Storage \u00b6 Cheaha has a location where shared data can be stored called $SHARE_PROJECT. As with user scratch, this area is not backed up ! This is helpful if a team of researchers must access the same data. Please open a help desk ticket to request a project directory under $SHARE_PROJECT. Uploading Data \u00b6 Do not store sensitive information on this filesystem. It is not encrypted. Note that your data will be stored on the cluster filesystem, and while not accessible to ordinary users, it could be accessible to the cluster administrator(s). Data can be moved onto the cluster (pushed) from a remote client (ie. you desktop) via SCP or SFTP. Data can also be downloaded to the cluster (pulled) by issuing transfer commands once you are logged into the cluster. Common transfer methods are wget <URL> , FTP, or SCP, and depend on how the data is made available from the data provider. Large data sets should be staged directly to your $USER_SCRATCH directory so as not to fill up $HOME. If you are working on a data set shared with multiple users, it's preferable to request space in $SHARE_PROJECT rather than duplicating the data for each user. Environment Modules \u00b6 Environment Modules is installed on Cheaha and should be used when constructing your job scripts if an applicable module file exists. Using the module command you can easily configure your environment for specific software packages without having to know the specific environment variables and values to set. Modules allows you to dynamically configure your environment without having to logout / login for the changes to take affect. If you find that specific software does not have a module, please submit a helpdesk ticket to request the module. Cheaha supports bash completion for the module command. For example, type 'module' and press the TAB key twice to see a list of options: module TAB TAB add display initlist keyword refresh switch use apropos help initprepend list rm unload whatis avail initadd initrm load show unuse clear initclear initswitch purge swap update To see the list of available modulefiles on the cluster, run the module avail command (note the example list below may not be complete!) or module load followed by two tab key presses: module avail ----------------------------------------------------------------------------------------- /cm/shared/modulefiles ----------------------------------------------------------------------------------------- acml/gcc/64/5.3.1 acml/open64-int64/mp/fma4/5.3.1 fftw2/openmpi/gcc/64/float/2.1.5 intel-cluster-runtime/ia32/3.8 netcdf/gcc/64/4.3.3.1 acml/gcc/fma4/5.3.1 blacs/openmpi/gcc/64/1.1patch03 fftw2/openmpi/open64/64/double/2.1.5 intel-cluster-runtime/intel64/3.8 netcdf/open64/64/4.3.3.1 acml/gcc/mp/64/5.3.1 blacs/openmpi/open64/64/1.1patch03 fftw2/openmpi/open64/64/float/2.1.5 intel-cluster-runtime/mic/3.8 netperf/2.7.0 acml/gcc/mp/fma4/5.3.1 blas/gcc/64/3.6.0 fftw3/openmpi/gcc/64/3.3.4 intel-tbb-oss/ia32/44_20160526oss open64/4.5.2.1 acml/gcc-int64/64/5.3.1 blas/open64/64/3.6.0 fftw3/openmpi/open64/64/3.3.4 intel-tbb-oss/intel64/44_20160526oss openblas/dynamic/0.2.15 acml/gcc-int64/fma4/5.3.1 bonnie++/1.97.1 gdb/7.9 iozone/3_434 openmpi/gcc/64/1.10.1 acml/gcc-int64/mp/64/5.3.1 cmgui/7.2 globalarrays/openmpi/gcc/64/5.4 lapack/gcc/64/3.6.0 openmpi/open64/64/1.10.1 acml/gcc-int64/mp/fma4/5.3.1 cuda75/blas/7.5.18 globalarrays/openmpi/open64/64/5.4 lapack/open64/64/3.6.0 pbspro/13.0.2.153173 acml/open64/64/5.3.1 cuda75/fft/7.5.18 hdf5/1.6.10 mpich/ge/gcc/64/3.2 puppet/3.8.4 acml/open64/fma4/5.3.1 cuda75/gdk/352.79 hdf5_18/1.8.16 mpich/ge/open64/64/3.2 rc-base acml/open64/mp/64/5.3.1 cuda75/nsight/7.5.18 hpl/2.1 mpiexec/0.84_432 scalapack/mvapich2/gcc/64/2.0.2 acml/open64/mp/fma4/5.3.1 cuda75/profiler/7.5.18 hwloc/1.10.1 mvapich/gcc/64/1.2rc1 scalapack/openmpi/gcc/64/2.0.2 acml/open64-int64/64/5.3.1 cuda75/toolkit/7.5.18 intel/compiler/32/15.0/2015.5.223 mvapich/open64/64/1.2rc1 sge/2011.11p1 acml/open64-int64/fma4/5.3.1 default-environment intel/compiler/64/15.0/2015.5.223 mvapich2/gcc/64/2.2b slurm/15.08.6 acml/open64-int64/mp/64/5.3.1 fftw2/openmpi/gcc/64/double/2.1.5 intel-cluster-checker/2.2.2 mvapich2/open64/64/2.2b torque/6.0.0.1 ---------------------------------------------------------------------------------------- /share/apps/modulefiles ----------------------------------------------------------------------------------------- rc/BrainSuite/15b rc/freesurfer/freesurfer-5.3.0 rc/intel/compiler/64/ps_2016/2016.0.047 rc/matlab/R2015a rc/SAS/v9.4 rc/cmg/2012.116.G rc/gromacs-intel/5.1.1 rc/Mathematica/10.3 rc/matlab/R2015b rc/dsistudio/dsistudio-20151020 rc/gtool/0.7.5 rc/matlab/R2012a rc/MRIConvert/2.0.8 --------------------------------------------------------------------------------------- /share/apps/rc/modules/all --------------------------------------------------------------------------------------- AFNI/linux_openmp_64-goolf-1.7.20-20160616 gperf/3.0.4-intel-2016a MVAPICH2/2.2b-GCC-4.9.3-2.25 Amber/14-intel-2016a-AmberTools-15-patchlevel-13-13 grep/2.15-goolf-1.4.10 NASM/2.11.06-goolf-1.7.20 annovar/2016Feb01-foss-2015b-Perl-5.22.1 GROMACS/5.0.5-intel-2015b-hybrid NASM/2.11.08-foss-2015b ant/1.9.6-Java-1.7.0_80 GSL/1.16-goolf-1.7.20 NASM/2.11.08-intel-2016a APBS/1.4-linux-static-x86_64 GSL/1.16-intel-2015b NASM/2.12.02-foss-2016a ASHS/rev103_20140612 GSL/2.1-foss-2015b NASM/2.12.02-intel-2015b Aspera-Connect/3.6.1 gtool/0.7.5_linux_x86_64 NASM/2.12.02-intel-2016a ATLAS/3.10.1-gompi-1.5.12-LAPACK-3.4.2 guile/1.8.8-GNU-4.9.3-2.25 ncurses/5.9-foss-2015b Autoconf/2.69-foss-2016a HAPGEN2/2.2.0 ncurses/5.9-GCC-4.8.4 Autoconf/2.69-GCC-4.8.4 HarfBuzz/1.2.7-intel-2016a ncurses/5.9-GNU-4.9.3-2.25 Autoconf/2.69-GNU-4.9.3-2.25 HDF5/1.8.15-patch1-intel-2015b ncurses/5.9-goolf-1.4.10 . . . . Some software packages have multiple module files, for example: GCC/4.7.2 GCC/4.8.1 GCC/4.8.2 GCC/4.8.4 GCC/4.9.2 GCC/4.9.3 GCC/4.9.3-2.25 In this case, the GCC module will always load the latest version, so loading this module is equivalent to loading GCC/4.9.3-2.25. If you always want to use the latest version, use this approach. If you want use a specific version, use the module file containing the appropriate version number. Some modules, when loaded, will actually load other modules. For example, the GROMACS/5.0.5-intel-2015b-hybrid module will also load intel/2015b and other related tools. To load a module, ex: for a GROMACS job, use the following module load command in your job script: module load GROMACS/5.0.5-intel-2015b-hybrid To see a list of the modules that you currently have loaded use the module list command module list Currently Loaded Modulefiles: 1 ) slurm/15.08.6 9 ) impi/5.0.3.048-iccifort-2015.3.187-GNU-4.9.3-2.25 17 ) Tcl/8.6.3-intel-2015b 2 ) rc-base 10 ) iimpi/7.3.5-GNU-4.9.3-2.25 18 ) SQLite/3.8.8.1-intel-2015b 3 ) GCC/4.9.3-binutils-2.25 11 ) imkl/11.2.3.187-iimpi-7.3.5-GNU-4.9.3-2.25 19 ) Tk/8.6.3-intel-2015b-no-X11 4 ) binutils/2.25-GCC-4.9.3-binutils-2.25 12 ) intel/2015b 20 ) Python/2.7.9-intel-2015b 5 ) GNU/4.9.3-2.25 13 ) bzip2/1.0.6-intel-2015b 21 ) Boost/1.58.0-intel-2015b-Python-2.7.9 6 ) icc/2015.3.187-GNU-4.9.3-2.25 14 ) zlib/1.2.8-intel-2015b 22 ) GROMACS/5.0.5-intel-2015b-hybrid 7 ) ifort/2015.3.187-GNU-4.9.3-2.25 15 ) ncurses/5.9-intel-2015b 8 ) iccifort/2015.3.187-GNU-4.9.3-2.25 16 ) libreadline/6.3-intel-2015b A module can be removed from your environment by using the module unload command: module unload GROMACS/5.0.5-intel-2015b-hybrid The definition of a module can also be viewed using the module show command, revealing what a specific module will do to your environment: module show GROMACS/5.0.5-intel-2015b-hybrid ------------------------------------------------------------------- /share/apps/rc/modules/all/GROMACS/5.0.5-intel-2015b-hybrid: module-whatis GROMACS is a versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations of motion for systems with hundreds to millions of particles. - Homepage: http://www.gromacs.org conflict GROMACS prepend-path CPATH /share/apps/rc/software/GROMACS/5.0.5-intel-2015b-hybrid/include prepend-path LD_LIBRARY_PATH /share/apps/rc/software/GROMACS/5.0.5-intel-2015b-hybrid/lib64 prepend-path LIBRARY_PATH /share/apps/rc/software/GROMACS/5.0.5-intel-2015b-hybrid/lib64 prepend-path MANPATH /share/apps/rc/software/GROMACS/5.0.5-intel-2015b-hybrid/share/man prepend-path PATH /share/apps/rc/software/GROMACS/5.0.5-intel-2015b-hybrid/bin prepend-path PKG_CONFIG_PATH /share/apps/rc/software/GROMACS/5.0.5-intel-2015b-hybrid/lib64/pkgconfig setenv EBROOTGROMACS /share/apps/rc/software/GROMACS/5.0.5-intel-2015b-hybrid setenv EBVERSIONGROMACS 5 .0.5 setenv EBDEVELGROMACS /share/apps/rc/software/GROMACS/5.0.5-intel-2015b-hybrid/easybuild/GROMACS-5.0.5-intel-2015b-hybrid-easybuild-devel ------------------------------------------------------------------- Error Using Modules from a Job Script \u00b6 If you are using modules and the command your job executes runs fine from the command line but fails when you run it from the job, you may be having an issue with the script initialization. If you see this error in your job error output file -bash: module: line 1 : syntax error: unexpected end of file -bash: error importing function definition for ` BASH_FUNC_module ' Add the command unset module before calling your module files. The -V job argument will cause a conflict with the module function used in your script. Sample Job Scripts \u00b6 The following are sample job scripts, please be careful to edit these for your environment (i.e. replace YOUR_EMAIL_ADDRESS with your real email address), set the h_rt to an appropriate runtime limit and modify the job name and any other parameters. Hello World is the classic example used throughout programming. We don't want to buck the system, so we'll use it as well to demonstrate jobs submission with one minor variation: our hello world will send us a greeting using the name of whatever machine it runs on. For example, when run on the Cheaha login node, it would print \"Hello from login001\". Hello World (serial) \u00b6 A serial job is one that can run independently of other commands, ie. it doesn't depend on the data from other jobs running simultaneously. You can run many serial jobs in any order. This is a common solution to processing lots of data when each command works on a single piece of data. For example, running the same conversion on 100s of images. Here we show how to create job script for one simple command. Running more than one command just requires submitting more jobs. Create your hello world application. Run this command to create a script, turn it into to a command, and run the command (just copy and past the following on to the command line). Create the file: vim helloworld.sh Write into \"helloworld.sh\" file (To write in vim editor: press shift + I ) #!/bin/bash echo Hello from ` hostname ` Save the file by pressing the esc key, type the following :wq Need to give permission the \"helloworld.sh\" file chmod +x helloworld.sh Create the Slurm job script that will request 256 MB RAM and a maximum runtime of 10 minutes. Create the JOB file: vim helloworld.job Write into \"helloworld.job\" file (To write in vim editor: press shift + I ) #!/bin/bash #SBATCH --share #SBATCH --partition=express # # Name your job to make it easier for you to track # #SBATCH --job-name=helloworld # # Set your error and output files # #SBATCH --error=helloworld.err #SBATCH --output=helloworld.out #SBATCH --ntasks=1 # # Tell the scheduler only need 10 minutes # #SBATCH --time=00:10:00 #SBATCH --mem-per-cpu=256 # # Set your email address and request notification when you job is complete or if it fails # #SBATCH --mail-type=FAIL #SBATCH --mail-user=$USER@uab.edu ./helloworld.sh Save the file by pressing the esc key, type the following :wq Submit the job to Slurm scheduler and check the status using squeue $ sbatch helloworld.job Submitted batch job 52888 When the job completes, you should have output files named helloworld.out and helloworld.err $ cat helloworld.out Hello from c0003 Hello World (parallel with MPI) \u00b6 MPI is used to coordinate the activity of many computations occurring in parallel. It is commonly used in simulation software for molecular dynamics, fluid dynamics, and similar domains where there is significant communication (data) exchanged between cooperating process. Here is a simple parallel Slurm job script for running commands the rely on MPI. This example also includes the example of compiling the code and submitting the job script to the Slurm scheduler. First, create a directory for the Hello World jobs mkdir -p ~/jobs/helloworld cd ~/jobs/helloworld Create the Hello World code written in C (this example of MPI enabled Hello World includes a 3 minute sleep to ensure the job runs for several minutes, a normal hello world example would run in a matter of seconds). $ vi helloworld-mpi.c #include <stdio.h> #include <mpi.h> main ( int argc, char **argv ) { int rank, size ; int i, j ; float f ; MPI_Init ( & argc, & argv ) ; MPI_Comm_rank ( MPI_COMM_WORLD, & rank ) ; MPI_Comm_size ( MPI_COMM_WORLD, & size ) ; printf ( \"Hello World from process %d of %d.\\n\" , rank, size ) ; sleep ( 180 ) ; for ( j = 0 ; j< = 100000 ; j++ ) for ( i = 0 ; i< = 100000 ; i++ ) f = i*2.718281828*i+i+i*3.141592654 ; MPI_Finalize () ; } Compile the code, first purging any modules you may have loaded followed by loading the module for OpenMPI GNU. The mpicc command will compile the code and produce a binary named helloworld_gnu_openmpi module purge module load DefaultModules module load OpenMPI/4.0.1-GCC-8.3.0-2.32 mpicc helloworld-mpi.c -o helloworld_gnu_openmpi Create the Slurm job script that will request 8 cpu slots and a maximum runtime of 10 minutes $ vi helloworld.job #!/bin/bash #SBATCH --share #SBATCH --partition=express # # Name your job to make it easier for you to track # #SBATCH --job-name=helloworld_mpi # # Set your error and output files # #SBATCH --error=helloworld_mpi.err #SBATCH --output=helloworld_mpi.out #SBATCH --ntasks=8 # # Tell the scheduler only need 10 minutes # #SBATCH --time=00:10:00 #SBATCH --mem-per-cpu=256 # # Set your email address and request notification when you job is complete or if it fails # #SBATCH --mail-type=FAIL #SBATCH --mail-user=YOUR_EMAIL_ADDRESS module load OpenMPI/1.8.8-GNU-4.9.3-2.25 mpirun -np $SLURM_NTASKS helloworld_gnu_openmpi Submit the job to Slurm scheduler and check the status using squeue -u $USER $ sbatch helloworld.job Submitted batch job 52893 $ squeue -u BLAZERID JOBID PARTITION NAME USER ST TIME NODES NODELIST ( REASON ) 52893 express hellowor BLAZERID R 2 :07 2 c [ 0005 -0006 ] When the job completes, you should have output files named helloworld_mpi.out and helloworld_mpi.err $ cat helloworld_mpi.out Hello World from process 1 of 8 . Hello World from process 3 of 8 . Hello World from process 4 of 8 . Hello World from process 7 of 8 . Hello World from process 5 of 8 . Hello World from process 6 of 8 . Hello World from process 0 of 8 . Hello World from process 2 of 8 . Hello World (serial) -- revisited \u00b6 The job submit scripts (sbatch scripts) are actually bash shell scripts in their own right. The reason for using the funky #SBATCH prefix in the scripts is so that bash interprets any such line as a comment and won't execute it. Because the # character starts a comment in bash, we can weave the Slurm scheduler directives (the #SBATCH lines) into standard bash scripts. This lets us build scripts that we can execute locally and then easily run the same script to on a cluster node by calling it with sbatch. This can be used to our advantage to create a more fluid experience in moving between development and production job runs. The following example is a simple variation on the serial job above. All we will do is convert our Slurm job script into a command called helloworld that calls the helloworld.sh command. If the first line of a file is #!/bin/bash and that file is executable, the shell will automatically run the command as if were any other system command, eg. ls. That is, the \".sh\" extension on our HelloWorld.sh script is completely optional and is only meaningful to the user. Copy the serial helloworld.job script to a new file, add a the special #!/bin/bash as the first line, and make it executable with the following command (note: those are single quotes in the echo command): echo '#!/bin/bash' | cat helloworld.job > helloworld ; chmod +x helloworld Our sbatch script has now become a regular command. We can now execute the command with the simple prefix \"./helloworld\", which means \"execute this file in the current directory\": ./helloworld Hello from login001 Or if we want to run the command on a compute node, replace the \"./\" prefix with \"sbatch \": $ sbatch helloworld Submitted batch job 53001 And when the cluster run is complete you can look at the content of the output: $ $ cat helloworld.out Hello from c0003 You can use this approach of treating you sbatch files as command wrappers to build a collection of commands that can be executed locally or via sbatch. The other examples can be restructured similarly. To avoid having to use the \"./\" prefix, just add the current directory to your PATH. Also, if you plan to do heavy development using this feature on the cluster, please be sure to run sinteractive first so you don't load the login node with your development work. Gromacs \u00b6 #!/bin/bash #SBATCH --partition=short # # Name your job to make it easier for you to track # #SBATCH --job-name=test_gromacs # # Set your error and output files # #SBATCH --error=test_gromacs.err #SBATCH --output=test_gromacs.out #SBATCH --ntasks=8 # # Tell the scheduler only need 10 minutes # #SBATCH --time=10:00:00 #SBATCH --mem-per-cpu=2048 # # Set your email address and request notification when you job is complete or if it fails # #SBATCH --mail-type=FAIL #SBATCH --mail-user=YOUR_EMAIL_ADDRESS module load OpenMPI/1.8.8-GNU-4.9.3-2.25 module load GROMACS/5.0.5-intel-2015b-hybrid # Change directory to the job working directory if not already there cd ${ USER_SCRATCH } /jobs/gromacs # Single precision MDRUN = mdrun_mpi # Enter your tpr file over here export MYFILE = example.tpr mpirun -np SLURM_NTASKS $MDRUN -v -s $MYFILE -o $MYFILE -c $MYFILE -x $MYFILE -e $MYFILE -g ${ MYFILE } .log R (array job) \u00b6 The following is an example job script that will use an array of 10 tasks (--array=1-10), each task has a max runtime of 2 hours and will use no more than 256 MB of RAM per task. Array's of tasks are useful when you have lots of simple jobs that work on their own separate files or a sub-set of the problem that can be selected by the array task index. For a more comprehensive introduction please see this tutorial . Create a working directory and the job submission script $ mkdir -p ~/jobs/ArrayExample $ cd ~/jobs/ArrayExample $ vi R-example-array.job #!/bin/bash #SBATCH --array=1-10 #SBATCH --share #SBATCH --partition=express # # Name your job to make it easier for you to track # #SBATCH --job-name=R_array_job # # Set your error and output files # #SBATCH --error=R_array_job.err #SBATCH --output=R_array_job.out #SBATCH --ntasks=1 # # Tell the scheduler only need 10 minutes # #SBATCH --time=00:10:00 #SBATCH --mem-per-cpu=256 # # Set your email address and request notification when you job is complete or if it fails # #SBATCH --mail-type=FAIL #SBATCH --mail-user=YOUR_EMAIL_ADDRESS module load R/3.2.0-goolf-1.7.20 cd ~/jobs/ArrayExample/rep $SLURM_ARRAY_TASK_ID srun R CMD BATCH rscript.R Submit the job to the Slurm scheduler and check the status of the job using the squeue command sbatch R-example-array.job squeue -u $USER Array Job Parameterization \u00b6 Suppose you need to submit thousands of jobs. While you could do this in a for loop, the global limit on jobs in the SLURM queue is 10,000. The limit is in place for performance reasons and the jobs may be rejected with the following error message and an incomplete set of tasks. sbatch: error: Slurm temporarily unable to accept job, sleeping and retrying The preferred way to handle this scenario is to allow SLURM to schedule the jobs for you using the array flag in an sbatch script. This allows many jobs to be submitted as a single entry in the queue, letting SLURM handle the for loop and queueing. It is possible to reference the current loop index, or task id, as $SLURM_ARRAY_TASK_ID. An example using $SLURM_ARRAY_TASK_ID to load input files and create output files is shown below. Suppose you have a short script called my_processing_script that needs to be run on 20,000 separate files. Suppose each instance only needs 1 cpu and 2 GB of RAM and finishes in 5 minutes. Submitting these files all at once won't work and at least half of them will be rejected by SLURM. Instead we can use the sbatch array flag. Note that some other useful flags have been omitted for brevity. #! /bin/bash #SBATCH --partition=express #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=2G #SBATCH --array=1-20000%100 # This will run tasks 1 through 20000, with up to 100 at a time. # It is possible to provide any comma-separated list of intervals. # An example of a valid subset is --array=1,2,5-1000,3777,4995-5000%100 INPUT_FILE = $USER_DATA /input/file_ $SLURM_ARRAY_TASK_ID .txt OUTPUT_FILE = $USER_DATA /output/file_ $SLURM_ARRAY_TASK_ID .txt my_processing_script --input = \" $INPUT_FILE \" --output = \" $OUTPUT_FILE \" GPU JOB \u00b6 A Graphics processing unit (GPU) is a specialized electronic circuit designed to rapidly manipulate and alter memory to accelerate the creation of images in a frame buffer intended for output to a display device. Create a math.sh file as: $vim math.sh #!/bin/bash ( e = 5 ) echo $e (( e = e + 3 )) echo $e (( e = e+4 )) # -- spaces or no spaces, it doesn't matter echo $e Give File permissions for script as follows: $chmod +x math.sh Create Job submission script file: $vi math.job #!/bin/bash #SBATCH --share #SBATCH --partition=pascalnodes #SBATCH --gres=gpu:1 # Name your job to make it easier for you to track # #SBATCH --job-name=math # # Set your error and output files # #SBATCH --error=math.err #SBATCH --output=math.out #SBATCH --ntasks=1 # # Tell the scheduler only need 10 minutes # #SBATCH --time=00:10:00 #SBATCH --mem-per-cpu=256 # # Set your email address and request notification when you job is complete or if it fails # #SBATCH --mail-type=FAIL #SBATCH --mail-user=$USER@uab.edu ./math.sh Submitting batch script to Slurm scheduler $sbatch math.job We can also request GPU's on cluster as: $sinteractive --ntasks = 1 --time = 00 :10:00 --exclusive --partition = pascalnodes -N2 --gres = gpu:2 GPU Job (with MPI) \u00b6 As mentioned above, MPI is used to coordinate the activity of many computations occurring in parallel. It is commonly used in simulation software for molecular dynamics, fluid dynamics, and similar domains where there is significant communication (data) exchanged between cooperating process. An example of an GPU job with MPI can be found by visiting this link . Be sure to request the appropiate amount of gpu resources for your job: sinteractive --ntasks = 8 --time = 08 :00:00 --exclusive --partition = pascalnodes -N2 --gres = gpu:4 Singularity Container \u00b6 Singularity is designed so that you can use it within SLURM jobs and it does not violate security constraints on the cluster. Singularity was built keeping HPC in mind, i.e a shared environment. Using Singularity container with SLURM job script is very easy, as the containers run as a process on the host machine, just like any other command in a batch script. You just need to load Singularity in your job script and run the command via a singularity process. Here's an example job script below: #!/bin/bash # #SBATCH --job-name=test-singularity #SBATCH --output=res.out #SBATCH --error=res.err # # Number of tasks needed for this job. Generally, used with MPI jobs #SBATCH --ntasks=1 #SBATCH --partition=express # # Time format = HH:MM:SS, DD-HH:MM:SS #SBATCH --time=10:00 # # Number of CPUs allocated to each task. #SBATCH --cpus-per-task=1 # # Mimimum memory required per allocated CPU in MegaBytes. #SBATCH --mem-per-cpu=100 # # Send mail to the email address when the job fails #SBATCH --mail-type=FAIL #SBATCH --mail-user=$USER@uab.edu #Set your environment here module load Singularity/2.5.2-GCC-5.4.0-2.26 #Run your singularity or any other commands here singularity exec -B /data/user/ $USER /data/user/ $USER /rc-training-sessions/neurodebian-neurodebian-master-latest.simg dcm2nii PATH_TO_YOUR_DICOM_FILES For a more comprehensive introduction please see this tutorial . Installed Software \u00b6 A partial list of installed software with additional instructions for their use is available on the Cheaha Software page.","title":"Getting Started"},{"location":"cheaha/getting_started/#getting-started","text":"Cheaha is a cluster computing environment for UAB researchers. Information about the history and future plans for Cheaha is available on the Cheaha page.","title":"Getting Started"},{"location":"cheaha/getting_started/#access-cluster-account-request","text":"To get started using Cheaha , simply visit our Open OnDemand portal at https://rc.uab.edu . This is the primary entry point for Cheaha and provides access to all cluster services directly from your web browser, including graphical desktops, Jupyter Notebooks, and even the traditional command-line. If you don't already have an account, you will be prompted to create one the first time you log into the portal. If you are creating an account, please share some of your interests in using Cheaha as this help us understand the science interests of our users. Please note : Usage of Cheaha is governed by UAB's Acceptable Use Policy (AUP) for computer resources.","title":"Access (Cluster Account Request)"},{"location":"cheaha/getting_started/#external-collaborator","text":"To request an account for an external collaborator, please follow the steps here.","title":"External Collaborator"},{"location":"cheaha/getting_started/#login","text":"","title":"Login"},{"location":"cheaha/getting_started/#overview","text":"Once your account has been created, you'll receive an email containing your user ID, generally your Blazer ID. You can log into Cheaha via your web browser using the new web-based HPC experience. You can also log into Cheaha via a traditional SSH client. Most UAB Windows workstations already have an SSH client installed, possibly named SSH Secure Shell Client or PuTTY . Linux and Mac OS X systems should have an SSH client installed by default. Usage of Cheaha is governed by UAB's Acceptable Use Policy (AUP) for computer and network resources.","title":"Overview"},{"location":"cheaha/getting_started/#client-configuration","text":"This section will cover steps to configure Windows, Linux and Mac OS X clients to connect to Cheaha. The official DNS name of Cheaha's frontend machine is cheaha.rc.uab.edu . If you want to refer to the machine as cheaha , you'll have to either add the \"rc.uab.edu\" to you computer's DNS search path. On Unix-derived systems (Linux, Mac) you can edit your computers /etc/resolv.conf as follows (you'll need administrator access to edit this file) search rc.uab.edu Or you can customize your SSH configuration to use the short name \"cheaha\" as a connection name. On systems using OpenSSH you can add the following to your ~/.ssh/config file Host cheaha Hostname cheaha.rc.uab.edu","title":"Client Configuration"},{"location":"cheaha/getting_started/#linux","text":"Linux systems, regardless of the flavor (RedHat, SuSE, Ubuntu, etc...), should already have an SSH client on the system as part of the default install. Start a terminal (on RedHat click Applications -> Accessories -> Terminal, on Ubuntu Ctrl+Alt+T) At the prompt, enter the following command to connect to Cheaha ( Replace blazerid with your Cheaha userid ) ssh blazerid@cheaha.rc.uab.edu","title":"Linux"},{"location":"cheaha/getting_started/#mac-os-x","text":"Mac OS X is a Unix operating system (BSD) and has a built in ssh client. Start a terminal (click Finder, type Terminal and double click on Terminal under the Applications category) At the prompt, enter the following command to connect to Cheaha ( Replace blazerid with your Cheaha userid ) ssh blazerid@cheaha.rc.uab.edu","title":"Mac OS X"},{"location":"cheaha/getting_started/#windows","text":"There are many SSH clients available for Windows, some commercial and some that are free (GPL). This section will cover two clients that are commonly found on UAB Windows systems.","title":"Windows"},{"location":"cheaha/getting_started/#mobaxterm","text":"MobaXterm is a free (also available for a price in a Profession version) suite of SSH tools. Of the Windows clients we've used, MobaXterm is the easiest to use and feature complete. Features include (but not limited to): SSH client (in a handy web browser like tabbed interface) Embedded Cygwin (which allows Windows users to run many Linux commands like grep, rsync, sed) Remote file system browser (graphical SFTP) X11 forwarding for remotely displaying graphical content from Cheaha Installs without requiring Windows Administrator rights Start MobaXterm and click the Session toolbar button (top left). Click SSH for the session type, enter the following information and click OK. Once finished, double click cheaha.rc.uab.edu in the list of Saved sessions under PuTTY sessions: Field Cheaha Settings Remote host cheaha.rc.uab.edu Port 22","title":"MobaXterm"},{"location":"cheaha/getting_started/#putty","text":"PuTTY is a free suite of SSH and telnet tools written and maintained by Simon Tatham . PuTTY supports SSH, secure FTP (SFTP), and X forwarding (XTERM) among other tools. Start PuTTY (Click START -> All Programs -> PuTTY -> PuTTY). The 'PuTTY Configuration' window will open Use these settings for each of the clusters that you would like to configure Field Cheaha Settings Host Name (or IP address) cheaha.rc.uab.edu Port 22 Protocol SSH Saved Sessions cheaha.rc.uab.edu Click Save to save the configuration, repeat the previous steps for the other clusters The next time you start PuTTY, simply double click on the cluster name under the 'Saved Sessions' list","title":"PuTTY"},{"location":"cheaha/getting_started/#ssh-secure-shell-client","text":"SSH Secure Shell is a commercial application that is installed on many Windows workstations on campus and can be configured as follows: Start the program (Click START -> All Programs -> SSH Secure Shell -> Secure Shell Client). The 'default - SSH Secure Shell' window will open Click File -> Profiles -> Add Profile to open the 'Add Profile' window Type in the name of the cluster (for example: cheaha) in the field and click 'Add to Profiles' Click File -> Profiles -> Edit Profiles to open the 'Profiles' window Single click on your new profile name Use these settings for the clusters Field Cheaha Settings Host name cheaha.rc.uab.edu User name blazerid (insert your blazerid here) Port 22 Protocol SSH Encryption algorithm MAC algorithm Compression Terminal answerback vt100 Leave 'Connect through firewall' and 'Request tunnels only' unchecked Click OK to save the configuration, repeat the previous steps for the other clusters The next time you start SSH Secure Shell, click 'Profiles' and click the cluster name","title":"SSH Secure Shell Client"},{"location":"cheaha/getting_started/#logging-in-to-cheaha","text":"No matter which client you use to connect to the Cheaha, the first time you connect, the SSH client should display a message asking if you would like to import the hosts public key. Answer Yes to this question. Connect to Cheaha using one of the methods listed above Answer Yes to import the cluster's public key Enter your BlazerID password After successfully logging in for the first time, You may see the following message just press ENTER for the next three prompts, don't type any passphrases! It doesn ' t appear that you have set up your ssh key. This process will make the files: /home/joeuser/.ssh/id_rsa.pub /home/joeuser/.ssh/id_rsa /home/joeuser/.ssh/authorized_keys Generating public/private rsa key pair. Enter file in which to save the key ( /home/joeuser/.ssh/id_rsa ) : Enter file in which to save the key (/home/joeuser/.ssh/id_rsa): Press Enter Enter passphrase (empty for no passphrase): Press Enter Enter same passphrase again: Press Enter Your identification has been saved in /home/joeuser/.ssh/id_rsa. Your public key has been saved in /home/joeuser/.ssh/id_rsa.pub. The key fingerprint is: f6:xx:xx:xx:xx:dd:9a:79:7b:83:xx:f9:d7:a7:d6:27 joeuser@cheaha.rc.uab.edu","title":"Logging in to Cheaha"},{"location":"cheaha/getting_started/#users-without-a-blazerid-collaborators-from-other-universities","text":"If you were issued a temporary password, enter it (Passwords are CaSE SensitivE!!!) You should see a message similar to this You are required to change your password immediately ( password aged ) WARNING: Your password has expired. You must change your password now and login again! Changing password for user joeuser. Changing password for joeuser ( current ) UNIX password: (current) UNIX password: Enter your temporary password at this prompt and press enter New UNIX password: Enter your new strong password and press enter Retype new UNIX password: Enter your new strong password again and press enter After you enter your new password for the second time and press enter, the shell may exit automatically. If it doesn't, type exit and press enter Log in again, this time use your new password Congratulations, you should now have a command prompt and be ready to start submitting jobs !!!","title":"Users without a blazerid (collaborators from other universities)"},{"location":"cheaha/getting_started/#hardware","text":"See Hardware for more information.","title":"Hardware"},{"location":"cheaha/getting_started/#cluster-software","text":"BrightCM 7.2 CentOS 7.2 x86_64 Slurm 15.08","title":"Cluster Software"},{"location":"cheaha/getting_started/#queuing-system","text":"All work on Cheaha must be submitted to our queuing system ( Slurm ) . A common mistake made by new users is to run 'jobs' on the login node. This section gives a basic overview of what a queuing system is and why we use it.","title":"Queuing System"},{"location":"cheaha/getting_started/#what-is-a-queuing-system","text":"Software that gives users fair allocation of the cluster's resources Schedules jobs based using resource requests (the following are commonly requested resources, there are many more that are available) Number of processors (often referred to as \"slots\") Maximum memory (RAM) required per slot Maximum run time Common queuing systems: Slurm Sun Grid Engine (Also know as SGE, OGE, GE) OpenPBS Torque LSF (load sharing facility) Slurm is a queue management system and stands for Simple Linux Utility for Resource Management. Slurm was developed at the Lawrence Livermore National Lab and currently runs some of the largest compute clusters in the world. Slurm is now the primary job manager on Cheaha, it replaces SUN Grid Engine ([ SGE ]) the job manager used earlier. Instructions of using SLURM and writing SLURM scripts for jobs submission on Cheaha can be found here .","title":"What is a queuing system?"},{"location":"cheaha/getting_started/#typical-workflow","text":"Stage data to $USER_SCRATCH (your scratch directory) Research how to run your code in \"batch\" mode. Batch mode typically means the ability to run it from the command line without requiring any interaction from the user. Identify the appropriate resources needed to run the job. The following are mandatory resource requests for all jobs on Cheaha Maximum memory (RAM) required per slot Maximum runtime Write a job script specifying queuing system parameters, resource requests and commands to run program Submit script to queuing system (sbatch script.job) Monitor job (squeue) Review the results and resubmit as necessary Clean up the scratch directory by moving or deleting the data off of the cluster","title":"Typical Workflow"},{"location":"cheaha/getting_started/#resource-requests","text":"Accurate resource requests are extremely important to the health of the over all cluster. In order for Cheaha to operate properly, the queing system must know how much runtime and RAM each job will need.","title":"Resource Requests"},{"location":"cheaha/getting_started/#mandatory-resource-requests","text":"-t, --time= Set a limit on the total run time of the job allocation. If the requested time limit exceeds the partition's time limit, the job will be left in a PENDING state (possibly indefinitely). For Array jobs, this represents the maximum run time for each task For serial or parallel jobs, this represents the maximum run time for the entire job --mem-per-cpu= Mimimum memory required per allocated CPU in MegaBytes.","title":"Mandatory Resource Requests"},{"location":"cheaha/getting_started/#other-common-resource-requests","text":"-N, --nodes= Request that a minimum of minnodes nodes be allocated to this job. A maximum node count may also be specified with maxnodes. If only one number is specified, this is used as both the minimum and maximum node count. -n, --ntasks= sbatch does not launch tasks, it requests an allocation of resources and submits a batch script. This option advises the Slurm controller that job steps run within the allocation will launch a maximum of number tasks and to provide for sufficient resources. The default is one task per node --mem= Specify the real memory required per node in MegaBytes. -c, --cpus-per-task= Advise the Slurm controller that ensuing job steps will require ncpus number of processors per task. Without this option, the controller will just try to allocate one processor per task. -p, --partition= Request a specific partition for the resource allocation. Available partitions are: express(max 2 hrs), short(max 12 hrs), medium(max 50 hrs), long(max 150 hrs), sinteractive(0-2 hrs)","title":"Other Common Resource Requests"},{"location":"cheaha/getting_started/#submitting-jobs","text":"Batch Jobs are submitted on Cheaha by using the \"sbatch\" command. The full manual for sbtach is available by running the following command man sbatch","title":"Submitting Jobs"},{"location":"cheaha/getting_started/#job-script-file-format","text":"To submit a job to the queuing systems, you will first define your job in a script (a text file) and then submit that script to the queuing system. The script file needs to be formatted as a UNIX file , not a Windows or Mac text file. In geek speak, this means that the end of line (EOL) character should be a line feed (LF) rather than a carriage return line feed (CRLF) for Windows or carriage return (CR) for Mac. If you submit a job script formatted as a Windows or Mac text file, your job will likely fail with misleading messages, for example that the path specified does not exist. Windows Notepad does not have the ability to save files using the UNIX file format. Do NOT use Notepad to create files intended for use on the clusters. Instead use one of the alternative text editors listed in the following section.","title":"Job Script File Format"},{"location":"cheaha/getting_started/#converting-files-to-unix-format","text":"","title":"Converting Files to UNIX Format"},{"location":"cheaha/getting_started/#dos2unix-method","text":"The lines below that begin with $ are commands, the $ represents the command prompt and should not be typed! The dos2unix program can be used to convert Windows text files to UNIX files with a simple command. After you have copied the file to your home directory on the cluster, you can identify that the file is a Windows file by executing the following (Windows uses CR LF as the line terminator, where UNIX uses only LF and Mac uses only CR): $ file testfile.txt testfile.txt: ASCII text, with CRLF line terminators Now, convert the file to UNIX $ dos2unix testfile.txt dos2unix: converting file testfile.txt to UNIX format ... Verify the conversion using the file command $ file testfile.txt testfile.txt: ASCII text","title":"Dos2Unix Method"},{"location":"cheaha/getting_started/#alternative-windows-text-editors","text":"There are many good text editors available for Windows that have the capability to save files using the UNIX file format. Here are a few: [ Geany ] is an excellent free text editor for Windows and Linux that supports Windows, UNIX and Mac file formats, syntax highlighting and many programming features. To convert from Windows to UNIX click Document click Set Line Endings and then Convert and Set to LF (Unix) [ Notepad++ ] is a great free Windows text editor that supports Windows, UNIX and Mac file formats, syntax highlighting and many programming features. To convert from Windows to UNIX click Format and then click Convert to UNIX Format [ TextPad ] is another excellent Windows text editor. TextPad is not free, however.","title":"Alternative Windows Text Editors"},{"location":"cheaha/getting_started/#example-batch-job-script","text":"A shared cluster environment like Cheaha uses a job scheduler to run tasks on the cluster to provide optimal resource sharing among users. Cheaha uses a job scheduling system call Slurm to schedule and manage jobs. A user needs to tell Slurm about resource requirements (e.g. CPU, memory) so that it can schedule jobs effectively. These resource requirements along with actual application code can be specified in a single file commonly referred as 'Job Script/File'. Following is a simple job script that prints job number and hostname. Note: Jobs must request the appropriate partition (ex: --partition=short ) to satisfy the jobs resource request (maximum runtime, number of compute nodes, etc...) #!/bin/bash # #SBATCH --job-name=test #SBATCH --output=res.txt #SBATCH --ntasks=1 #SBATCH --partition=express #SBATCH --time=10:00 #SBATCH --mem-per-cpu=100 #SBATCH --mail-type=FAIL #SBATCH --mail-user=YOUR_EMAIL_ADDRESS srun hostname srun sleep 60 Lines starting with '#SBATCH' have a special meaning in the Slurm world. Slurm specific configuration options are specified after the '#SBATCH' characters. Above configuration options are useful for most job scripts and for additional configuration options refer to Slurm commands manual. A job script is submitted to the cluster using Slurm specific commands. There are many commands available, but following three commands are the most common: sbatch - to submit job scancel - to delete job squeue - to view job status We can submit above job script using sbatch command: $ sbatch HelloCheaha.sh Submitted batch job 52707 When the job script is submitted, Slurm queues it up and assigns it a job number (e.g. 52707 in above example). The job number is available inside job script using environment variable $JOB_ID. This variable can be used inside job script to create job related directory structure or file names.","title":"Example Batch Job Script"},{"location":"cheaha/getting_started/#interactive-resources","text":"Login Node (the host that you connected to when you setup the SSH connection to Cheaha) is supposed to be used for submitting jobs and/or lighter prep work required for the job scripts. Do not run heavy computations on the login node . If you have a heavier workload to prepare for a batch job (eg. compiling code or other manipulations of data) or your compute application requires interactive control, you should request a dedicated interactive node for this work. Interactive resources are requested by submitting an \"interactive\" job to the scheduler. Interactive jobs will provide you a command line on a compute resource that you can use just like you would the command line on the login node. The difference is that the scheduler has dedicated the requested resources to your job and you can run your interactive commands without having to worry about impacting other users on the login node. Interactive jobs, that can be run on command line, are requested with the srun command. srun --ntasks = 1 --cpus-per-task = 4 --mem-per-cpu = 4096 --time = 08 :00:00 --partition = medium --job-name = JOB_NAME --pty /bin/bash This command requests for 4 cores (--cpus-per-task) for a single task (--ntasks) with each cpu requesting size 4GB of RAM (--mem-per-cpu) for 8 hrs (--time). More advanced interactive scenarios to support graphical applications are available using VNC or X11 tunneling X-Win32 2014 for Windows Interactive jobs that requires running a graphical application, are requested with the sinteractive command, via Terminal on your VNC window. sinteractive --ntasks = 1 --cpus-per-task = 4 --mem-per-cpu = 4096 --time = 08 :00:00 --partition = medium --job-name = JOB_NAME Please note, sinteractive starts your shell in a screen session. Screen is a terminal emulator that is designed to make it possible to detach and reattach a session. This feature can mostly be ignored. If you application uses ctrl-a as a special command sequence (e.g. Emacs), however, you may find the application doesn't receive this special character. When using screen, you need to type ctrl-a a (ctrl-a followed by a single \"a\" key press) to send a ctrl-a to your application. Screen uses ctrl-a as it's own command character, so this special sequence issues the command to screen to \"send ctrl-a to my app\". Learn more about screen from it's documentation .","title":"Interactive Resources"},{"location":"cheaha/getting_started/#storage","text":"","title":"Storage"},{"location":"cheaha/getting_started/#privacy","text":"Do not store sensitive information on this filesystem. It is not encrypted. Note that your data will be stored on the cluster filesystem, and while not accessible to ordinary users, it could be accessible to the cluster administrator(s).","title":"Privacy"},{"location":"cheaha/getting_started/#file-and-directory-permissions","text":"The default permissions for all user data storage locations described below are as follows. In these descriptions, the \"$USER\" variable should be replaced with the user's account name string: /home/$USER - the owner ($USER) of the directory can read, write/delete, and list files. No other users or groups have permissions to this directory. /data/user/$USER - the owner ($USER) of the directory can read, write/delete, and list files. No other users or groups have permissions to this directory. /scratch/$USER - the owner ($USER) of the directory can read, write/delete, and list files. No other users or groups have permissions to this directory. /data/projects/ - a PI can request project space for their lab or specific collaborations. The project directory is created with the PI/requestor as the user-owner and a dedicated collaboration group as the group-owner. The PI and all members of the dedicated collaboration group have can read, write/delete, and list files. No privileges are granted to other users of the system. Additional controls can be implemented via access control lists (ACLs). The PI/requestor can modify the ACLs to allow additional access to specific users. These permissions are the default configuration. While it is possible to modify these permissions or change the group owner of a file to any group to which a user belongs, users are encouraged to work within the default configuration and contact support@listserv.uab.edu if the default permissions are not adequate. Setting up a collaboration group and associated project directory can address most collaboration need while keep data access restricted to the minimum necessary users for the collaboration. Additional background on Linux file system permissions can be found here: https://its.unc.edu/research-computing/techdocs/how-to-use-unix-and-linux-file-permissions/ https://www.rc.fas.harvard.edu/resources/documentation/linux/unix-permissions/ https://hpc.nih.gov/storage/permissions.html","title":"File and Directory Permissions"},{"location":"cheaha/getting_started/#no-automatic-backups","text":"There is no automatic back up of any user data on the cluster in home, data, or scratch. At this time, all user data back up processes are defined and managed by each user and/or lab. Given that data backup demands vary widely between different users, groups, and research domains, this approach enables those who are most familiar with the data to make appropriate decisions based on their specific needs. For example, if a group is working with a large shared data set that is a local copy of a data set maintained authoritatively at a national data bank, maintaining a local backup is unlikely to be a productive use of limited storage resources, since this data could potentially be restored from the authoritative source. If, however, you are maintaining a unique source of data of which yours is the only copy, then maintaining a backup is critical if you value that data set. It's worth noting that while this \"uniqueness\" criteria may not apply to the data you analyze, it may readily apply to the codes that define your analysis pipelines. An often recommended backup policy is the 3-2-1 rule: maintain three copies of data, on two different media, with one copy off-site. You can read more about the 3-2-1 rule here . In the case of your application codes, using revision control tools during development provides an easy way to maintain a second copy, makes for a good software development process, and can help achieve reproducible research goals. Please review the data storage options provided by UAB IT for maintaining copies of your data. In choosing among these options, you should also be aware of UAB's data classification rules and requirements for security requirements for sensitive and restricted data storage. Given the importance of backup, Research Computing continues to explore options to facilitate data backup workflows from the cluster. Please contact us if you have questions or would like to discuss specific data backup scenarios. A good guide for thinking about your backup strategy might be: \"If you aren't managing a data back up process, then you have no backup data.\"","title":"No Automatic Backups"},{"location":"cheaha/getting_started/#home-directories","text":"Your home directory on Cheaha is NFS-mounted to the compute nodes as /home/$USER or $HOME. It is acceptable to use your home directory as a location to store job scripts and custom code. You are responsible for keeping your home directory under 10GB in size! The home directory must not be used to store large amounts of data. Please use $USER_SCRATCH for actively used data sets and $USER_DATA for storage of non scratch data.","title":"Home directories"},{"location":"cheaha/getting_started/#scratch","text":"Research Computing policy requires that all bulky input and output must be located on the scratch space. The home directory is intended to store your job scripts, log files, libraries and other supporting files. Important Information: Scratch space (network and local) is not backed up . Research Computing expects each user to keep their scratch areas clean. The cluster scratch area are not to be used for archiving data. Cheaha has two types of scratch space, network mounted and local. Network scratch ($USER_SCRATCH) is available on the login node and each compute node. This storage is a GPFS high performance file system providing roughly 4.7PB of usable storage. This should be your jobs primary working directory, unless the job would benefit from local scratch (see below). Local scratch is physically located on each compute node and is not accessible to the other nodes (including the login node). This space is useful if the job performs a lot of file I/O. Most of the jobs that run on our clusters do not fall into this category. Because the local scratch is inaccessible outside the job, it is important to note that you must move any data between local scratch to your network accessible scratch within your job. For example, step 1 in the job could be to copy the input from $USER_SCRATCH to ${USER_SCRATCH}, step 2 code execution, step 3 move the data back to $USER_SCRATCH.","title":"Scratch"},{"location":"cheaha/getting_started/#network-scratch","text":"Network scratch is available using the environment variable $USER_SCRATCH or directly by /data/scratch/$USER It is advisable to use the environment variable whenever possible rather than the hard coded path.","title":"Network Scratch"},{"location":"cheaha/getting_started/#local-scratch","text":"Each compute node has a local scratch directory that is accessible via the variable $LOCAL_SCRATCH . If your job performs a lot of file I/O, the job should use $LOCAL_SCRATCH rather than $USER_SCRATCH to prevent bogging down the network scratch file system. The amount of scratch space available is approximately 800GB. The $LOCAL_SCRATCH is a special temporary directory and it's important to note that this directory is deleted when the job completes, so the job script has to move the results to $USER_SCRATCH or other location prior to the job exiting. Note that $LOCAL_SCRATCH is only useful for jobs in which all processes run on the same compute node, so MPI jobs are not candidates for this solution. The following is an array job example that uses $LOCAL_SCRATCH by transferring the inputs into $LOCAL_SCRATCH at the beginning of the script and the result out of $LOCAL_SCRATCH at the end of the script. #!/bin/bash #SBATCH --array=1-10 #SBATCH --share #SBATCH --partition=express # # Name your job to make it easier for you to track # #SBATCH --job-name=R_array_job # # Set your error and output files # #SBATCH --error=R_array_job.err #SBATCH --output=R_array_job.out #SBATCH --ntasks=1 # # Tell the scheduler only need 10 minutes and the appropriate partition # #SBATCH --time=00:10:00 #SBATCH --mem-per-cpu=256 # # Set your email address and request notification when you job is complete or if it fails # #SBATCH --mail-type=FAIL #SBATCH --mail-user=YOUR_EMAIL_ADDRESS module load R/3.2.0-goolf-1.7.20 echo \"TMPDIR: $LOCAL_SCRATCH \" cd $LOCAL_SCRATCH # Create a working directory under the special scheduler local scratch directory # using the array job's taskID mdkir $SLURM_ARRAY_TASK_ID cd $SLURM_ARRAY_TASK_ID # Next copy the input data to the local scratch echo \"Copying input data from network scratch to $LOCAL_SCRATCH / $SLURM_ARRAY_TASK_ID - $( date ) # The input data in this case has a numerical file extension that # matches $SLURM_ARRAY_TASK_ID cp -a $USER_SCRATCH /GeneData/INP*. $SLURM_ARRAY_TASK_ID ./ echo \" copied input data from network scratch to $LOCAL_SCRATCH / $SLURM_ARRAY_TASK_ID - $( date ) someapp -S 1 -D 10 -i INP*. $SLURM_ARRAY_TASK_ID -o geneapp.out. $SLURM_ARRAY_TASK_ID # Lastly copy the results back to network scratch echo \"Copying results from local $LOCAL_SCRATCH / $SLURM_ARRAY_TASK_ID to network - $( date ) cp -a geneapp.out. $SLURM_ARRAY_TASK_ID $USER_SCRATCH /GeneData/ echo \" Copied results from local $LOCAL_SCRATCH / $SLURM_ARRAY_TASK_ID to network - $( date )","title":"Local Scratch"},{"location":"cheaha/getting_started/#project-storage","text":"Cheaha has a location where shared data can be stored called $SHARE_PROJECT. As with user scratch, this area is not backed up ! This is helpful if a team of researchers must access the same data. Please open a help desk ticket to request a project directory under $SHARE_PROJECT.","title":"Project Storage"},{"location":"cheaha/getting_started/#uploading-data","text":"Do not store sensitive information on this filesystem. It is not encrypted. Note that your data will be stored on the cluster filesystem, and while not accessible to ordinary users, it could be accessible to the cluster administrator(s). Data can be moved onto the cluster (pushed) from a remote client (ie. you desktop) via SCP or SFTP. Data can also be downloaded to the cluster (pulled) by issuing transfer commands once you are logged into the cluster. Common transfer methods are wget <URL> , FTP, or SCP, and depend on how the data is made available from the data provider. Large data sets should be staged directly to your $USER_SCRATCH directory so as not to fill up $HOME. If you are working on a data set shared with multiple users, it's preferable to request space in $SHARE_PROJECT rather than duplicating the data for each user.","title":"Uploading Data"},{"location":"cheaha/getting_started/#environment-modules","text":"Environment Modules is installed on Cheaha and should be used when constructing your job scripts if an applicable module file exists. Using the module command you can easily configure your environment for specific software packages without having to know the specific environment variables and values to set. Modules allows you to dynamically configure your environment without having to logout / login for the changes to take affect. If you find that specific software does not have a module, please submit a helpdesk ticket to request the module. Cheaha supports bash completion for the module command. For example, type 'module' and press the TAB key twice to see a list of options: module TAB TAB add display initlist keyword refresh switch use apropos help initprepend list rm unload whatis avail initadd initrm load show unuse clear initclear initswitch purge swap update To see the list of available modulefiles on the cluster, run the module avail command (note the example list below may not be complete!) or module load followed by two tab key presses: module avail ----------------------------------------------------------------------------------------- /cm/shared/modulefiles ----------------------------------------------------------------------------------------- acml/gcc/64/5.3.1 acml/open64-int64/mp/fma4/5.3.1 fftw2/openmpi/gcc/64/float/2.1.5 intel-cluster-runtime/ia32/3.8 netcdf/gcc/64/4.3.3.1 acml/gcc/fma4/5.3.1 blacs/openmpi/gcc/64/1.1patch03 fftw2/openmpi/open64/64/double/2.1.5 intel-cluster-runtime/intel64/3.8 netcdf/open64/64/4.3.3.1 acml/gcc/mp/64/5.3.1 blacs/openmpi/open64/64/1.1patch03 fftw2/openmpi/open64/64/float/2.1.5 intel-cluster-runtime/mic/3.8 netperf/2.7.0 acml/gcc/mp/fma4/5.3.1 blas/gcc/64/3.6.0 fftw3/openmpi/gcc/64/3.3.4 intel-tbb-oss/ia32/44_20160526oss open64/4.5.2.1 acml/gcc-int64/64/5.3.1 blas/open64/64/3.6.0 fftw3/openmpi/open64/64/3.3.4 intel-tbb-oss/intel64/44_20160526oss openblas/dynamic/0.2.15 acml/gcc-int64/fma4/5.3.1 bonnie++/1.97.1 gdb/7.9 iozone/3_434 openmpi/gcc/64/1.10.1 acml/gcc-int64/mp/64/5.3.1 cmgui/7.2 globalarrays/openmpi/gcc/64/5.4 lapack/gcc/64/3.6.0 openmpi/open64/64/1.10.1 acml/gcc-int64/mp/fma4/5.3.1 cuda75/blas/7.5.18 globalarrays/openmpi/open64/64/5.4 lapack/open64/64/3.6.0 pbspro/13.0.2.153173 acml/open64/64/5.3.1 cuda75/fft/7.5.18 hdf5/1.6.10 mpich/ge/gcc/64/3.2 puppet/3.8.4 acml/open64/fma4/5.3.1 cuda75/gdk/352.79 hdf5_18/1.8.16 mpich/ge/open64/64/3.2 rc-base acml/open64/mp/64/5.3.1 cuda75/nsight/7.5.18 hpl/2.1 mpiexec/0.84_432 scalapack/mvapich2/gcc/64/2.0.2 acml/open64/mp/fma4/5.3.1 cuda75/profiler/7.5.18 hwloc/1.10.1 mvapich/gcc/64/1.2rc1 scalapack/openmpi/gcc/64/2.0.2 acml/open64-int64/64/5.3.1 cuda75/toolkit/7.5.18 intel/compiler/32/15.0/2015.5.223 mvapich/open64/64/1.2rc1 sge/2011.11p1 acml/open64-int64/fma4/5.3.1 default-environment intel/compiler/64/15.0/2015.5.223 mvapich2/gcc/64/2.2b slurm/15.08.6 acml/open64-int64/mp/64/5.3.1 fftw2/openmpi/gcc/64/double/2.1.5 intel-cluster-checker/2.2.2 mvapich2/open64/64/2.2b torque/6.0.0.1 ---------------------------------------------------------------------------------------- /share/apps/modulefiles ----------------------------------------------------------------------------------------- rc/BrainSuite/15b rc/freesurfer/freesurfer-5.3.0 rc/intel/compiler/64/ps_2016/2016.0.047 rc/matlab/R2015a rc/SAS/v9.4 rc/cmg/2012.116.G rc/gromacs-intel/5.1.1 rc/Mathematica/10.3 rc/matlab/R2015b rc/dsistudio/dsistudio-20151020 rc/gtool/0.7.5 rc/matlab/R2012a rc/MRIConvert/2.0.8 --------------------------------------------------------------------------------------- /share/apps/rc/modules/all --------------------------------------------------------------------------------------- AFNI/linux_openmp_64-goolf-1.7.20-20160616 gperf/3.0.4-intel-2016a MVAPICH2/2.2b-GCC-4.9.3-2.25 Amber/14-intel-2016a-AmberTools-15-patchlevel-13-13 grep/2.15-goolf-1.4.10 NASM/2.11.06-goolf-1.7.20 annovar/2016Feb01-foss-2015b-Perl-5.22.1 GROMACS/5.0.5-intel-2015b-hybrid NASM/2.11.08-foss-2015b ant/1.9.6-Java-1.7.0_80 GSL/1.16-goolf-1.7.20 NASM/2.11.08-intel-2016a APBS/1.4-linux-static-x86_64 GSL/1.16-intel-2015b NASM/2.12.02-foss-2016a ASHS/rev103_20140612 GSL/2.1-foss-2015b NASM/2.12.02-intel-2015b Aspera-Connect/3.6.1 gtool/0.7.5_linux_x86_64 NASM/2.12.02-intel-2016a ATLAS/3.10.1-gompi-1.5.12-LAPACK-3.4.2 guile/1.8.8-GNU-4.9.3-2.25 ncurses/5.9-foss-2015b Autoconf/2.69-foss-2016a HAPGEN2/2.2.0 ncurses/5.9-GCC-4.8.4 Autoconf/2.69-GCC-4.8.4 HarfBuzz/1.2.7-intel-2016a ncurses/5.9-GNU-4.9.3-2.25 Autoconf/2.69-GNU-4.9.3-2.25 HDF5/1.8.15-patch1-intel-2015b ncurses/5.9-goolf-1.4.10 . . . . Some software packages have multiple module files, for example: GCC/4.7.2 GCC/4.8.1 GCC/4.8.2 GCC/4.8.4 GCC/4.9.2 GCC/4.9.3 GCC/4.9.3-2.25 In this case, the GCC module will always load the latest version, so loading this module is equivalent to loading GCC/4.9.3-2.25. If you always want to use the latest version, use this approach. If you want use a specific version, use the module file containing the appropriate version number. Some modules, when loaded, will actually load other modules. For example, the GROMACS/5.0.5-intel-2015b-hybrid module will also load intel/2015b and other related tools. To load a module, ex: for a GROMACS job, use the following module load command in your job script: module load GROMACS/5.0.5-intel-2015b-hybrid To see a list of the modules that you currently have loaded use the module list command module list Currently Loaded Modulefiles: 1 ) slurm/15.08.6 9 ) impi/5.0.3.048-iccifort-2015.3.187-GNU-4.9.3-2.25 17 ) Tcl/8.6.3-intel-2015b 2 ) rc-base 10 ) iimpi/7.3.5-GNU-4.9.3-2.25 18 ) SQLite/3.8.8.1-intel-2015b 3 ) GCC/4.9.3-binutils-2.25 11 ) imkl/11.2.3.187-iimpi-7.3.5-GNU-4.9.3-2.25 19 ) Tk/8.6.3-intel-2015b-no-X11 4 ) binutils/2.25-GCC-4.9.3-binutils-2.25 12 ) intel/2015b 20 ) Python/2.7.9-intel-2015b 5 ) GNU/4.9.3-2.25 13 ) bzip2/1.0.6-intel-2015b 21 ) Boost/1.58.0-intel-2015b-Python-2.7.9 6 ) icc/2015.3.187-GNU-4.9.3-2.25 14 ) zlib/1.2.8-intel-2015b 22 ) GROMACS/5.0.5-intel-2015b-hybrid 7 ) ifort/2015.3.187-GNU-4.9.3-2.25 15 ) ncurses/5.9-intel-2015b 8 ) iccifort/2015.3.187-GNU-4.9.3-2.25 16 ) libreadline/6.3-intel-2015b A module can be removed from your environment by using the module unload command: module unload GROMACS/5.0.5-intel-2015b-hybrid The definition of a module can also be viewed using the module show command, revealing what a specific module will do to your environment: module show GROMACS/5.0.5-intel-2015b-hybrid ------------------------------------------------------------------- /share/apps/rc/modules/all/GROMACS/5.0.5-intel-2015b-hybrid: module-whatis GROMACS is a versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations of motion for systems with hundreds to millions of particles. - Homepage: http://www.gromacs.org conflict GROMACS prepend-path CPATH /share/apps/rc/software/GROMACS/5.0.5-intel-2015b-hybrid/include prepend-path LD_LIBRARY_PATH /share/apps/rc/software/GROMACS/5.0.5-intel-2015b-hybrid/lib64 prepend-path LIBRARY_PATH /share/apps/rc/software/GROMACS/5.0.5-intel-2015b-hybrid/lib64 prepend-path MANPATH /share/apps/rc/software/GROMACS/5.0.5-intel-2015b-hybrid/share/man prepend-path PATH /share/apps/rc/software/GROMACS/5.0.5-intel-2015b-hybrid/bin prepend-path PKG_CONFIG_PATH /share/apps/rc/software/GROMACS/5.0.5-intel-2015b-hybrid/lib64/pkgconfig setenv EBROOTGROMACS /share/apps/rc/software/GROMACS/5.0.5-intel-2015b-hybrid setenv EBVERSIONGROMACS 5 .0.5 setenv EBDEVELGROMACS /share/apps/rc/software/GROMACS/5.0.5-intel-2015b-hybrid/easybuild/GROMACS-5.0.5-intel-2015b-hybrid-easybuild-devel -------------------------------------------------------------------","title":"Environment Modules"},{"location":"cheaha/getting_started/#error-using-modules-from-a-job-script","text":"If you are using modules and the command your job executes runs fine from the command line but fails when you run it from the job, you may be having an issue with the script initialization. If you see this error in your job error output file -bash: module: line 1 : syntax error: unexpected end of file -bash: error importing function definition for ` BASH_FUNC_module ' Add the command unset module before calling your module files. The -V job argument will cause a conflict with the module function used in your script.","title":"Error Using Modules from a Job Script"},{"location":"cheaha/getting_started/#sample-job-scripts","text":"The following are sample job scripts, please be careful to edit these for your environment (i.e. replace YOUR_EMAIL_ADDRESS with your real email address), set the h_rt to an appropriate runtime limit and modify the job name and any other parameters. Hello World is the classic example used throughout programming. We don't want to buck the system, so we'll use it as well to demonstrate jobs submission with one minor variation: our hello world will send us a greeting using the name of whatever machine it runs on. For example, when run on the Cheaha login node, it would print \"Hello from login001\".","title":"Sample Job Scripts"},{"location":"cheaha/getting_started/#hello-world-serial","text":"A serial job is one that can run independently of other commands, ie. it doesn't depend on the data from other jobs running simultaneously. You can run many serial jobs in any order. This is a common solution to processing lots of data when each command works on a single piece of data. For example, running the same conversion on 100s of images. Here we show how to create job script for one simple command. Running more than one command just requires submitting more jobs. Create your hello world application. Run this command to create a script, turn it into to a command, and run the command (just copy and past the following on to the command line). Create the file: vim helloworld.sh Write into \"helloworld.sh\" file (To write in vim editor: press shift + I ) #!/bin/bash echo Hello from ` hostname ` Save the file by pressing the esc key, type the following :wq Need to give permission the \"helloworld.sh\" file chmod +x helloworld.sh Create the Slurm job script that will request 256 MB RAM and a maximum runtime of 10 minutes. Create the JOB file: vim helloworld.job Write into \"helloworld.job\" file (To write in vim editor: press shift + I ) #!/bin/bash #SBATCH --share #SBATCH --partition=express # # Name your job to make it easier for you to track # #SBATCH --job-name=helloworld # # Set your error and output files # #SBATCH --error=helloworld.err #SBATCH --output=helloworld.out #SBATCH --ntasks=1 # # Tell the scheduler only need 10 minutes # #SBATCH --time=00:10:00 #SBATCH --mem-per-cpu=256 # # Set your email address and request notification when you job is complete or if it fails # #SBATCH --mail-type=FAIL #SBATCH --mail-user=$USER@uab.edu ./helloworld.sh Save the file by pressing the esc key, type the following :wq Submit the job to Slurm scheduler and check the status using squeue $ sbatch helloworld.job Submitted batch job 52888 When the job completes, you should have output files named helloworld.out and helloworld.err $ cat helloworld.out Hello from c0003","title":"Hello World (serial)"},{"location":"cheaha/getting_started/#hello-world-parallel-with-mpi","text":"MPI is used to coordinate the activity of many computations occurring in parallel. It is commonly used in simulation software for molecular dynamics, fluid dynamics, and similar domains where there is significant communication (data) exchanged between cooperating process. Here is a simple parallel Slurm job script for running commands the rely on MPI. This example also includes the example of compiling the code and submitting the job script to the Slurm scheduler. First, create a directory for the Hello World jobs mkdir -p ~/jobs/helloworld cd ~/jobs/helloworld Create the Hello World code written in C (this example of MPI enabled Hello World includes a 3 minute sleep to ensure the job runs for several minutes, a normal hello world example would run in a matter of seconds). $ vi helloworld-mpi.c #include <stdio.h> #include <mpi.h> main ( int argc, char **argv ) { int rank, size ; int i, j ; float f ; MPI_Init ( & argc, & argv ) ; MPI_Comm_rank ( MPI_COMM_WORLD, & rank ) ; MPI_Comm_size ( MPI_COMM_WORLD, & size ) ; printf ( \"Hello World from process %d of %d.\\n\" , rank, size ) ; sleep ( 180 ) ; for ( j = 0 ; j< = 100000 ; j++ ) for ( i = 0 ; i< = 100000 ; i++ ) f = i*2.718281828*i+i+i*3.141592654 ; MPI_Finalize () ; } Compile the code, first purging any modules you may have loaded followed by loading the module for OpenMPI GNU. The mpicc command will compile the code and produce a binary named helloworld_gnu_openmpi module purge module load DefaultModules module load OpenMPI/4.0.1-GCC-8.3.0-2.32 mpicc helloworld-mpi.c -o helloworld_gnu_openmpi Create the Slurm job script that will request 8 cpu slots and a maximum runtime of 10 minutes $ vi helloworld.job #!/bin/bash #SBATCH --share #SBATCH --partition=express # # Name your job to make it easier for you to track # #SBATCH --job-name=helloworld_mpi # # Set your error and output files # #SBATCH --error=helloworld_mpi.err #SBATCH --output=helloworld_mpi.out #SBATCH --ntasks=8 # # Tell the scheduler only need 10 minutes # #SBATCH --time=00:10:00 #SBATCH --mem-per-cpu=256 # # Set your email address and request notification when you job is complete or if it fails # #SBATCH --mail-type=FAIL #SBATCH --mail-user=YOUR_EMAIL_ADDRESS module load OpenMPI/1.8.8-GNU-4.9.3-2.25 mpirun -np $SLURM_NTASKS helloworld_gnu_openmpi Submit the job to Slurm scheduler and check the status using squeue -u $USER $ sbatch helloworld.job Submitted batch job 52893 $ squeue -u BLAZERID JOBID PARTITION NAME USER ST TIME NODES NODELIST ( REASON ) 52893 express hellowor BLAZERID R 2 :07 2 c [ 0005 -0006 ] When the job completes, you should have output files named helloworld_mpi.out and helloworld_mpi.err $ cat helloworld_mpi.out Hello World from process 1 of 8 . Hello World from process 3 of 8 . Hello World from process 4 of 8 . Hello World from process 7 of 8 . Hello World from process 5 of 8 . Hello World from process 6 of 8 . Hello World from process 0 of 8 . Hello World from process 2 of 8 .","title":"Hello World (parallel with MPI)"},{"location":"cheaha/getting_started/#hello-world-serial-revisited","text":"The job submit scripts (sbatch scripts) are actually bash shell scripts in their own right. The reason for using the funky #SBATCH prefix in the scripts is so that bash interprets any such line as a comment and won't execute it. Because the # character starts a comment in bash, we can weave the Slurm scheduler directives (the #SBATCH lines) into standard bash scripts. This lets us build scripts that we can execute locally and then easily run the same script to on a cluster node by calling it with sbatch. This can be used to our advantage to create a more fluid experience in moving between development and production job runs. The following example is a simple variation on the serial job above. All we will do is convert our Slurm job script into a command called helloworld that calls the helloworld.sh command. If the first line of a file is #!/bin/bash and that file is executable, the shell will automatically run the command as if were any other system command, eg. ls. That is, the \".sh\" extension on our HelloWorld.sh script is completely optional and is only meaningful to the user. Copy the serial helloworld.job script to a new file, add a the special #!/bin/bash as the first line, and make it executable with the following command (note: those are single quotes in the echo command): echo '#!/bin/bash' | cat helloworld.job > helloworld ; chmod +x helloworld Our sbatch script has now become a regular command. We can now execute the command with the simple prefix \"./helloworld\", which means \"execute this file in the current directory\": ./helloworld Hello from login001 Or if we want to run the command on a compute node, replace the \"./\" prefix with \"sbatch \": $ sbatch helloworld Submitted batch job 53001 And when the cluster run is complete you can look at the content of the output: $ $ cat helloworld.out Hello from c0003 You can use this approach of treating you sbatch files as command wrappers to build a collection of commands that can be executed locally or via sbatch. The other examples can be restructured similarly. To avoid having to use the \"./\" prefix, just add the current directory to your PATH. Also, if you plan to do heavy development using this feature on the cluster, please be sure to run sinteractive first so you don't load the login node with your development work.","title":"Hello World (serial) -- revisited"},{"location":"cheaha/getting_started/#gromacs","text":"#!/bin/bash #SBATCH --partition=short # # Name your job to make it easier for you to track # #SBATCH --job-name=test_gromacs # # Set your error and output files # #SBATCH --error=test_gromacs.err #SBATCH --output=test_gromacs.out #SBATCH --ntasks=8 # # Tell the scheduler only need 10 minutes # #SBATCH --time=10:00:00 #SBATCH --mem-per-cpu=2048 # # Set your email address and request notification when you job is complete or if it fails # #SBATCH --mail-type=FAIL #SBATCH --mail-user=YOUR_EMAIL_ADDRESS module load OpenMPI/1.8.8-GNU-4.9.3-2.25 module load GROMACS/5.0.5-intel-2015b-hybrid # Change directory to the job working directory if not already there cd ${ USER_SCRATCH } /jobs/gromacs # Single precision MDRUN = mdrun_mpi # Enter your tpr file over here export MYFILE = example.tpr mpirun -np SLURM_NTASKS $MDRUN -v -s $MYFILE -o $MYFILE -c $MYFILE -x $MYFILE -e $MYFILE -g ${ MYFILE } .log","title":"Gromacs"},{"location":"cheaha/getting_started/#r-array-job","text":"The following is an example job script that will use an array of 10 tasks (--array=1-10), each task has a max runtime of 2 hours and will use no more than 256 MB of RAM per task. Array's of tasks are useful when you have lots of simple jobs that work on their own separate files or a sub-set of the problem that can be selected by the array task index. For a more comprehensive introduction please see this tutorial . Create a working directory and the job submission script $ mkdir -p ~/jobs/ArrayExample $ cd ~/jobs/ArrayExample $ vi R-example-array.job #!/bin/bash #SBATCH --array=1-10 #SBATCH --share #SBATCH --partition=express # # Name your job to make it easier for you to track # #SBATCH --job-name=R_array_job # # Set your error and output files # #SBATCH --error=R_array_job.err #SBATCH --output=R_array_job.out #SBATCH --ntasks=1 # # Tell the scheduler only need 10 minutes # #SBATCH --time=00:10:00 #SBATCH --mem-per-cpu=256 # # Set your email address and request notification when you job is complete or if it fails # #SBATCH --mail-type=FAIL #SBATCH --mail-user=YOUR_EMAIL_ADDRESS module load R/3.2.0-goolf-1.7.20 cd ~/jobs/ArrayExample/rep $SLURM_ARRAY_TASK_ID srun R CMD BATCH rscript.R Submit the job to the Slurm scheduler and check the status of the job using the squeue command sbatch R-example-array.job squeue -u $USER","title":"R (array job)"},{"location":"cheaha/getting_started/#array-job-parameterization","text":"Suppose you need to submit thousands of jobs. While you could do this in a for loop, the global limit on jobs in the SLURM queue is 10,000. The limit is in place for performance reasons and the jobs may be rejected with the following error message and an incomplete set of tasks. sbatch: error: Slurm temporarily unable to accept job, sleeping and retrying The preferred way to handle this scenario is to allow SLURM to schedule the jobs for you using the array flag in an sbatch script. This allows many jobs to be submitted as a single entry in the queue, letting SLURM handle the for loop and queueing. It is possible to reference the current loop index, or task id, as $SLURM_ARRAY_TASK_ID. An example using $SLURM_ARRAY_TASK_ID to load input files and create output files is shown below. Suppose you have a short script called my_processing_script that needs to be run on 20,000 separate files. Suppose each instance only needs 1 cpu and 2 GB of RAM and finishes in 5 minutes. Submitting these files all at once won't work and at least half of them will be rejected by SLURM. Instead we can use the sbatch array flag. Note that some other useful flags have been omitted for brevity. #! /bin/bash #SBATCH --partition=express #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=2G #SBATCH --array=1-20000%100 # This will run tasks 1 through 20000, with up to 100 at a time. # It is possible to provide any comma-separated list of intervals. # An example of a valid subset is --array=1,2,5-1000,3777,4995-5000%100 INPUT_FILE = $USER_DATA /input/file_ $SLURM_ARRAY_TASK_ID .txt OUTPUT_FILE = $USER_DATA /output/file_ $SLURM_ARRAY_TASK_ID .txt my_processing_script --input = \" $INPUT_FILE \" --output = \" $OUTPUT_FILE \"","title":"Array Job Parameterization"},{"location":"cheaha/getting_started/#gpu-job","text":"A Graphics processing unit (GPU) is a specialized electronic circuit designed to rapidly manipulate and alter memory to accelerate the creation of images in a frame buffer intended for output to a display device. Create a math.sh file as: $vim math.sh #!/bin/bash ( e = 5 ) echo $e (( e = e + 3 )) echo $e (( e = e+4 )) # -- spaces or no spaces, it doesn't matter echo $e Give File permissions for script as follows: $chmod +x math.sh Create Job submission script file: $vi math.job #!/bin/bash #SBATCH --share #SBATCH --partition=pascalnodes #SBATCH --gres=gpu:1 # Name your job to make it easier for you to track # #SBATCH --job-name=math # # Set your error and output files # #SBATCH --error=math.err #SBATCH --output=math.out #SBATCH --ntasks=1 # # Tell the scheduler only need 10 minutes # #SBATCH --time=00:10:00 #SBATCH --mem-per-cpu=256 # # Set your email address and request notification when you job is complete or if it fails # #SBATCH --mail-type=FAIL #SBATCH --mail-user=$USER@uab.edu ./math.sh Submitting batch script to Slurm scheduler $sbatch math.job We can also request GPU's on cluster as: $sinteractive --ntasks = 1 --time = 00 :10:00 --exclusive --partition = pascalnodes -N2 --gres = gpu:2","title":"GPU JOB"},{"location":"cheaha/getting_started/#gpu-job-with-mpi","text":"As mentioned above, MPI is used to coordinate the activity of many computations occurring in parallel. It is commonly used in simulation software for molecular dynamics, fluid dynamics, and similar domains where there is significant communication (data) exchanged between cooperating process. An example of an GPU job with MPI can be found by visiting this link . Be sure to request the appropiate amount of gpu resources for your job: sinteractive --ntasks = 8 --time = 08 :00:00 --exclusive --partition = pascalnodes -N2 --gres = gpu:4","title":"GPU Job (with MPI)"},{"location":"cheaha/getting_started/#singularity-container","text":"Singularity is designed so that you can use it within SLURM jobs and it does not violate security constraints on the cluster. Singularity was built keeping HPC in mind, i.e a shared environment. Using Singularity container with SLURM job script is very easy, as the containers run as a process on the host machine, just like any other command in a batch script. You just need to load Singularity in your job script and run the command via a singularity process. Here's an example job script below: #!/bin/bash # #SBATCH --job-name=test-singularity #SBATCH --output=res.out #SBATCH --error=res.err # # Number of tasks needed for this job. Generally, used with MPI jobs #SBATCH --ntasks=1 #SBATCH --partition=express # # Time format = HH:MM:SS, DD-HH:MM:SS #SBATCH --time=10:00 # # Number of CPUs allocated to each task. #SBATCH --cpus-per-task=1 # # Mimimum memory required per allocated CPU in MegaBytes. #SBATCH --mem-per-cpu=100 # # Send mail to the email address when the job fails #SBATCH --mail-type=FAIL #SBATCH --mail-user=$USER@uab.edu #Set your environment here module load Singularity/2.5.2-GCC-5.4.0-2.26 #Run your singularity or any other commands here singularity exec -B /data/user/ $USER /data/user/ $USER /rc-training-sessions/neurodebian-neurodebian-master-latest.simg dcm2nii PATH_TO_YOUR_DICOM_FILES For a more comprehensive introduction please see this tutorial .","title":"Singularity Container"},{"location":"cheaha/getting_started/#installed-software","text":"A partial list of installed software with additional instructions for their use is available on the Cheaha Software page.","title":"Installed Software"},{"location":"cheaha/hardware/","text":"Detailed Hardware Information \u00b6 Node Summary \u00b6 The current HPC cluster is comprised of 8192 compute cores connected by low-latency Fourteen Data Rate (FDR) and Enhanced Data Rate (EDR) InfiniBand networks. In addition to the basic compute cores, there are also 72 NVIDIA Tesla P100 GPUs available. A description of the different hardware generations are summarized in the following table: Generation Compute Type Partition Total Cores Total Memory GB Total GPUs Cores Per Node Memory Per Node GB Nodes CPU Info GPU Info 7 gpu pascalnodes 504 4608 72 28 256 18 Intel Xeon E5-2680 v4 2.40 GHz NVIDIA Tesla P100 16 GB 8 cpu cpu 504 4032 24 192 21 Intel Xeon E5-2680 v4 2.50 GHz 8 high memory largemem 240 7680 24 768 10 Intel Xeon E5-2680 v4 2.50 GHz 8 high memory largemem 96 6144 24 1536 4 Intel Xeon E5-2680 v4 2.50 GHz 9 cpu cpu 2496 9984 48 192 52 Intel Xeon Gold 6248R 3.00 GHz 10 cpu cpu 4352 17408 128 512 34 AMD Epyc 7713 Milan 2.00 GHz TOTAL 8192 49856 72 139 TFLOPS \u00b6 The table below is a theoretical analysis based on processor instructions and core counts, and is not a reflection of efficiency in practice. Generation CPU TFLOPS Per Node GPU TFLOPS Per Node TFLOPS Per Node Nodes TFLOPS 7 1.08 17.06 18.14 18 326.43 8 0.96 0.96 21 20.16 8 0.96 0.96 10 9.6 8 0.96 0.96 4 3.84 9 2.30 2.30 52 119.81 10 4.10 4.10 34 139.26 TOTAL 619.1","title":"Hardware"},{"location":"cheaha/hardware/#detailed-hardware-information","text":"","title":"Detailed Hardware Information"},{"location":"cheaha/hardware/#node-summary","text":"The current HPC cluster is comprised of 8192 compute cores connected by low-latency Fourteen Data Rate (FDR) and Enhanced Data Rate (EDR) InfiniBand networks. In addition to the basic compute cores, there are also 72 NVIDIA Tesla P100 GPUs available. A description of the different hardware generations are summarized in the following table: Generation Compute Type Partition Total Cores Total Memory GB Total GPUs Cores Per Node Memory Per Node GB Nodes CPU Info GPU Info 7 gpu pascalnodes 504 4608 72 28 256 18 Intel Xeon E5-2680 v4 2.40 GHz NVIDIA Tesla P100 16 GB 8 cpu cpu 504 4032 24 192 21 Intel Xeon E5-2680 v4 2.50 GHz 8 high memory largemem 240 7680 24 768 10 Intel Xeon E5-2680 v4 2.50 GHz 8 high memory largemem 96 6144 24 1536 4 Intel Xeon E5-2680 v4 2.50 GHz 9 cpu cpu 2496 9984 48 192 52 Intel Xeon Gold 6248R 3.00 GHz 10 cpu cpu 4352 17408 128 512 34 AMD Epyc 7713 Milan 2.00 GHz TOTAL 8192 49856 72 139","title":"Node Summary"},{"location":"cheaha/hardware/#tflops","text":"The table below is a theoretical analysis based on processor instructions and core counts, and is not a reflection of efficiency in practice. Generation CPU TFLOPS Per Node GPU TFLOPS Per Node TFLOPS Per Node Nodes TFLOPS 7 1.08 17.06 18.14 18 326.43 8 0.96 0.96 21 20.16 8 0.96 0.96 10 9.6 8 0.96 0.96 4 3.84 9 2.30 2.30 52 119.81 10 4.10 4.10 34 139.26 TOTAL 619.1","title":"TFLOPS"},{"location":"cheaha/introduction/","text":"Cheaha \u00b6 Cheaha is a High Performance Computing (HPC) resource intended primarily for batch processing. We offer a user-friendly portal website Open OnDemand with graphical interfaces to the most common features, all in one place. Etiquette \u00b6 Quotas are in place to ensure any one user can't monopolize all resources. All expensive compute tasks must be run on compute nodes. Tasks running on the login node slow down processes for everyone, and in extreme cases can cause service outages, affecting your work and the work of many of your colleagues. We will contact you if we find processes on the login node. Don't worry, we're happy to help get your tasks running in the right place with the most efficient resources. You are on compute nodes if \u00b6 using Open OnDemand Interactive Apps using Open OnDemand Job Composer terminal prompt contains something like c0001 You are on the login node if \u00b6 terminal prompt contains something like login001 When do I use need a compute node? If my task \u00b6 takes longer than 60 seconds uses more than one core uses more than 4 GB ram runs multiple times affects more than a few files transfers more than 1 GB over the internet Open OnDemand \u00b6 Our online portal website, Open OnDemand, is available at https://rc.uab.edu . We have more detailed documentation on using Open OnDemand located further in . The portal features a file browser , job composer and various interactive applications including a remote desktop, Jupyter, RStudio and MATLAB, among others. There is also a terminal usable directly in the browser. Slurm \u00b6 Slurm is our job queueing software, and we have documentation further in . More complete documentation is available at https://slurm.schedmd.com/ . Important Expensive compute tasks should only be run on compute nodes. If your task will take longer than For more information please see our [Sbatch Documentation](slurm/sbatch_usage.md).","title":"Cheaha"},{"location":"cheaha/introduction/#cheaha","text":"Cheaha is a High Performance Computing (HPC) resource intended primarily for batch processing. We offer a user-friendly portal website Open OnDemand with graphical interfaces to the most common features, all in one place.","title":"Cheaha"},{"location":"cheaha/introduction/#etiquette","text":"Quotas are in place to ensure any one user can't monopolize all resources. All expensive compute tasks must be run on compute nodes. Tasks running on the login node slow down processes for everyone, and in extreme cases can cause service outages, affecting your work and the work of many of your colleagues. We will contact you if we find processes on the login node. Don't worry, we're happy to help get your tasks running in the right place with the most efficient resources.","title":"Etiquette"},{"location":"cheaha/introduction/#you-are-on-compute-nodes-if","text":"using Open OnDemand Interactive Apps using Open OnDemand Job Composer terminal prompt contains something like c0001","title":"You are on compute nodes if"},{"location":"cheaha/introduction/#you-are-on-the-login-node-if","text":"terminal prompt contains something like login001","title":"You are on the login node if"},{"location":"cheaha/introduction/#when-do-i-use-need-a-compute-node-if-my-task","text":"takes longer than 60 seconds uses more than one core uses more than 4 GB ram runs multiple times affects more than a few files transfers more than 1 GB over the internet","title":"When do I use need a compute node? If my task"},{"location":"cheaha/introduction/#open-ondemand","text":"Our online portal website, Open OnDemand, is available at https://rc.uab.edu . We have more detailed documentation on using Open OnDemand located further in . The portal features a file browser , job composer and various interactive applications including a remote desktop, Jupyter, RStudio and MATLAB, among others. There is also a terminal usable directly in the browser.","title":"Open OnDemand"},{"location":"cheaha/introduction/#slurm","text":"Slurm is our job queueing software, and we have documentation further in . More complete documentation is available at https://slurm.schedmd.com/ . Important Expensive compute tasks should only be run on compute nodes. If your task will take longer than For more information please see our [Sbatch Documentation](slurm/sbatch_usage.md).","title":"Slurm"},{"location":"cheaha/job_efficiency/","text":"Job Efficiency \u00b6 Efficient jobs save you time. Many factors go into queue wait time, but you can control your job requests. Optimizing queue wait times relies on getting resource requests close to actual resource usage. For example, if your task runs as fast with 2 cores as with 4 cores, requesting 4 cores will increase your wait time for no benefit. Other users time will be wasted due to locked up, unused resources. So please read this page to learn how to increase your efficiency and save time. As with any new skill, developing an intuition for efficiency and resource estimation requires experimentation, practice, and feedback. Please DO: run subsets of your data with varying resource requests to develop intuition make use of seff to validate contact us for advice if you're lost Estimating Compute Resources \u00b6 Being able to estimate the resources a job will need is critical. Requesting substantially more resources than necessary bottlenecks the cluster by preventing jobs from using resources that are reserved, but going unused. Of course requesting too few resources may cause the tasks to perform unacceptably slowly, or to fail altogether. Questions to ask yourself before requesting resources: Can my scripts take advantage of multiple cores? If yes, then request more cores. If no, then request only one core. Example: RStudio generally runs on a single thread. Any cores beyond the first will go unused and unusable. How large is the data I'm working with? Start by requesting memory equal to double the size of one file, no less than 2 GB per core. If that isn't enough, increase the request by 50% until there are no more memory errors. Example: If your data file is 4 GB, try starting out by requesting 8 GB of memory, then 12 GB, 16 GB, etc. Do my pipelines keep large amounts of data in memory? If yes, you may need to request even more memory than above. Example: Without careful programming, MATLAB code will often make and retain copies of data until finished. How long should my job take? Example: If my laptop is able to run the code on one data file in 2 hours, it will take about that long on Cheaha. Example: Requesting 50 hours of time for a 15 hour process will lengthen the queue time. Don't request too little! Include a buffer to account for scheduler and network issues. How is the software I'm using programmed? Can it use a GPU? Request one. Can it use multiple cores? Request more than one core. Is it single-threaded? Request only one core. Does it use MPI? Request multiple nodes. Be sure to check all of the flags, configuration, and options for the software, or these changes may not work. Which partition is most appropriate? More than 40 GB memory and queue wait times are long? Try largemem* . Need a GPU? Use pascalnodes* . Software works with AMD? Try amd-hdr100 . Note Reasonable overestimation of resources is better than underestimation. However, gross overestimation may cause admins to contact you about adjusting resources for future jobs. We are happy to help guide you to an efficient usage of the cluster. Use seff to verify that your code is as efficient as possible. Verifying Job Efficiency \u00b6 It's important to evaluate the efficiency of your job in terms of resource usage after it completes. Remember that Cheaha is a shared resource, so requesting resources that sit unused during a job prevents others from using those resources. As well, because each user has a maximum amount of resources they can use at a given time, having inefficient jobs can increase analysis runtime across many jobs, and increase queue wait times. In order to look at job efficieny, use the seff command. seff <jobid> The output will look like: The job had poor CPU efficiency, requesting 2 CPUs which were only busy for 30% of runtime. Requesting only a single core may have made more sense here. The job also had poor memory efficiency, using less than 1 GB total memory of the requested 16 GB (5.73%). For subsequent jobs using a similar analysis and dataset size, decreasing the requested memory to about 1200 MB and a single CPU would be more efficient, and get the job queued faster. Tip Aim for between 75% and 90% memory efficiency. Lower than that is a waste of resources, but too close to 100% could result in job failure due to an unexpected out-of-memory issue.","title":"Job Efficiency"},{"location":"cheaha/job_efficiency/#job-efficiency","text":"Efficient jobs save you time. Many factors go into queue wait time, but you can control your job requests. Optimizing queue wait times relies on getting resource requests close to actual resource usage. For example, if your task runs as fast with 2 cores as with 4 cores, requesting 4 cores will increase your wait time for no benefit. Other users time will be wasted due to locked up, unused resources. So please read this page to learn how to increase your efficiency and save time. As with any new skill, developing an intuition for efficiency and resource estimation requires experimentation, practice, and feedback. Please DO: run subsets of your data with varying resource requests to develop intuition make use of seff to validate contact us for advice if you're lost","title":"Job Efficiency"},{"location":"cheaha/job_efficiency/#estimating-compute-resources","text":"Being able to estimate the resources a job will need is critical. Requesting substantially more resources than necessary bottlenecks the cluster by preventing jobs from using resources that are reserved, but going unused. Of course requesting too few resources may cause the tasks to perform unacceptably slowly, or to fail altogether. Questions to ask yourself before requesting resources: Can my scripts take advantage of multiple cores? If yes, then request more cores. If no, then request only one core. Example: RStudio generally runs on a single thread. Any cores beyond the first will go unused and unusable. How large is the data I'm working with? Start by requesting memory equal to double the size of one file, no less than 2 GB per core. If that isn't enough, increase the request by 50% until there are no more memory errors. Example: If your data file is 4 GB, try starting out by requesting 8 GB of memory, then 12 GB, 16 GB, etc. Do my pipelines keep large amounts of data in memory? If yes, you may need to request even more memory than above. Example: Without careful programming, MATLAB code will often make and retain copies of data until finished. How long should my job take? Example: If my laptop is able to run the code on one data file in 2 hours, it will take about that long on Cheaha. Example: Requesting 50 hours of time for a 15 hour process will lengthen the queue time. Don't request too little! Include a buffer to account for scheduler and network issues. How is the software I'm using programmed? Can it use a GPU? Request one. Can it use multiple cores? Request more than one core. Is it single-threaded? Request only one core. Does it use MPI? Request multiple nodes. Be sure to check all of the flags, configuration, and options for the software, or these changes may not work. Which partition is most appropriate? More than 40 GB memory and queue wait times are long? Try largemem* . Need a GPU? Use pascalnodes* . Software works with AMD? Try amd-hdr100 . Note Reasonable overestimation of resources is better than underestimation. However, gross overestimation may cause admins to contact you about adjusting resources for future jobs. We are happy to help guide you to an efficient usage of the cluster. Use seff to verify that your code is as efficient as possible.","title":"Estimating Compute Resources"},{"location":"cheaha/job_efficiency/#verifying-job-efficiency","text":"It's important to evaluate the efficiency of your job in terms of resource usage after it completes. Remember that Cheaha is a shared resource, so requesting resources that sit unused during a job prevents others from using those resources. As well, because each user has a maximum amount of resources they can use at a given time, having inefficient jobs can increase analysis runtime across many jobs, and increase queue wait times. In order to look at job efficieny, use the seff command. seff <jobid> The output will look like: The job had poor CPU efficiency, requesting 2 CPUs which were only busy for 30% of runtime. Requesting only a single core may have made more sense here. The job also had poor memory efficiency, using less than 1 GB total memory of the requested 16 GB (5.73%). For subsequent jobs using a similar analysis and dataset size, decreasing the requested memory to about 1200 MB and a single CPU would be more efficient, and get the job queued faster. Tip Aim for between 75% and 90% memory efficiency. Lower than that is a waste of resources, but too close to 100% could result in job failure due to an unexpected out-of-memory issue.","title":"Verifying Job Efficiency"},{"location":"cheaha/lmod/","text":"Modules and Applications \u00b6 Most software available on Cheaha is installed as modules, managed by the Lmod system. This document will provide a basic rundown of using Lmod commands to customize a software environment. module is the main command used to interface with module files in Lmod. Listing and Searching Modules \u00b6 To begin, all module commands are run from the terminal. To know what software is installed on Cheaha, use the avail command. module avail If you need to know what software is already loaded in your environment, run: module list If there is specific software you want to search for, you can use the spider subcommand, and provide a string or regular expression to match against. All modules containing the string (case-insensitive) or matching the regular expression will be returned along with their installed versions. # list modules containing string module spider \\< string \\> # list modules matching a regular expression module -r spider \\< regex \\> Loading Modules \u00b6 To load modules, run: module load module1 module2 ... Note If you only specify a module name without an accompanying version tag, the most recently installed version will be loaded into the workspace. If your scripts depend on specific versions of software being used, explicitly load the module version you need. To unload packages, run: module unload package1 package2 ... If you want to revert to the default modules, you can use: module reset","title":"Modules and Applications"},{"location":"cheaha/lmod/#modules-and-applications","text":"Most software available on Cheaha is installed as modules, managed by the Lmod system. This document will provide a basic rundown of using Lmod commands to customize a software environment. module is the main command used to interface with module files in Lmod.","title":"Modules and Applications"},{"location":"cheaha/lmod/#listing-and-searching-modules","text":"To begin, all module commands are run from the terminal. To know what software is installed on Cheaha, use the avail command. module avail If you need to know what software is already loaded in your environment, run: module list If there is specific software you want to search for, you can use the spider subcommand, and provide a string or regular expression to match against. All modules containing the string (case-insensitive) or matching the regular expression will be returned along with their installed versions. # list modules containing string module spider \\< string \\> # list modules matching a regular expression module -r spider \\< regex \\>","title":"Listing and Searching Modules"},{"location":"cheaha/lmod/#loading-modules","text":"To load modules, run: module load module1 module2 ... Note If you only specify a module name without an accompanying version tag, the most recently installed version will be loaded into the workspace. If your scripts depend on specific versions of software being used, explicitly load the module version you need. To unload packages, run: module unload package1 package2 ... If you want to revert to the default modules, you can use: module reset","title":"Loading Modules"},{"location":"cheaha/open_ondemand/ood_files/","text":"File Browser \u00b6 OOD provides an web-based file browser for your files on Cheaha. In order to access it, in the toolbar click Files --> <dir> , where <dir> is one of the choices of your $HOME , $USER_SCRATCH , or $USER_DATA directories. This will open up the following page: This page has a few parts to it: Home directory (red): A link to your $HOME directory and all of its subdirectories for easier navigation. This is always $HOME even if you chose $USER_DATA or $USER_SCRATCH to open. Working directory (green): The absolute path for the current directory you are in along with hyperlinks to the parent directories for easier navigation. File List (black): A list of all file and folders in the working directory along with select information. Hidden files and file permissions can be shown using the radio button in Command Bar at the top right (orange). File Commands (blue): A list of commands to perform to a file or directory. Danger Be careful deleting files here. They will be gone forever! User Commands (orange): A list of commands for navigating in the file browser, file or folder creation, and opening a terminal. User Commands \u00b6 Uploading Data \u00b6 Data can be uploaded from your local machine using this interface. Use the Upload button in the list of User Commands at the top right to select files from your local browser. Additionally, you can drag and drop files from your machine into the File List window as well. This should be limited to small files only. For large files or datasets, please use Globus instead. Opening a Terminal \u00b6 You can also open a bash terminal in the current directory using the >_Open in Terminal command. This should only be used for small tasks when fine-grain user control is necessary because the terminal is running on the login node. For compute-intensive tasks, either request an interactive session in the terminal or request an HPC Desktop session through the Interactive Apps and use the terminal there.","title":"File Browser"},{"location":"cheaha/open_ondemand/ood_files/#file-browser","text":"OOD provides an web-based file browser for your files on Cheaha. In order to access it, in the toolbar click Files --> <dir> , where <dir> is one of the choices of your $HOME , $USER_SCRATCH , or $USER_DATA directories. This will open up the following page: This page has a few parts to it: Home directory (red): A link to your $HOME directory and all of its subdirectories for easier navigation. This is always $HOME even if you chose $USER_DATA or $USER_SCRATCH to open. Working directory (green): The absolute path for the current directory you are in along with hyperlinks to the parent directories for easier navigation. File List (black): A list of all file and folders in the working directory along with select information. Hidden files and file permissions can be shown using the radio button in Command Bar at the top right (orange). File Commands (blue): A list of commands to perform to a file or directory. Danger Be careful deleting files here. They will be gone forever! User Commands (orange): A list of commands for navigating in the file browser, file or folder creation, and opening a terminal.","title":"File Browser"},{"location":"cheaha/open_ondemand/ood_files/#user-commands","text":"","title":"User Commands"},{"location":"cheaha/open_ondemand/ood_files/#uploading-data","text":"Data can be uploaded from your local machine using this interface. Use the Upload button in the list of User Commands at the top right to select files from your local browser. Additionally, you can drag and drop files from your machine into the File List window as well. This should be limited to small files only. For large files or datasets, please use Globus instead.","title":"Uploading Data"},{"location":"cheaha/open_ondemand/ood_files/#opening-a-terminal","text":"You can also open a bash terminal in the current directory using the >_Open in Terminal command. This should only be used for small tasks when fine-grain user control is necessary because the terminal is running on the login node. For compute-intensive tasks, either request an interactive session in the terminal or request an HPC Desktop session through the Interactive Apps and use the terminal there.","title":"Opening a Terminal"},{"location":"cheaha/open_ondemand/ood_interactive/","text":"Interactive Apps \u00b6 The Interactive Apps dropdown from the toolbar will list a few standalone programs you are able to launch directly from the browser as well as an HPC Desktop that will allow you access all of the other software on Cheaha. Currently, the available standalone programs are IGV, Matlab, RStudio, SAS, and Jupyter. All of the interactive apps have similar setup pages. For instance, if we click HPC Desktop, the following screen will appear: This will allow to choose the number of hours, partition, number of cpus, and memory per cpu needed for the job. These fields are common to all interactive apps and are required. Not all partitions are available when creating an interactive job in OOD. For instance, if you need to use the largemem partition, request those resources in a terminal session for an interactive job or submit a batch job. Tip You can decrease wait time in the queue by choosing resources carefully. The closer your request is to actual usage, the more optimal your wait time will be. Please see our section on [Job Efficiency](../job_efficiency.md) for more information. Once you've selected the compute resources you need, Launch the job. This will bring you to the My Interactive Sessions page. This page looks like: There will be basic information about the number of cores and nodes as well as the job ID in the top part of the job card. The amount of time remaining in the job is included in the card as well as a quick link to the file browser in the Session ID field. Click Launch Desktop in new tab to open your interactive VNC session. Note For HPC Desktop, you do not need to request resources after you open the Desktop. You are already on a compute node. Any tasks you run will use the resources you requested when initializing the job. Note You can request another interactive session in a terminal in HPC Desktop. Only the terminal you requested the other interactive session in will have access to the new resources. Everything else in the HPC Desktop will run with the resources you requested when creating the initial job. These interactive jobs can be stopped early by clicking Delete on the right side of the job card. Standalone Programs \u00b6 As shown earlier, some software can be run outside of the VNC session. Setup for most of these follow the same rules as creation of an HPC Desktop job in terms of requesting resources. You will also need to select the version of software to use for the job. Note Versions in OOD and versions seen when loading modules in a terminal may not match. If you need a specific version available in OOD, submit a support ticket at \\<support@listserv.uab.edu\\> Jupyter \u00b6 Jupyter notebooks are available for use in OOD, but some extra setup is required. The extra fields you need to fill out are seen below: At the bottom of the Environment Setup field, you will need to place a module load command to load the version of Anaconda your Jupyter job will be running. View the list of Anaconda modules installed on Cheaha in a terminal session using module spider Anaconda . In addition, if you are using the CUDA cores for GPU-enabled machine learning, you will need to load the corresponding CUDA module here. Use module spider cuda to view the list of CUDA modules. Tip You do not need module load Anaconda3 in the Environment Setup field, it is loaded automatically. Warning Having conda activate statements in the Environment Setup field can cause unexpected and silent job failure. In the Extra Jupyter Arguments field, you will need to add a path to the directory with your jupyter notebooks. For instance, if your notebooks are stored in your user directory, put --notebook-dir=$USER_DATA in this field. You will be able to navigate to the notebook if it is in a subdirectory of notebook-dir . Submitting the job will bring you to the My Interactive Jobs window while the Jupyter job is initialized. Click Connect to Jupyter to open the Jupyter Home Page. Note If you get a Failed to Connect message when opening the job, close the tab and wait a couple of minutes. Jupyter is still initializing and takes some time after the job first begins running. The Jupyter Home Page will look like: From here, you can navigate to and select an existing notebook, or you can create a new one using one of your existing virtual environments or the base environment. Once inside a Jupyter notebook, you can use the Kernel --> Change kernel menu to select your preferred Anaconda environment. Note The ipykernel package must be installed in your preferred environment for it to appear in the Change kernel menu. Tip Anaconda environments used with Open OnDemand Jupyter do not need the jupyter package installed. The server software is already taken care of. Python Libraries and Virtual Environments \u00b6 To run Jupyter with specific libraries and packages outside of the base install, you will need to create a virtual environment first. You can do this either in an HPC Desktop job or in the Conda tab of the Jupyter homepage. The Conda has the following layout: Current environments (red): a listing of the current existing environments in your $HOME/.conda/envs folder. Available packages (green): a list of all packages available to install from conda sources. Installed packages (blue): a list of the packages installed in the currently selected environment. To create a new environment, click the + button at the top of the Current environments pane and enter the name of the environment. After it has been created, you can select packages to install by searching for the package name at the top right of the Available packages pane. After selecting the package, click the -> button, and the package and all its dependencies will be installed. Note If a package is not available using the `conda` command directly, it will not be listed as an available package. Use a terminal window to install the package as necessary. Note In order to use an environment with Jupyter, the `ipykernel` library is necessary. Creating an environment in the Conda tab will autoinstall this library. If using the terminal, use `conda install ipykernel` to install it. After successfully creating your environment, navigate to the Files tab. You can create a new notebook using the New dropdown menu in the top right. Select your virtual environment of choice, and a notebook will be created and opened.","title":"Interactive Apps"},{"location":"cheaha/open_ondemand/ood_interactive/#interactive-apps","text":"The Interactive Apps dropdown from the toolbar will list a few standalone programs you are able to launch directly from the browser as well as an HPC Desktop that will allow you access all of the other software on Cheaha. Currently, the available standalone programs are IGV, Matlab, RStudio, SAS, and Jupyter. All of the interactive apps have similar setup pages. For instance, if we click HPC Desktop, the following screen will appear: This will allow to choose the number of hours, partition, number of cpus, and memory per cpu needed for the job. These fields are common to all interactive apps and are required. Not all partitions are available when creating an interactive job in OOD. For instance, if you need to use the largemem partition, request those resources in a terminal session for an interactive job or submit a batch job. Tip You can decrease wait time in the queue by choosing resources carefully. The closer your request is to actual usage, the more optimal your wait time will be. Please see our section on [Job Efficiency](../job_efficiency.md) for more information. Once you've selected the compute resources you need, Launch the job. This will bring you to the My Interactive Sessions page. This page looks like: There will be basic information about the number of cores and nodes as well as the job ID in the top part of the job card. The amount of time remaining in the job is included in the card as well as a quick link to the file browser in the Session ID field. Click Launch Desktop in new tab to open your interactive VNC session. Note For HPC Desktop, you do not need to request resources after you open the Desktop. You are already on a compute node. Any tasks you run will use the resources you requested when initializing the job. Note You can request another interactive session in a terminal in HPC Desktop. Only the terminal you requested the other interactive session in will have access to the new resources. Everything else in the HPC Desktop will run with the resources you requested when creating the initial job. These interactive jobs can be stopped early by clicking Delete on the right side of the job card.","title":"Interactive Apps"},{"location":"cheaha/open_ondemand/ood_interactive/#standalone-programs","text":"As shown earlier, some software can be run outside of the VNC session. Setup for most of these follow the same rules as creation of an HPC Desktop job in terms of requesting resources. You will also need to select the version of software to use for the job. Note Versions in OOD and versions seen when loading modules in a terminal may not match. If you need a specific version available in OOD, submit a support ticket at \\<support@listserv.uab.edu\\>","title":"Standalone Programs"},{"location":"cheaha/open_ondemand/ood_interactive/#jupyter","text":"Jupyter notebooks are available for use in OOD, but some extra setup is required. The extra fields you need to fill out are seen below: At the bottom of the Environment Setup field, you will need to place a module load command to load the version of Anaconda your Jupyter job will be running. View the list of Anaconda modules installed on Cheaha in a terminal session using module spider Anaconda . In addition, if you are using the CUDA cores for GPU-enabled machine learning, you will need to load the corresponding CUDA module here. Use module spider cuda to view the list of CUDA modules. Tip You do not need module load Anaconda3 in the Environment Setup field, it is loaded automatically. Warning Having conda activate statements in the Environment Setup field can cause unexpected and silent job failure. In the Extra Jupyter Arguments field, you will need to add a path to the directory with your jupyter notebooks. For instance, if your notebooks are stored in your user directory, put --notebook-dir=$USER_DATA in this field. You will be able to navigate to the notebook if it is in a subdirectory of notebook-dir . Submitting the job will bring you to the My Interactive Jobs window while the Jupyter job is initialized. Click Connect to Jupyter to open the Jupyter Home Page. Note If you get a Failed to Connect message when opening the job, close the tab and wait a couple of minutes. Jupyter is still initializing and takes some time after the job first begins running. The Jupyter Home Page will look like: From here, you can navigate to and select an existing notebook, or you can create a new one using one of your existing virtual environments or the base environment. Once inside a Jupyter notebook, you can use the Kernel --> Change kernel menu to select your preferred Anaconda environment. Note The ipykernel package must be installed in your preferred environment for it to appear in the Change kernel menu. Tip Anaconda environments used with Open OnDemand Jupyter do not need the jupyter package installed. The server software is already taken care of.","title":"Jupyter"},{"location":"cheaha/open_ondemand/ood_interactive/#python-libraries-and-virtual-environments","text":"To run Jupyter with specific libraries and packages outside of the base install, you will need to create a virtual environment first. You can do this either in an HPC Desktop job or in the Conda tab of the Jupyter homepage. The Conda has the following layout: Current environments (red): a listing of the current existing environments in your $HOME/.conda/envs folder. Available packages (green): a list of all packages available to install from conda sources. Installed packages (blue): a list of the packages installed in the currently selected environment. To create a new environment, click the + button at the top of the Current environments pane and enter the name of the environment. After it has been created, you can select packages to install by searching for the package name at the top right of the Available packages pane. After selecting the package, click the -> button, and the package and all its dependencies will be installed. Note If a package is not available using the `conda` command directly, it will not be listed as an available package. Use a terminal window to install the package as necessary. Note In order to use an environment with Jupyter, the `ipykernel` library is necessary. Creating an environment in the Conda tab will autoinstall this library. If using the terminal, use `conda install ipykernel` to install it. After successfully creating your environment, navigate to the Files tab. You can create a new notebook using the New dropdown menu in the top right. Select your virtual environment of choice, and a notebook will be created and opened.","title":"Python Libraries and Virtual Environments"},{"location":"cheaha/open_ondemand/ood_jobs/","text":"Job Viewer and Composer \u00b6 Using the Jobs dropdown menu in the toolbar, you can view the status of your current submitted jobs and how long they have been running as well as submit new jobs via the job composer. View Current Jobs \u00b6 Click Jobs > Active Jobs . This will open a new window with you current active jobs that looks like: There are fields such as job ID, job name, time spent active, and the queue or partition. You can sort your job list by any of these fields and can filter for specific jobs using the Filter option at the top right. Additionally, you can view more detailed information about a job by clicking the arrow to the left of the job ID. The resulting table will look like: This table shows extra information such as the total number of nodes, CPUs, time limit, and memory requested for the job. The path to the output file for the job created by SLURM will also be listed. You can open the file location in a file browser or in a terminal here. You can end a currently running job by pressing Delete at the bottom right of these expanded job details. Job Composer \u00b6 The job composer allows you to create SLURM jobs directly in the web interface without having to create a VNC session. Clicking Jobs > Job Composer will bring up a new window: To create a job: Select New Job > From Default Template . This will bring up the job details window pane. Click Open Editor at the bottom of the Job Details. This will open an editable document in another browser window. Paste or type in your script directives including SBATCH options. Once done, click Save in the top left of the editor and close the tab. In the main job window, click Submit , and your job will be submitted to the scheduler. View its status on the Active Jobs page.","title":"Job Viewer and Composer"},{"location":"cheaha/open_ondemand/ood_jobs/#job-viewer-and-composer","text":"Using the Jobs dropdown menu in the toolbar, you can view the status of your current submitted jobs and how long they have been running as well as submit new jobs via the job composer.","title":"Job Viewer and Composer"},{"location":"cheaha/open_ondemand/ood_jobs/#view-current-jobs","text":"Click Jobs > Active Jobs . This will open a new window with you current active jobs that looks like: There are fields such as job ID, job name, time spent active, and the queue or partition. You can sort your job list by any of these fields and can filter for specific jobs using the Filter option at the top right. Additionally, you can view more detailed information about a job by clicking the arrow to the left of the job ID. The resulting table will look like: This table shows extra information such as the total number of nodes, CPUs, time limit, and memory requested for the job. The path to the output file for the job created by SLURM will also be listed. You can open the file location in a file browser or in a terminal here. You can end a currently running job by pressing Delete at the bottom right of these expanded job details.","title":"View Current Jobs"},{"location":"cheaha/open_ondemand/ood_jobs/#job-composer","text":"The job composer allows you to create SLURM jobs directly in the web interface without having to create a VNC session. Clicking Jobs > Job Composer will bring up a new window: To create a job: Select New Job > From Default Template . This will bring up the job details window pane. Click Open Editor at the bottom of the Job Details. This will open an editable document in another browser window. Paste or type in your script directives including SBATCH options. Once done, click Save in the top left of the editor and close the tab. In the main job window, click Submit , and your job will be submitted to the scheduler. View its status on the Active Jobs page.","title":"Job Composer"},{"location":"cheaha/open_ondemand/ood_main/","text":"Homepage \u00b6 Navigating to rc.uab.edu will take you to the OOD homepage: You will find system-wide messages from admins at the tope of the page (red outline). These will always include links to the Research Computing Office Hours on Zoom. This will also be the place to see information about ongoing maintenance. In the middle of the page (green outline), you will see a Message of the Day containing the email address for support if you are having any issues with Cheaha. There are also links to our Acceptable Use Policy as well as links to our documentation. Lastly, there is a table with a list of available SLURM partitions on Cheaha with their max runtime and number of compute nodes per job as well as their priority. Use this table to plan job requests based on your needed computational resources. Toolbar \u00b6 To access all of the features OOD has to offer, use the toolbar at the top of the page that looks like: In it, you will find options to: Directly access your files on Cheaha View currently running jobs Interface with Cheaha via a shell terminal Request interactive sessions To use a shell terminal in Cheaha through OOD, click Clusters >> >_Cheaha Shell Access . You can use this exactly like a standard ssh tunnel. Warning Using the shell terminal in this way puts you on the login node. Do not run any compute tasks on the login node. Request a compute node first!","title":"Homepage"},{"location":"cheaha/open_ondemand/ood_main/#homepage","text":"Navigating to rc.uab.edu will take you to the OOD homepage: You will find system-wide messages from admins at the tope of the page (red outline). These will always include links to the Research Computing Office Hours on Zoom. This will also be the place to see information about ongoing maintenance. In the middle of the page (green outline), you will see a Message of the Day containing the email address for support if you are having any issues with Cheaha. There are also links to our Acceptable Use Policy as well as links to our documentation. Lastly, there is a table with a list of available SLURM partitions on Cheaha with their max runtime and number of compute nodes per job as well as their priority. Use this table to plan job requests based on your needed computational resources.","title":"Homepage"},{"location":"cheaha/open_ondemand/ood_main/#toolbar","text":"To access all of the features OOD has to offer, use the toolbar at the top of the page that looks like: In it, you will find options to: Directly access your files on Cheaha View currently running jobs Interface with Cheaha via a shell terminal Request interactive sessions To use a shell terminal in Cheaha through OOD, click Clusters >> >_Cheaha Shell Access . You can use this exactly like a standard ssh tunnel. Warning Using the shell terminal in this way puts you on the login node. Do not run any compute tasks on the login node. Request a compute node first!","title":"Toolbar"},{"location":"cheaha/slurm/gpu/","text":"GPUs \u00b6 Available Devices \u00b6 Currently, the Cheaha cluster has 18 nodes dedicated to GPU use under the pascalnodes partition family. Each node contains 4 individual NVIDIA P100 GPUs. These GPUs have the following specifications: GPU Architecture NVIDIA Pascal NVIDIA CUDA Cores 3584 GPU Memory 16GB CoWoS HBM2 at 732 GB/s Double-Precision Performance 4.7 TeraFLOPS Single-Precision Performance 9.3 TeraFLOPS Compute APIs CUDA, DirectCompute, OpenCL, OpenACC For more information on these nodes, see Detailed Hardware Information . Scheduling GPUs \u00b6 To successfully request access to GPUs, you will need to set the partition to one of the pascalnodes family of partitions depending on how much time you need for the job. Partition Time Limit pascalnodes 12 hours pascalnodes-medium 50 hours Additionally, when requesting a job using sbatch , you will need to include a SLURM directive --gres=gpu:# where # is the number of GPUs you need. Note It is suggested that at least 2 CPUs are requested for every GPU to begin with. The user should monitor and adjust the number of cores on subsequent job submissions if necessary. Look at [Managing Jobs](job_management.md#managing-jobs) for more information. Open OnDemand \u00b6 When requesting an interactive job through Open OnDemand , selecting the pascalnodes partitions will automatically request access to one GPU as well. There is currently no way to change the number of GPUs for OOD interactive jobs. CUDA Toolkit \u00b6 You will need to load a CUDA toolkit module for relevant commands to access the GPUs. Depending on which version of tensorflow, pytorch, or other similar software you are using, a different version of the CUDA toolkit may be required. For instance, tensorflow version 2.5.0 requires CUDA toolkit version 11.2. Several CUDA toolkit versions have been installed as modules on Cheaha. To see which CUDA toolkits are available, use: module -r spider 'cuda.*toolkit' If a specific version of the CUDA toolkit is needed but not installed, send an install request to [support@listserv.uab.edu].","title":"GPUs"},{"location":"cheaha/slurm/gpu/#gpus","text":"","title":"GPUs"},{"location":"cheaha/slurm/gpu/#available-devices","text":"Currently, the Cheaha cluster has 18 nodes dedicated to GPU use under the pascalnodes partition family. Each node contains 4 individual NVIDIA P100 GPUs. These GPUs have the following specifications: GPU Architecture NVIDIA Pascal NVIDIA CUDA Cores 3584 GPU Memory 16GB CoWoS HBM2 at 732 GB/s Double-Precision Performance 4.7 TeraFLOPS Single-Precision Performance 9.3 TeraFLOPS Compute APIs CUDA, DirectCompute, OpenCL, OpenACC For more information on these nodes, see Detailed Hardware Information .","title":"Available Devices"},{"location":"cheaha/slurm/gpu/#scheduling-gpus","text":"To successfully request access to GPUs, you will need to set the partition to one of the pascalnodes family of partitions depending on how much time you need for the job. Partition Time Limit pascalnodes 12 hours pascalnodes-medium 50 hours Additionally, when requesting a job using sbatch , you will need to include a SLURM directive --gres=gpu:# where # is the number of GPUs you need. Note It is suggested that at least 2 CPUs are requested for every GPU to begin with. The user should monitor and adjust the number of cores on subsequent job submissions if necessary. Look at [Managing Jobs](job_management.md#managing-jobs) for more information.","title":"Scheduling GPUs"},{"location":"cheaha/slurm/gpu/#open-ondemand","text":"When requesting an interactive job through Open OnDemand , selecting the pascalnodes partitions will automatically request access to one GPU as well. There is currently no way to change the number of GPUs for OOD interactive jobs.","title":"Open OnDemand"},{"location":"cheaha/slurm/gpu/#cuda-toolkit","text":"You will need to load a CUDA toolkit module for relevant commands to access the GPUs. Depending on which version of tensorflow, pytorch, or other similar software you are using, a different version of the CUDA toolkit may be required. For instance, tensorflow version 2.5.0 requires CUDA toolkit version 11.2. Several CUDA toolkit versions have been installed as modules on Cheaha. To see which CUDA toolkits are available, use: module -r spider 'cuda.*toolkit' If a specific version of the CUDA toolkit is needed but not installed, send an install request to [support@listserv.uab.edu].","title":"CUDA Toolkit"},{"location":"cheaha/slurm/introduction/","text":"Introduction to SLURM \u00b6 All work on Cheaha must be submitted to the queueing system, Slurm. This doc gives a basic overview of Slurm and how to use it. Slurm is software that gives users fair allocation of the cluster's resources. It schedules jobs based using resource requests such as number of CPUs, maximum memory (RAM) required per CPU, maximum run time, and more. The main Slurm documentation can be found at the Slurm site . The Slurm Quickstart can also be helpful for orienting users new to queueing systems on the cluster. The basic workflow for non-interactive jobs follows: Stage data to $USER_DATA , $USER_SCRATCH , or a project directory. Research how to run your directives in 'batch' mode. In other words, how to run your analysis pipeline from the command line, with no GUIs or user input. Identify the appropriate resources necessary to run the jobs (CPUs, time, memory, etc) Write a job script specifying these parameters using Slurm directives. Submit the job ( sbatch ) Monitor the job ( squeue ) Review the results, and modify/rerun if necessary ( sacct and seff ) Remove data from $USER_SCRATCH","title":"Introduction"},{"location":"cheaha/slurm/introduction/#introduction-to-slurm","text":"All work on Cheaha must be submitted to the queueing system, Slurm. This doc gives a basic overview of Slurm and how to use it. Slurm is software that gives users fair allocation of the cluster's resources. It schedules jobs based using resource requests such as number of CPUs, maximum memory (RAM) required per CPU, maximum run time, and more. The main Slurm documentation can be found at the Slurm site . The Slurm Quickstart can also be helpful for orienting users new to queueing systems on the cluster. The basic workflow for non-interactive jobs follows: Stage data to $USER_DATA , $USER_SCRATCH , or a project directory. Research how to run your directives in 'batch' mode. In other words, how to run your analysis pipeline from the command line, with no GUIs or user input. Identify the appropriate resources necessary to run the jobs (CPUs, time, memory, etc) Write a job script specifying these parameters using Slurm directives. Submit the job ( sbatch ) Monitor the job ( squeue ) Review the results, and modify/rerun if necessary ( sacct and seff ) Remove data from $USER_SCRATCH","title":"Introduction to SLURM"},{"location":"cheaha/slurm/job_management/","text":"Managing Jobs \u00b6 When jobs are submitted, users can monitor their status using Slurm commands. Additionally, users can get information about completed jobs regarding their CPU and memory usage during execution for planning future jobs. Both of these cases should be a regular part of using Cheaha for users. In case jobs were submitted by accident or the code was written incorrectly, they can also be cancelled. Monitoring Jobs \u00b6 Currently running jobs can be monitored using the squeue command. The basic command to list all jobs for a specific user is: squeue -u $USER The output of squeue will look like: This gives the job id, name, run time, partition, user, job status, and number of nodes used for each job a user has submitted. For array jobs, the job id will be formatted as jobid_arrayid . Further information about filtering by job name or partition, including information about memory or number of CPUs, and info regarding messages specific to a job's status can be seen using man squeue . Cancelling Jobs \u00b6 Cancelling queued and currently running jobs can be done using the scancel command. Importantly, this will only cancel jobs that were initiated by the user running the command. scancel is very flexible in how it behaves: # cancel a single job or an entire job array scancel \\< jobid \\> # cancel specific job array IDs, specified as single number or a range scancel \\< jobid_arrayid \\> # cancel all jobs on a partition for the user scancel -p \\< partition \\> # cancel all jobs for a user scancel -u $USER Keep in mind, cancelling all jobs will also cancel the interactive jobs created on the Open OnDemand portal. More information on options to cancel jobs can be seen using man scancel . Reviewing Past Jobs \u00b6 If you are planning a new set of jobs and are estimating resource requests, it is useful to review similar jobs that have already completed. To list past jobs for a user, use the sacct command. Tip To minimize queue wait times and make best use of resources, please review job efficiency using `seff`. See our [Job Efficiency](../job_efficiency.md) page for more information. Review With Job ID \u00b6 The basic form is to use -j along with a job ID to list information about that job. sacct -j [ jobid ] This command will output basic information such as the ID, Name, Partition, Allocated CPUs, and State for the given job ID. Jobs can have matching extern and/or batch job entries as well. These are not especially helpful for most users. You can remove these entries using: sacct -j [ jobid ] | grep -wv -e extern -e batch Review Jobs Submitted Between Specific Timepoints \u00b6 If you do not remember the job ID, you can use the -S and -E flags to retrieve jobs submitted between the given start datetime and end datetime. Valid start/end time formats are: HH:MM[:SS] [AM|PM] MMDD[YY] or MM/DD[/YY] or MM.DD[.YY] MM/DD[/YY]-HH:MM[:SS] YYYY-MM-DD[THH:MM[:SS]] Notes: Anything in [] is optional Times can be specified in either 12-hour with AM/PM or 24-hour For the last specification, the T itself is inserted, it is not replaced with any value. For example, requesting jobs starting after 12:30 PM on October 5, 2021, the form would be 2021-10-05T12:30 . For example, to retrieve jobs submitted during the month of July 2021, the command could be: sacct -S 070121 -E 073121 sacct -S 07 /01/21 -E 07 /31/21 sacct -S 2021 -07-01 -E 2021 -07-31 Customizing the Output \u00b6 You can add -o with a list of output fields to customize the information you see. sacct -j [ jobid ] -o jobid,start,end,state,alloccpu,reqmem This command will output the job ID, the start time, end time, the state, the number of allocated CPUs, and the requested memory for the specified job. All potential output fields can be seen using sacct --helpformat . Their descriptions can be found on the sacct documentation under Job Accounting Fields.","title":"Managing Jobs"},{"location":"cheaha/slurm/job_management/#managing-jobs","text":"When jobs are submitted, users can monitor their status using Slurm commands. Additionally, users can get information about completed jobs regarding their CPU and memory usage during execution for planning future jobs. Both of these cases should be a regular part of using Cheaha for users. In case jobs were submitted by accident or the code was written incorrectly, they can also be cancelled.","title":"Managing Jobs"},{"location":"cheaha/slurm/job_management/#monitoring-jobs","text":"Currently running jobs can be monitored using the squeue command. The basic command to list all jobs for a specific user is: squeue -u $USER The output of squeue will look like: This gives the job id, name, run time, partition, user, job status, and number of nodes used for each job a user has submitted. For array jobs, the job id will be formatted as jobid_arrayid . Further information about filtering by job name or partition, including information about memory or number of CPUs, and info regarding messages specific to a job's status can be seen using man squeue .","title":"Monitoring Jobs"},{"location":"cheaha/slurm/job_management/#cancelling-jobs","text":"Cancelling queued and currently running jobs can be done using the scancel command. Importantly, this will only cancel jobs that were initiated by the user running the command. scancel is very flexible in how it behaves: # cancel a single job or an entire job array scancel \\< jobid \\> # cancel specific job array IDs, specified as single number or a range scancel \\< jobid_arrayid \\> # cancel all jobs on a partition for the user scancel -p \\< partition \\> # cancel all jobs for a user scancel -u $USER Keep in mind, cancelling all jobs will also cancel the interactive jobs created on the Open OnDemand portal. More information on options to cancel jobs can be seen using man scancel .","title":"Cancelling Jobs"},{"location":"cheaha/slurm/job_management/#reviewing-past-jobs","text":"If you are planning a new set of jobs and are estimating resource requests, it is useful to review similar jobs that have already completed. To list past jobs for a user, use the sacct command. Tip To minimize queue wait times and make best use of resources, please review job efficiency using `seff`. See our [Job Efficiency](../job_efficiency.md) page for more information.","title":"Reviewing Past Jobs"},{"location":"cheaha/slurm/job_management/#review-with-job-id","text":"The basic form is to use -j along with a job ID to list information about that job. sacct -j [ jobid ] This command will output basic information such as the ID, Name, Partition, Allocated CPUs, and State for the given job ID. Jobs can have matching extern and/or batch job entries as well. These are not especially helpful for most users. You can remove these entries using: sacct -j [ jobid ] | grep -wv -e extern -e batch","title":"Review With Job ID"},{"location":"cheaha/slurm/job_management/#review-jobs-submitted-between-specific-timepoints","text":"If you do not remember the job ID, you can use the -S and -E flags to retrieve jobs submitted between the given start datetime and end datetime. Valid start/end time formats are: HH:MM[:SS] [AM|PM] MMDD[YY] or MM/DD[/YY] or MM.DD[.YY] MM/DD[/YY]-HH:MM[:SS] YYYY-MM-DD[THH:MM[:SS]] Notes: Anything in [] is optional Times can be specified in either 12-hour with AM/PM or 24-hour For the last specification, the T itself is inserted, it is not replaced with any value. For example, requesting jobs starting after 12:30 PM on October 5, 2021, the form would be 2021-10-05T12:30 . For example, to retrieve jobs submitted during the month of July 2021, the command could be: sacct -S 070121 -E 073121 sacct -S 07 /01/21 -E 07 /31/21 sacct -S 2021 -07-01 -E 2021 -07-31","title":"Review Jobs Submitted Between Specific Timepoints"},{"location":"cheaha/slurm/job_management/#customizing-the-output","text":"You can add -o with a list of output fields to customize the information you see. sacct -j [ jobid ] -o jobid,start,end,state,alloccpu,reqmem This command will output the job ID, the start time, end time, the state, the number of allocated CPUs, and the requested memory for the specified job. All potential output fields can be seen using sacct --helpformat . Their descriptions can be found on the sacct documentation under Job Accounting Fields.","title":"Customizing the Output"},{"location":"cheaha/slurm/sbatch_usage/","text":"Submitting Jobs with Slurm \u00b6 Slurm is simple to use to submit batch jobs. Scripts should be written in an available shell language on Cheaha, typically bash, and should include the appropriate Slurm directives at the top of the script telling the scheduler the requested resources. Common Slurm directives can be seen below along with simple examples for both single batch jobs and array batch jobs. Tip Please see our page on [Job Efficiency](../job_efficiency.md) for more information on making the best use of cluster resources and minimizing queue wait times. Common Slurm Terminology \u00b6 Node: A subdivision of the cluster that contains multiple cores. Login nodes: Controls user access to Cheaha. Low count and shared among all users. DO NOT RUN JOBS ON THE LOGIN NODE Compute nodes: Dedicated nodes for running user jobs. Core: A single CPU Partition: A job queue to submit your job to. Different partitions have different resource limits and priority. Job: Any single or combination of commands that require computational resources to perform. Can be interactive or submitted to the scheduler. Batch jobs: Scripts to submit to the SLURM scheduler. Should run with no user input or graphical user interface (GUI). Replicates commands in an order you would run them on the command line. Basic Slurm Directives \u00b6 Slurm has many directives a researcher can use when creating a job, but a short list of the very common ones are listed here: --job-name : The name of the job that appears when using squeue --ntasks : The number of nodes a job needs --cpus-per-task : The number of cores to request for each task (default:1) --partition : The partition to submit the job to. Partition details can be seen below --time : Amount of time the job is estimated to run for. Acceptable time formats include \"minutes\", \"minutes:seconds\", \"hours:minutes:seconds\", \"days-hours\", \"days-hours:minutes\" and \"days-hours:minutes:seconds\" --mem-per-cpu : Amount of RAM (in MB) needed per CPU. Can specify 4 GB with either 4000 or 4G. --mem can be used to specify the total RAM across all CPUs instead. Requested memory is shared across all CPUs. --output : Path to a file storing the text output of the job commands. --error : Path to an output file if the script errors. For batch jobs, directives are typically included as comments at the top of the script. See examples below. All batch jobs should be submitted using the sbatch command. All directives and more information on how to submit jobs can be seen using man sbatch . Slurm Partitions \u00b6 Partition Nodes Nodes Per User Time Limit Priority Tier Core Count Quota Memory (GB) Quota interactive 52 1 2 hours 20 48 express 52 UNLIMITED 2 hours 20 264 3072 short 52 44 12 hours 16 264 3072 pascalnodes 18 UNLIMITED 12 hours 16 56 500 pascalnodes-medium 7 UNLIMITED 2 days, 0 hours 15 56 500 medium 52 44 2 days, 2 hours 12 264 3072 long 52 5 6 days, 6 hours 8 264 3072 intel-dcb 21 5 6 days, 6 hours 8 264 3072 amd-hdr100 33 5 6 days, 6 hours 8 264 3072 largemem 14 10 2 days, 2 hours 6 290 7168 largemem-long 5 10 6 days, 6 hours 6 290 7168 Notes: Express jobs are highest priority in scheduling meaning they will be scheduled faster Most partitions have a max amount of requestable memory per node at 175 GB. Largemem has a maximum memory limit of 1.5 TB. Pascalnodes are specifically used for access to GPUs Each user has a maximum amount of requestable resources across all jobs. Submitted jobs beyond this resource limit will be kept in the queue until a user's prior jobs have completed. This will appear as QOSMaxResourceLimit in your squeue list. If a script finishes executing before the requested time limit, the job will automatically close and resources will be released. However requesting the max amount of time will cause scheduler priority to decrease. Estimating Compute Resources \u00b6 Being able to estimate how many resources a job will need is critical. Requesting many more resources than necessary bottlenecks the cluster by reserving unused resources for an inefficient job preventing other jobs from using them. However, requesting too few resources will slow down the job or cause it to error. Questions to ask yourself when requesting job resources: Can my scripts take advantage of multiple CPUs? For instance, RStudio only works on a single thread (outside of very specific cases). Requesting more than 1 CPU here would not improve performance. How large is the data I'm working with? Do my pipelines keep large amounts of data in memory? How long should my job take? For example, do not request 50 hours time for a 15 hour process. Have a reasonable buffer included to account for unexpected processing delays, but do not request the maximum time on a partition if that's unnecessary. Note Reasonable overestimation of resources is better than underestimation. However, gross overestimation may cause admins to contact you about adjusting resources for future jobs. After a job is completed, look at how well resources were used using seff . For more information, read job-efficiency . Single Batch Job \u00b6 An example script using some of the listed directives can be seen below: #!/bin/bash # #SBATCH --job-name=test #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --partition=express #SBATCH --time=10:00 #SBATCH --mem-per-cpu=1G #SBATCH --output=test.out echo \"Hello World\" This script requests 1 core on 1 node with 1 GB of RAM on the express partition for 10 minutes. The output of the commands in the script, the echo command here, can be seen in the test.out file that will be created when the script executes. If the script is saved as $HOME/example.sh , it can be submitted using the following command from the command line: sbatch $HOME /example.sh Array Jobs \u00b6 For some analyses, you will want to perform the same operations on different inputs. However, instead of creating individual scripts for each different input, you can create an array job instead. These array jobs duplicate the SBATCH parameters as well as the commands of the script and apply them to different inputs specified by the user. Array jobs can use a Slurm environmental variable, $SLURM_ARRAY_TASK_ID , as an index for inputs. For example, if we have a script that looks like: #!/bin/bash # #SBATCH --job-name=array #SBATCH --output=array_%A_%a.out #SBATCH --time=10:00 #SBATCH --partition=express #SBATCH --ntasks=1 #SBATCH --mem=1G # Print the task id. echo \"My SLURM_ARRAY_TASK_ID: \" $SLURM_ARRAY_TASK_ID In this script, the %A and %a values in the output file name refer to the overall job ID and array task ID, respectively. We can submit the script (named array.sh) using the following command: sbatch --array = 0 -15 array.sh Note It is crucial to note that arrays use 0-based indexing. Array number 0 corresponds to the first job you're running. The `SLURM_ARRAY_TASK_ID` variable will also be 0 in this case. This will cause 16 jobs to be created with array IDs from 0 to 15. Each job will write out the line \"My SLURM_ARRAY_TASK_ID: \" followed by the ID number. Scripts can be written to take advantage of this indexing environmental variable. For example, a project could have a list of participants that should be processed in the same way, and the analysis script uses the array task ID as an index to say which participant is processed in each individual job. Bash, python, MATLAB, and most languages have specific ways of interacting with environmental variables. If you do not want to submit a full array, the --array directive can take a variety of inputs: # submit jobs with index 0, 3, and 7 sbatch --array = 0 ,3,7 array.sh # submit jobs with index 0, 2, 4, and 6 sbatch --array = 0 -6:2 array.sh Additionally, the --array directive can be included with the rest of the SBATCH options in the script itself, although this adds another step if different subsets of the array job need to be run over time. Interactive Jobs \u00b6 Batch jobs are meant to be submitted and not interacted with during execution. However, some jobs need user input during execution or need to use a GUI. Interactive jobs are meant to be used for these situations. It is highly suggested to use the Cheaha Open OnDemand web portal for interactive jobs. Interactive sessions for certain software such as MATLAB and RStudio can be created directly from the browser while an HPC Desktop is available to access all of the other software on Cheaha. If you choose to use a standard ssh connection and VNC for your interactive job, you will need to request resources for your job from the command line after opening the VNC. You can do this using the following command: srun --ntasks = 1 --cpus-per-task = 1 --mem-per-cpu = 4G --time = 1 :00:00 --partition = express --pty /bin/bash Resources should be changed to fit the job's needs. An interactive job will then start on a compute node. You can tell if you are on a compute node by looking at the command line. It should have the form: [blazerid@c0XXX ~] where XXX is a number. Warning If your terminal says `[blazerid@loginXXX ~]`, you are on the login node. NO COMPUTE JOBS SHOULD BE RUN ON THE LOGIN NODE. If jobs are being run on the login node, they will be deleted and the user will be warned. Multiple warnings will result in account suspension.","title":"Submitting Jobs with Slurm"},{"location":"cheaha/slurm/sbatch_usage/#submitting-jobs-with-slurm","text":"Slurm is simple to use to submit batch jobs. Scripts should be written in an available shell language on Cheaha, typically bash, and should include the appropriate Slurm directives at the top of the script telling the scheduler the requested resources. Common Slurm directives can be seen below along with simple examples for both single batch jobs and array batch jobs. Tip Please see our page on [Job Efficiency](../job_efficiency.md) for more information on making the best use of cluster resources and minimizing queue wait times.","title":"Submitting Jobs with Slurm"},{"location":"cheaha/slurm/sbatch_usage/#common-slurm-terminology","text":"Node: A subdivision of the cluster that contains multiple cores. Login nodes: Controls user access to Cheaha. Low count and shared among all users. DO NOT RUN JOBS ON THE LOGIN NODE Compute nodes: Dedicated nodes for running user jobs. Core: A single CPU Partition: A job queue to submit your job to. Different partitions have different resource limits and priority. Job: Any single or combination of commands that require computational resources to perform. Can be interactive or submitted to the scheduler. Batch jobs: Scripts to submit to the SLURM scheduler. Should run with no user input or graphical user interface (GUI). Replicates commands in an order you would run them on the command line.","title":"Common Slurm Terminology"},{"location":"cheaha/slurm/sbatch_usage/#basic-slurm-directives","text":"Slurm has many directives a researcher can use when creating a job, but a short list of the very common ones are listed here: --job-name : The name of the job that appears when using squeue --ntasks : The number of nodes a job needs --cpus-per-task : The number of cores to request for each task (default:1) --partition : The partition to submit the job to. Partition details can be seen below --time : Amount of time the job is estimated to run for. Acceptable time formats include \"minutes\", \"minutes:seconds\", \"hours:minutes:seconds\", \"days-hours\", \"days-hours:minutes\" and \"days-hours:minutes:seconds\" --mem-per-cpu : Amount of RAM (in MB) needed per CPU. Can specify 4 GB with either 4000 or 4G. --mem can be used to specify the total RAM across all CPUs instead. Requested memory is shared across all CPUs. --output : Path to a file storing the text output of the job commands. --error : Path to an output file if the script errors. For batch jobs, directives are typically included as comments at the top of the script. See examples below. All batch jobs should be submitted using the sbatch command. All directives and more information on how to submit jobs can be seen using man sbatch .","title":"Basic Slurm Directives"},{"location":"cheaha/slurm/sbatch_usage/#slurm-partitions","text":"Partition Nodes Nodes Per User Time Limit Priority Tier Core Count Quota Memory (GB) Quota interactive 52 1 2 hours 20 48 express 52 UNLIMITED 2 hours 20 264 3072 short 52 44 12 hours 16 264 3072 pascalnodes 18 UNLIMITED 12 hours 16 56 500 pascalnodes-medium 7 UNLIMITED 2 days, 0 hours 15 56 500 medium 52 44 2 days, 2 hours 12 264 3072 long 52 5 6 days, 6 hours 8 264 3072 intel-dcb 21 5 6 days, 6 hours 8 264 3072 amd-hdr100 33 5 6 days, 6 hours 8 264 3072 largemem 14 10 2 days, 2 hours 6 290 7168 largemem-long 5 10 6 days, 6 hours 6 290 7168 Notes: Express jobs are highest priority in scheduling meaning they will be scheduled faster Most partitions have a max amount of requestable memory per node at 175 GB. Largemem has a maximum memory limit of 1.5 TB. Pascalnodes are specifically used for access to GPUs Each user has a maximum amount of requestable resources across all jobs. Submitted jobs beyond this resource limit will be kept in the queue until a user's prior jobs have completed. This will appear as QOSMaxResourceLimit in your squeue list. If a script finishes executing before the requested time limit, the job will automatically close and resources will be released. However requesting the max amount of time will cause scheduler priority to decrease.","title":"Slurm Partitions"},{"location":"cheaha/slurm/sbatch_usage/#estimating-compute-resources","text":"Being able to estimate how many resources a job will need is critical. Requesting many more resources than necessary bottlenecks the cluster by reserving unused resources for an inefficient job preventing other jobs from using them. However, requesting too few resources will slow down the job or cause it to error. Questions to ask yourself when requesting job resources: Can my scripts take advantage of multiple CPUs? For instance, RStudio only works on a single thread (outside of very specific cases). Requesting more than 1 CPU here would not improve performance. How large is the data I'm working with? Do my pipelines keep large amounts of data in memory? How long should my job take? For example, do not request 50 hours time for a 15 hour process. Have a reasonable buffer included to account for unexpected processing delays, but do not request the maximum time on a partition if that's unnecessary. Note Reasonable overestimation of resources is better than underestimation. However, gross overestimation may cause admins to contact you about adjusting resources for future jobs. After a job is completed, look at how well resources were used using seff . For more information, read job-efficiency .","title":"Estimating Compute Resources"},{"location":"cheaha/slurm/sbatch_usage/#single-batch-job","text":"An example script using some of the listed directives can be seen below: #!/bin/bash # #SBATCH --job-name=test #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --partition=express #SBATCH --time=10:00 #SBATCH --mem-per-cpu=1G #SBATCH --output=test.out echo \"Hello World\" This script requests 1 core on 1 node with 1 GB of RAM on the express partition for 10 minutes. The output of the commands in the script, the echo command here, can be seen in the test.out file that will be created when the script executes. If the script is saved as $HOME/example.sh , it can be submitted using the following command from the command line: sbatch $HOME /example.sh","title":"Single Batch Job"},{"location":"cheaha/slurm/sbatch_usage/#array-jobs","text":"For some analyses, you will want to perform the same operations on different inputs. However, instead of creating individual scripts for each different input, you can create an array job instead. These array jobs duplicate the SBATCH parameters as well as the commands of the script and apply them to different inputs specified by the user. Array jobs can use a Slurm environmental variable, $SLURM_ARRAY_TASK_ID , as an index for inputs. For example, if we have a script that looks like: #!/bin/bash # #SBATCH --job-name=array #SBATCH --output=array_%A_%a.out #SBATCH --time=10:00 #SBATCH --partition=express #SBATCH --ntasks=1 #SBATCH --mem=1G # Print the task id. echo \"My SLURM_ARRAY_TASK_ID: \" $SLURM_ARRAY_TASK_ID In this script, the %A and %a values in the output file name refer to the overall job ID and array task ID, respectively. We can submit the script (named array.sh) using the following command: sbatch --array = 0 -15 array.sh Note It is crucial to note that arrays use 0-based indexing. Array number 0 corresponds to the first job you're running. The `SLURM_ARRAY_TASK_ID` variable will also be 0 in this case. This will cause 16 jobs to be created with array IDs from 0 to 15. Each job will write out the line \"My SLURM_ARRAY_TASK_ID: \" followed by the ID number. Scripts can be written to take advantage of this indexing environmental variable. For example, a project could have a list of participants that should be processed in the same way, and the analysis script uses the array task ID as an index to say which participant is processed in each individual job. Bash, python, MATLAB, and most languages have specific ways of interacting with environmental variables. If you do not want to submit a full array, the --array directive can take a variety of inputs: # submit jobs with index 0, 3, and 7 sbatch --array = 0 ,3,7 array.sh # submit jobs with index 0, 2, 4, and 6 sbatch --array = 0 -6:2 array.sh Additionally, the --array directive can be included with the rest of the SBATCH options in the script itself, although this adds another step if different subsets of the array job need to be run over time.","title":"Array Jobs"},{"location":"cheaha/slurm/sbatch_usage/#interactive-jobs","text":"Batch jobs are meant to be submitted and not interacted with during execution. However, some jobs need user input during execution or need to use a GUI. Interactive jobs are meant to be used for these situations. It is highly suggested to use the Cheaha Open OnDemand web portal for interactive jobs. Interactive sessions for certain software such as MATLAB and RStudio can be created directly from the browser while an HPC Desktop is available to access all of the other software on Cheaha. If you choose to use a standard ssh connection and VNC for your interactive job, you will need to request resources for your job from the command line after opening the VNC. You can do this using the following command: srun --ntasks = 1 --cpus-per-task = 1 --mem-per-cpu = 4G --time = 1 :00:00 --partition = express --pty /bin/bash Resources should be changed to fit the job's needs. An interactive job will then start on a compute node. You can tell if you are on a compute node by looking at the command line. It should have the form: [blazerid@c0XXX ~] where XXX is a number. Warning If your terminal says `[blazerid@loginXXX ~]`, you are on the login node. NO COMPUTE JOBS SHOULD BE RUN ON THE LOGIN NODE. If jobs are being run on the login node, they will be deleted and the user will be warned. Multiple warnings will result in account suspension.","title":"Interactive Jobs"},{"location":"data_management/s3/","text":"Under construction.....","title":"Long-Term Storage"},{"location":"data_management/storage/","text":"Storage \u00b6 Privacy \u00b6 Do not store sensitive information on this filesystem. It is not encrypted. Note that your data will be stored on the cluster filesystem, and while not accessible to ordinary users, it could be accessible to the cluster administrator(s). No Automatic Backups \u00b6 There is no automatic back up of any user data on the cluster in home, data, or scratch. At this time, all user data back up processes are defined and managed by each user and/or lab. Given that data backup demands vary widely between different users, groups, and research domains, this approach enables those who are most familiar with the data to make appropriate decisions based on their specific needs. For example, if a group is working with a large shared data set that is a local copy of a data set maintained authoritatively at a national data bank, maintaining a local backup is unlikely to be a productive use of limited storage resources, since this data could potentially be restored from the authoritative source. If, however, you are maintaining a unique source of data of which yours is the only copy, then maintaining a backup is critical if you value that data set. It's worth noting that while this \"uniqueness\" criteria may not apply to the data you analyze, it may readily apply to the codes that define your analysis pipelines. An often recommended backup policy is the 3-2-1 rule: maintain three copies of data, on two different media, with one copy off-site. You can read more about the 3-2-1 rule here . In the case of your application codes, using revision control tools during development provides an easy way to maintain a second copy, makes for a good software development process, and can help achieve reproducible research goals. Please review the data storage options provided by UAB IT for maintaining copies of your data. In choosing among these options, you should also be aware of UAB's data classification rules and requirements for security requirements for sensitive and restricted data storage. Given the importance of backup, Research Computing continues to explore options to facilitate data backup workflows from the cluster. Please contact us if you have questions or would like to discuss specific data backup scenarios. Directories on Cheaha \u00b6 Users are provided a high performance GPFS file system to store data, toolboxes, and other supporting files. The specific directories a user can access are described below. In these descriptions, the \"$USER\" variable should be replaced with the user's account name string. Home Directory \u00b6 Each user has a personal directory found at /home/$USER (or $HOME ). This is traditionally meant to store scripts and supporting files and toolboxes such as those relating to Anaconda virtual environments or R packages. The owner ($USER) of the directory can read, write/delete, and list files. No other users or groups have permissions to this directory. A user is limited to 5 TB of data across both their home directory and their user data directory (see below). User Data Directory \u00b6 Each user has another directory found at /data/user/$USER (or $USER_DATA ) that can store datasets and results for a user's projects. The owner ($USER) of the directory can read, write/delete, and list files. No other users or groups have permissions to this directory. A user is limited to 5 TB of data across both their home directory (see above)and their user data directory. Note The home and user data directories are mirrored across storage locations to allow for emergency backup in case some of the drives fail. This is not meant to be a long-term backup solution as any data deleted by a user is deleted on the main drive and the mirrored drive. The mirrored system technically allows for over 5 TB of data to be stored but data cannot be recovered in case of an emergency storage failure. For data safety, do not store over 5 TB of data across user data and home directories. Project Directory \u00b6 Shared data can be stored in a /data/project/<project_name> directory. The default storage size for a new project is 50TB. As with user scratch, this area is not backed up ! This is helpful if a team of researchers must access the same data. A PI can open a help desk ticket to request a project directory under /data/project . In order to add or remove a user's access to a project directory, the PI who requested the project space must create a support ticket. The PI and all members of the dedicated collaboration group have can read, write/delete, and list files. No privileges are granted to other users of the system. Additional controls can be implemented via access control lists (see the bash commands setfacl and getfacl ). The PI/requestor can modify the ACLs to allow additional access to specific users. Sloss \u00b6 A special location under /data/project/sloss to store projects that are, at most, a few TB large for access across multiple researchers. Essentially a foundry for project spaces that start small but may grow and graduate into a full-fledged project space. Scratch \u00b6 Two types of scratch space are provided for analyses currently being ran, network-mounted and local. These are spaces shared across users (though one user still cannot access another user's files without permission) and as such, data should be moved out of scratch when the analysis is finished. Note Scratch space (network and local) **is not backed up**. Network Scratch \u00b6 All users have access to a large, temporary, work-in-progress directory for storing data, called a scratch directory in /data/scratch/$USER or $USER_SCRATCH . Use this directory to store very large datasets for a short period of time and to run your jobs. The maximum amount of data a single user can store in network scratch is 100 TB at once. Network scratch is available on the login node and each compute node. This storage is a GPFS high performance file system providing roughly 1 PB of network scratch storage. If using scratch, this should be your jobs' primary working directory, unless the job would benefit from local scratch (see below). Warning Research Computing expects each user to keep their scratch areas clean. **The cluster scratch areas are not to be used for archiving data.** In order to keep scratch clear and usable for everyone, files older than 28 days will be automatically deleted. Local Scratch \u00b6 Each compute node has a local scratch directory that is accessible via the variable $LOCAL_SCRATCH . If your job performs a lot of file I/O, the job should use $LOCAL_SCRATCH rather than $USER_SCRATCH to prevent bogging down the network scratch file system. It's important to recognize most jobs run on the cluster do not fall under this category. The amount of scratch space available is approximately 800GB. The $LOCAL_SCRATCH is a special temporary directory and it's important to note that this directory is deleted when the job completes, so the job script has to move the results to $USER_SCRATCH or other location prior to the job exiting. Note that $LOCAL_SCRATCH is only useful for jobs in which all processes run on the same compute node, so MPI jobs are not candidates for this solution. Use the #SBATCH --nodes=1 slurm directive to specify that all requested cores are on the same node. The following is an array job example that uses $LOCAL_SCRATCH by transferring the inputs into $LOCAL_SCRATCH at the beginning of the script and the result out of $LOCAL_SCRATCH at the end of the script. #!/bin/bash #SBATCH --array=1-10 #SBATCH --share #SBATCH --partition=express # # Name your job to make it easier for you to track # #SBATCH --job-name=R_array_job # # Set your error and output files # #SBATCH --error=R_array_job.err #SBATCH --output=R_array_job.out #SBATCH --ntasks=1 #SBATCH --nodes=1 # # Tell the scheduler only need 10 minutes and the appropriate partition # #SBATCH --time=00:10:00 #SBATCH --mem-per-cpu=256 # # Set your email address and request notification when you job is complete or if it fails # #SBATCH --mail-type=FAIL #SBATCH --mail-user=YOUR_EMAIL_ADDRESS module load R/3.2.0-goolf-1.7.20 echo \"TMPDIR: $LOCAL_SCRATCH \" cd $LOCAL_SCRATCH # Create a working directory under the special scheduler local scratch directory # using the array job's taskID mdkir $SLURM_ARRAY_TASK_ID cd $SLURM_ARRAY_TASK_ID # Next copy the input data to the local scratch echo \"Copying input data from network scratch to $LOCAL_SCRATCH / $SLURM_ARRAY_TASK_ID - $( date ) # The input data in this case has a numerical file extension that # matches $SLURM_ARRAY_TASK_ID cp -a $USER_SCRATCH /GeneData/INP*. $SLURM_ARRAY_TASK_ID ./ echo \" copied input data from network scratch to $LOCAL_SCRATCH / $SLURM_ARRAY_TASK_ID - $( date ) someapp -S 1 -D 10 -i INP*. $SLURM_ARRAY_TASK_ID -o geneapp.out. $SLURM_ARRAY_TASK_ID # Lastly copy the results back to network scratch echo \"Copying results from local $LOCAL_SCRATCH / $SLURM_ARRAY_TASK_ID to network - $( date ) cp -a geneapp.out. $SLURM_ARRAY_TASK_ID $USER_SCRATCH /GeneData/ echo \" Copied results from local $LOCAL_SCRATCH / $SLURM_ARRAY_TASK_ID to network - $( date ) Directory Permissions \u00b6 Default file permissions are described for each directory above. Additional background on Linux file system permissions can be found here: https://its.unc.edu/research-computing/techdocs/how-to-use-unix-and-linux-file-permissions/ https://www.rc.fas.harvard.edu/resources/documentation/linux/unix-permissions/ https://hpc.nih.gov/storage/permissions.html","title":"Storage"},{"location":"data_management/storage/#storage","text":"","title":"Storage"},{"location":"data_management/storage/#privacy","text":"Do not store sensitive information on this filesystem. It is not encrypted. Note that your data will be stored on the cluster filesystem, and while not accessible to ordinary users, it could be accessible to the cluster administrator(s).","title":"Privacy"},{"location":"data_management/storage/#no-automatic-backups","text":"There is no automatic back up of any user data on the cluster in home, data, or scratch. At this time, all user data back up processes are defined and managed by each user and/or lab. Given that data backup demands vary widely between different users, groups, and research domains, this approach enables those who are most familiar with the data to make appropriate decisions based on their specific needs. For example, if a group is working with a large shared data set that is a local copy of a data set maintained authoritatively at a national data bank, maintaining a local backup is unlikely to be a productive use of limited storage resources, since this data could potentially be restored from the authoritative source. If, however, you are maintaining a unique source of data of which yours is the only copy, then maintaining a backup is critical if you value that data set. It's worth noting that while this \"uniqueness\" criteria may not apply to the data you analyze, it may readily apply to the codes that define your analysis pipelines. An often recommended backup policy is the 3-2-1 rule: maintain three copies of data, on two different media, with one copy off-site. You can read more about the 3-2-1 rule here . In the case of your application codes, using revision control tools during development provides an easy way to maintain a second copy, makes for a good software development process, and can help achieve reproducible research goals. Please review the data storage options provided by UAB IT for maintaining copies of your data. In choosing among these options, you should also be aware of UAB's data classification rules and requirements for security requirements for sensitive and restricted data storage. Given the importance of backup, Research Computing continues to explore options to facilitate data backup workflows from the cluster. Please contact us if you have questions or would like to discuss specific data backup scenarios.","title":"No Automatic Backups"},{"location":"data_management/storage/#directories-on-cheaha","text":"Users are provided a high performance GPFS file system to store data, toolboxes, and other supporting files. The specific directories a user can access are described below. In these descriptions, the \"$USER\" variable should be replaced with the user's account name string.","title":"Directories on Cheaha"},{"location":"data_management/storage/#home-directory","text":"Each user has a personal directory found at /home/$USER (or $HOME ). This is traditionally meant to store scripts and supporting files and toolboxes such as those relating to Anaconda virtual environments or R packages. The owner ($USER) of the directory can read, write/delete, and list files. No other users or groups have permissions to this directory. A user is limited to 5 TB of data across both their home directory and their user data directory (see below).","title":"Home Directory"},{"location":"data_management/storage/#user-data-directory","text":"Each user has another directory found at /data/user/$USER (or $USER_DATA ) that can store datasets and results for a user's projects. The owner ($USER) of the directory can read, write/delete, and list files. No other users or groups have permissions to this directory. A user is limited to 5 TB of data across both their home directory (see above)and their user data directory. Note The home and user data directories are mirrored across storage locations to allow for emergency backup in case some of the drives fail. This is not meant to be a long-term backup solution as any data deleted by a user is deleted on the main drive and the mirrored drive. The mirrored system technically allows for over 5 TB of data to be stored but data cannot be recovered in case of an emergency storage failure. For data safety, do not store over 5 TB of data across user data and home directories.","title":"User Data Directory"},{"location":"data_management/storage/#project-directory","text":"Shared data can be stored in a /data/project/<project_name> directory. The default storage size for a new project is 50TB. As with user scratch, this area is not backed up ! This is helpful if a team of researchers must access the same data. A PI can open a help desk ticket to request a project directory under /data/project . In order to add or remove a user's access to a project directory, the PI who requested the project space must create a support ticket. The PI and all members of the dedicated collaboration group have can read, write/delete, and list files. No privileges are granted to other users of the system. Additional controls can be implemented via access control lists (see the bash commands setfacl and getfacl ). The PI/requestor can modify the ACLs to allow additional access to specific users.","title":"Project Directory"},{"location":"data_management/storage/#sloss","text":"A special location under /data/project/sloss to store projects that are, at most, a few TB large for access across multiple researchers. Essentially a foundry for project spaces that start small but may grow and graduate into a full-fledged project space.","title":"Sloss"},{"location":"data_management/storage/#scratch","text":"Two types of scratch space are provided for analyses currently being ran, network-mounted and local. These are spaces shared across users (though one user still cannot access another user's files without permission) and as such, data should be moved out of scratch when the analysis is finished. Note Scratch space (network and local) **is not backed up**.","title":"Scratch"},{"location":"data_management/storage/#network-scratch","text":"All users have access to a large, temporary, work-in-progress directory for storing data, called a scratch directory in /data/scratch/$USER or $USER_SCRATCH . Use this directory to store very large datasets for a short period of time and to run your jobs. The maximum amount of data a single user can store in network scratch is 100 TB at once. Network scratch is available on the login node and each compute node. This storage is a GPFS high performance file system providing roughly 1 PB of network scratch storage. If using scratch, this should be your jobs' primary working directory, unless the job would benefit from local scratch (see below). Warning Research Computing expects each user to keep their scratch areas clean. **The cluster scratch areas are not to be used for archiving data.** In order to keep scratch clear and usable for everyone, files older than 28 days will be automatically deleted.","title":"Network Scratch"},{"location":"data_management/storage/#local-scratch","text":"Each compute node has a local scratch directory that is accessible via the variable $LOCAL_SCRATCH . If your job performs a lot of file I/O, the job should use $LOCAL_SCRATCH rather than $USER_SCRATCH to prevent bogging down the network scratch file system. It's important to recognize most jobs run on the cluster do not fall under this category. The amount of scratch space available is approximately 800GB. The $LOCAL_SCRATCH is a special temporary directory and it's important to note that this directory is deleted when the job completes, so the job script has to move the results to $USER_SCRATCH or other location prior to the job exiting. Note that $LOCAL_SCRATCH is only useful for jobs in which all processes run on the same compute node, so MPI jobs are not candidates for this solution. Use the #SBATCH --nodes=1 slurm directive to specify that all requested cores are on the same node. The following is an array job example that uses $LOCAL_SCRATCH by transferring the inputs into $LOCAL_SCRATCH at the beginning of the script and the result out of $LOCAL_SCRATCH at the end of the script. #!/bin/bash #SBATCH --array=1-10 #SBATCH --share #SBATCH --partition=express # # Name your job to make it easier for you to track # #SBATCH --job-name=R_array_job # # Set your error and output files # #SBATCH --error=R_array_job.err #SBATCH --output=R_array_job.out #SBATCH --ntasks=1 #SBATCH --nodes=1 # # Tell the scheduler only need 10 minutes and the appropriate partition # #SBATCH --time=00:10:00 #SBATCH --mem-per-cpu=256 # # Set your email address and request notification when you job is complete or if it fails # #SBATCH --mail-type=FAIL #SBATCH --mail-user=YOUR_EMAIL_ADDRESS module load R/3.2.0-goolf-1.7.20 echo \"TMPDIR: $LOCAL_SCRATCH \" cd $LOCAL_SCRATCH # Create a working directory under the special scheduler local scratch directory # using the array job's taskID mdkir $SLURM_ARRAY_TASK_ID cd $SLURM_ARRAY_TASK_ID # Next copy the input data to the local scratch echo \"Copying input data from network scratch to $LOCAL_SCRATCH / $SLURM_ARRAY_TASK_ID - $( date ) # The input data in this case has a numerical file extension that # matches $SLURM_ARRAY_TASK_ID cp -a $USER_SCRATCH /GeneData/INP*. $SLURM_ARRAY_TASK_ID ./ echo \" copied input data from network scratch to $LOCAL_SCRATCH / $SLURM_ARRAY_TASK_ID - $( date ) someapp -S 1 -D 10 -i INP*. $SLURM_ARRAY_TASK_ID -o geneapp.out. $SLURM_ARRAY_TASK_ID # Lastly copy the results back to network scratch echo \"Copying results from local $LOCAL_SCRATCH / $SLURM_ARRAY_TASK_ID to network - $( date ) cp -a geneapp.out. $SLURM_ARRAY_TASK_ID $USER_SCRATCH /GeneData/ echo \" Copied results from local $LOCAL_SCRATCH / $SLURM_ARRAY_TASK_ID to network - $( date )","title":"Local Scratch"},{"location":"data_management/storage/#directory-permissions","text":"Default file permissions are described for each directory above. Additional background on Linux file system permissions can be found here: https://its.unc.edu/research-computing/techdocs/how-to-use-unix-and-linux-file-permissions/ https://www.rc.fas.harvard.edu/resources/documentation/linux/unix-permissions/ https://hpc.nih.gov/storage/permissions.html","title":"Directory Permissions"},{"location":"data_management/transfer/filezilla/","text":"FileZilla \u00b6 Filezilla is a free SFTP platform used to transfer data between a local machine and a remote server, in this case remote storage accessible to Cheaha and UAB Cloud or long-term S3 storage. Filezilla is useful for medium sized data transfers from a local machine as opposed to Globus which can easily connect two different local or remote servers and handle large quantities of data. Installation \u00b6 To download the program, go to the FileZilla site and click Download FileZilla Client. Filezilla is also already installed on Cheaha and can be accessed through the Accessories menu. Using FileZilla \u00b6 Once FileZilla is installed and you open it, you will see the following window A file browser for the local machine FileZilla is running on is on the left while the file system for the remote site will be shown on the right once a remote site has been connected. Creating a Remote Connection \u00b6 You can easily connect to a remote site using the QuickConnect bar near the top of the window. You will need to input the following options: Host: sftp://cheaha.rc.uab.edu Username: your BlazerID or XIAS ID (do NOT include '@uab.edu') Password: your BlazerID or XIAS password Port: 22 Click Quickconnect and you will be connected to the remote storage system. The window should now look like: When connecting in the future, you will be able to select the connection from the dropdown arrow next to the Quickconnect button. In both the local and remote panes, you can navigate to the directories you are transferring from and to. You only have access to directories you can normally access on Cheaha, so your user space as well as any project directories you have been added to. Transferring Data \u00b6 From here you can drag and drop whichever files and directories between the local and remote site windows. This will automatically initiate a file transfer. The directory structure is maintained from the source to the destination and is recursive, so all subdirectories and folders within the main directory will be transferred as well. Transfer status will be logged at the bottom of the window. Once all your files have been transferred, you can close FileZilla which will close the SFTP connection.","title":"FileZilla"},{"location":"data_management/transfer/filezilla/#filezilla","text":"Filezilla is a free SFTP platform used to transfer data between a local machine and a remote server, in this case remote storage accessible to Cheaha and UAB Cloud or long-term S3 storage. Filezilla is useful for medium sized data transfers from a local machine as opposed to Globus which can easily connect two different local or remote servers and handle large quantities of data.","title":"FileZilla"},{"location":"data_management/transfer/filezilla/#installation","text":"To download the program, go to the FileZilla site and click Download FileZilla Client. Filezilla is also already installed on Cheaha and can be accessed through the Accessories menu.","title":"Installation"},{"location":"data_management/transfer/filezilla/#using-filezilla","text":"Once FileZilla is installed and you open it, you will see the following window A file browser for the local machine FileZilla is running on is on the left while the file system for the remote site will be shown on the right once a remote site has been connected.","title":"Using FileZilla"},{"location":"data_management/transfer/filezilla/#creating-a-remote-connection","text":"You can easily connect to a remote site using the QuickConnect bar near the top of the window. You will need to input the following options: Host: sftp://cheaha.rc.uab.edu Username: your BlazerID or XIAS ID (do NOT include '@uab.edu') Password: your BlazerID or XIAS password Port: 22 Click Quickconnect and you will be connected to the remote storage system. The window should now look like: When connecting in the future, you will be able to select the connection from the dropdown arrow next to the Quickconnect button. In both the local and remote panes, you can navigate to the directories you are transferring from and to. You only have access to directories you can normally access on Cheaha, so your user space as well as any project directories you have been added to.","title":"Creating a Remote Connection"},{"location":"data_management/transfer/filezilla/#transferring-data","text":"From here you can drag and drop whichever files and directories between the local and remote site windows. This will automatically initiate a file transfer. The directory structure is maintained from the source to the destination and is recursive, so all subdirectories and folders within the main directory will be transferred as well. Transfer status will be logged at the bottom of the window. Once all your files have been transferred, you can close FileZilla which will close the SFTP connection.","title":"Transferring Data"},{"location":"data_management/transfer/globus/","text":"Globus \u00b6 Setting up Globus Connect Personal \u00b6 Globus Connect Personal is software meant to be installed on local machines such as laptops, desktops, workstations and self-owned, local-scale servers. Globus maintains excellent documentation for installation on MacOS , Linux and Windows . To verify your installation is complete, please visit https://app.globus.org and log in. Click \"Endpoints\" in the left-hand navigation pane and then click the \"Administered By You\" tab. Look in the table for the endpoint you just created. Moving Data Between Endpoints \u00b6 Log in to the Globus App online at https://app.globus.org using UAB Single Sign-On (SSO). Start typing \"University of Alabama at Birmingham\" into the \"Use your existing organizational login\" text box and selected it when it appears in the list. ![!Globus login page with University of Alabama at Birmingham entered into the text box./globus_001_login.png) Click File Manager in the left-hand navigation pane. Ensure the center icon for the \"Panels\" selection is picked. Click the \"Search\" icon in the \"Collection\" text box near the top-left or top-right of the page to locate an endpoint. There are multiple ways to find an endpoint. For some endpoints you may be asked to log in, which is true of all UAB endpoints. Some UAB endpoints may also require that you be on the UAB VPN. Begin typing in the box to search for an endpoint. To find UAB-related endpoints, search for \"UAB\". There are two Cheaha endpoints Cheaha cluster on-campus (UAB Science DMZ) for machines that are on campus or connected to the VPN. Cheaha cluster off-campus (UAB Science DMZ) for machines that are off campus and not on the VPN. The \"Recent\" tab shows endpoints that have most recently been used. The \"Bookmarks\" tab shows a list of endpoint bookmarks. The \"Your Collections\" tab shows all endpoints owned by you. For most users this will be one or more Globus Connect Personal endpoints. The \"Shared With You\" tab shows any private endpoints that have been shared with you by other users, possibly collaborators. The \"More Options\" tab will show a brief text on installing Globus Connect Personal. When an endpoint has been selected you will see a list of folders and files on the default path for that endpoint in the bottom box. You can use the \"Path\" box to type a path to find the files you are looking for. Repeat the process of selecting an endpoint for the other \"Collection\" text box. When both endpoints have been selected and you have chosen the correct paths for each endpoint, select files and/or folders on the side you wish to transfer FROM. We will call this side the source endpoint, and the other side the target endpoint. Selections may be made by clicking the checkboxes that appear when you hover over each file or folder. When all files and folders have been selected from the source endpoint, click the \"Start\" button on the source endpoint side. This will start a transfer process from source to target. The files will be placed in the currently open path on the target endpoint. A green pop-up notification will appear indicating the transfer has started. Click \"View details >\" to be taken to the status of the transfer. You can also check on the status of any transfers by clicking the \"Activity\" button in the left-hand navigation pane. Transfer and Sync Options \u00b6 Between the two \"Start\" buttons on the \"File Manager\" page is a \"Transfer & Sync Options\" drop down menu. Click that button to change the options. More information on each option. A brief summary of the options are... sync - Sync files only, rather than create new files. delete files - Delete any files on the target that are not on the source. Useful for forcing identical filesystems when syncing. preserve source - Copies file \"modified time\" metadata. verify integrity - Verifies that checksums are identical on source and target after transfer completes. Highly recommended to have this checked. encrypt transfer - Encrypts data before leaving source and decrypts after arriving at destination. Recommended for all transfers, required and enforced for all UAB endpoints. skip files - Skips source files that cause errors during the transfer. Otherwise the entire transfer will stop when an error is encountered. quota fail - Fails instead of retries when the target storage quota is exceeded. Common Errors \u00b6 File Not Found - This may mean that a file was not readable by Globus. Check that the file hasn't moved or changed names during the transfer. It is recommended to not modify files while they are being transferred by Globus. Permission Denied - Globus is not able to access the files because permissions do not allow it. For Globus Connect Personal, be sure the containing folder is on the \"Accessible Folders\" list. Be sure that your user account has access to read the file. More Information \u00b6 A Globus FAQ is available for additional information on endpoints and transfers. Using Bookmarks \u00b6 To save a bookmark, use the File Manager interface to select an endpoint and navigate to a path on that endpoint. Then click the bookmark button as shown below. To manage bookmarks, click \"Bookmarks\" in the left-hand navigation pane. Click the \"Pencil\" icon to edit a bookmark. Click the \"Trash Bin\" icon to delete a bookmark. Managing Shared Collections from a Globus Connect Personal Endpoint \u00b6 It is NOT RECOMMENDED to make Globus Connect Personal endpoints public as this is insecure. It is more difficult to manage access controls for the entire Globus Connect Personal endpoint than for a shared collection. Shared collections make it simpler to share different data with distinct collaborators, and to manage who has access to what data. Be secure, use shared collections! Creating a Shared Collection \u00b6 Click \"Endpoints\" in the left-hand navigation pane. Click the \"Administered By You\" tab. In the table, find the endpoint you wish to share data from and click its name. You will be taken to the page for that endpoint. Click the \"Collections\" tab. Click the \"Add a Guest Collection\" button. Fill out the form. Manually enter a path or click the Browse button to select a folder. Give a short but memorable name for your shared collection. This information will be useful for your collaborators. Optionally fill in a more detailed description of the shared collection for your records. Optionally fill in searchable keywords. Click \"Create Share\" to move to the next step. You will be taken to the page for the newly created collection, which is now a full-fledged endpoint. Any further references to \"an endpoint\" will be about the newly created, shared collection. Make sure you are on the \"Permissions\" tab. You should see a permissions table with your name in the first row. Click \"Add Permissions -- Share With\" to share your endpoint with other users. Fill out the form. Optionally enter a path within the shared endpoint or use the Browse button. If you leave the path as just a slash, the entire shared endpoint will be shared with these users. Select who to share with. User - One or more users. Group - All members of a group. All Users - All globus users. Warning! This exposes data publicly! Search for users to add, or a group, depending on your choice above. You should be able to find any globus user using the search box. Warning! Be certain of which user you are selecting! Check the email domain! If adding users, optionally enter a message so they know why they are being added. Select permissions. Read is automatically selected and cannot be changed. Write permissions are optional. Click \"Add Permission\" to add permissions for these users or groups. You will be returned to the page for the shared endpoint and should be on the \"Permissions\" tab and should see the user or group in the table. Deleting a Shared Collection \u00b6 Click \"Endpoints\" in the left-hand navigation pane, then c Click the \"Administered By You\" tab. Click the right caret \">\" icon at the right side of the row with the endpoint you wish to delete. You will be taken to the information page for that endpoint. Click \"X Delete Endpoint\" and a confirmation dialog will open at the top of the page. Respond to the dialog to delete the endpoint, or to cancel. Setting up Globus Connect Server \u00b6 Under construction!","title":"Globus"},{"location":"data_management/transfer/globus/#globus","text":"","title":"Globus"},{"location":"data_management/transfer/globus/#setting-up-globus-connect-personal","text":"Globus Connect Personal is software meant to be installed on local machines such as laptops, desktops, workstations and self-owned, local-scale servers. Globus maintains excellent documentation for installation on MacOS , Linux and Windows . To verify your installation is complete, please visit https://app.globus.org and log in. Click \"Endpoints\" in the left-hand navigation pane and then click the \"Administered By You\" tab. Look in the table for the endpoint you just created.","title":"Setting up Globus Connect Personal"},{"location":"data_management/transfer/globus/#moving-data-between-endpoints","text":"Log in to the Globus App online at https://app.globus.org using UAB Single Sign-On (SSO). Start typing \"University of Alabama at Birmingham\" into the \"Use your existing organizational login\" text box and selected it when it appears in the list. ![!Globus login page with University of Alabama at Birmingham entered into the text box./globus_001_login.png) Click File Manager in the left-hand navigation pane. Ensure the center icon for the \"Panels\" selection is picked. Click the \"Search\" icon in the \"Collection\" text box near the top-left or top-right of the page to locate an endpoint. There are multiple ways to find an endpoint. For some endpoints you may be asked to log in, which is true of all UAB endpoints. Some UAB endpoints may also require that you be on the UAB VPN. Begin typing in the box to search for an endpoint. To find UAB-related endpoints, search for \"UAB\". There are two Cheaha endpoints Cheaha cluster on-campus (UAB Science DMZ) for machines that are on campus or connected to the VPN. Cheaha cluster off-campus (UAB Science DMZ) for machines that are off campus and not on the VPN. The \"Recent\" tab shows endpoints that have most recently been used. The \"Bookmarks\" tab shows a list of endpoint bookmarks. The \"Your Collections\" tab shows all endpoints owned by you. For most users this will be one or more Globus Connect Personal endpoints. The \"Shared With You\" tab shows any private endpoints that have been shared with you by other users, possibly collaborators. The \"More Options\" tab will show a brief text on installing Globus Connect Personal. When an endpoint has been selected you will see a list of folders and files on the default path for that endpoint in the bottom box. You can use the \"Path\" box to type a path to find the files you are looking for. Repeat the process of selecting an endpoint for the other \"Collection\" text box. When both endpoints have been selected and you have chosen the correct paths for each endpoint, select files and/or folders on the side you wish to transfer FROM. We will call this side the source endpoint, and the other side the target endpoint. Selections may be made by clicking the checkboxes that appear when you hover over each file or folder. When all files and folders have been selected from the source endpoint, click the \"Start\" button on the source endpoint side. This will start a transfer process from source to target. The files will be placed in the currently open path on the target endpoint. A green pop-up notification will appear indicating the transfer has started. Click \"View details >\" to be taken to the status of the transfer. You can also check on the status of any transfers by clicking the \"Activity\" button in the left-hand navigation pane.","title":"Moving Data Between Endpoints"},{"location":"data_management/transfer/globus/#transfer-and-sync-options","text":"Between the two \"Start\" buttons on the \"File Manager\" page is a \"Transfer & Sync Options\" drop down menu. Click that button to change the options. More information on each option. A brief summary of the options are... sync - Sync files only, rather than create new files. delete files - Delete any files on the target that are not on the source. Useful for forcing identical filesystems when syncing. preserve source - Copies file \"modified time\" metadata. verify integrity - Verifies that checksums are identical on source and target after transfer completes. Highly recommended to have this checked. encrypt transfer - Encrypts data before leaving source and decrypts after arriving at destination. Recommended for all transfers, required and enforced for all UAB endpoints. skip files - Skips source files that cause errors during the transfer. Otherwise the entire transfer will stop when an error is encountered. quota fail - Fails instead of retries when the target storage quota is exceeded.","title":"Transfer and Sync Options"},{"location":"data_management/transfer/globus/#common-errors","text":"File Not Found - This may mean that a file was not readable by Globus. Check that the file hasn't moved or changed names during the transfer. It is recommended to not modify files while they are being transferred by Globus. Permission Denied - Globus is not able to access the files because permissions do not allow it. For Globus Connect Personal, be sure the containing folder is on the \"Accessible Folders\" list. Be sure that your user account has access to read the file.","title":"Common Errors"},{"location":"data_management/transfer/globus/#more-information","text":"A Globus FAQ is available for additional information on endpoints and transfers.","title":"More Information"},{"location":"data_management/transfer/globus/#using-bookmarks","text":"To save a bookmark, use the File Manager interface to select an endpoint and navigate to a path on that endpoint. Then click the bookmark button as shown below. To manage bookmarks, click \"Bookmarks\" in the left-hand navigation pane. Click the \"Pencil\" icon to edit a bookmark. Click the \"Trash Bin\" icon to delete a bookmark.","title":"Using Bookmarks"},{"location":"data_management/transfer/globus/#managing-shared-collections-from-a-globus-connect-personal-endpoint","text":"It is NOT RECOMMENDED to make Globus Connect Personal endpoints public as this is insecure. It is more difficult to manage access controls for the entire Globus Connect Personal endpoint than for a shared collection. Shared collections make it simpler to share different data with distinct collaborators, and to manage who has access to what data. Be secure, use shared collections!","title":"Managing Shared Collections from a Globus Connect Personal Endpoint"},{"location":"data_management/transfer/globus/#creating-a-shared-collection","text":"Click \"Endpoints\" in the left-hand navigation pane. Click the \"Administered By You\" tab. In the table, find the endpoint you wish to share data from and click its name. You will be taken to the page for that endpoint. Click the \"Collections\" tab. Click the \"Add a Guest Collection\" button. Fill out the form. Manually enter a path or click the Browse button to select a folder. Give a short but memorable name for your shared collection. This information will be useful for your collaborators. Optionally fill in a more detailed description of the shared collection for your records. Optionally fill in searchable keywords. Click \"Create Share\" to move to the next step. You will be taken to the page for the newly created collection, which is now a full-fledged endpoint. Any further references to \"an endpoint\" will be about the newly created, shared collection. Make sure you are on the \"Permissions\" tab. You should see a permissions table with your name in the first row. Click \"Add Permissions -- Share With\" to share your endpoint with other users. Fill out the form. Optionally enter a path within the shared endpoint or use the Browse button. If you leave the path as just a slash, the entire shared endpoint will be shared with these users. Select who to share with. User - One or more users. Group - All members of a group. All Users - All globus users. Warning! This exposes data publicly! Search for users to add, or a group, depending on your choice above. You should be able to find any globus user using the search box. Warning! Be certain of which user you are selecting! Check the email domain! If adding users, optionally enter a message so they know why they are being added. Select permissions. Read is automatically selected and cannot be changed. Write permissions are optional. Click \"Add Permission\" to add permissions for these users or groups. You will be returned to the page for the shared endpoint and should be on the \"Permissions\" tab and should see the user or group in the table.","title":"Creating a Shared Collection"},{"location":"data_management/transfer/globus/#deleting-a-shared-collection","text":"Click \"Endpoints\" in the left-hand navigation pane, then c Click the \"Administered By You\" tab. Click the right caret \">\" icon at the right side of the row with the endpoint you wish to delete. You will be taken to the information page for that endpoint. Click \"X Delete Endpoint\" and a confirmation dialog will open at the top of the page. Respond to the dialog to delete the endpoint, or to cancel.","title":"Deleting a Shared Collection"},{"location":"data_management/transfer/globus/#setting-up-globus-connect-server","text":"Under construction!","title":"Setting up Globus Connect Server"},{"location":"resources/publications/","text":"Grant Descriptions \u00b6 Short \u00b6 UAB IT Research Computing maintains high performance compute (HPC) and storage resources for investigators. The Cheaha high performance compute cluster provides 8192 CPU cores and 72 GPUs interconnected via an InfiniBand network, providing over 619 TFLOP/s of aggregate theoretical peak performance. A high-performance, 12PB raw GPFS storage on DDN SFA12KX hardware is also connected to these compute nodes via the Infiniband fabric, available to all UAB investigators. Detailed \u00b6 Note Under construction. Acknoweldgement in Publications \u00b6 To acknowledge the use of Cheaha in published work, for compute time or substantial technical assistance, please consider adding the following to the acknowledgements section of your publication: The authors gratefully acknowledge the resources provided by the University of Alabama at Birmingham IT-Research Computing group for high performance computing (HPC) support and CPU time on the Cheaha compute cluster. If Globus was used to transfer data to/from Cheaha, please consider adding the following to the acknowledgements section of your publication: This work was supported in part by the National Science Foundation under Grants Nos. OAC-1541310, the University of Alabama at Birmingham, and the Alabama Innovation Fund. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation or the University of Alabama at Birmingham. Detailed Hardware Information \u00b6 For more detailed information on compute hardware please see: Detailed Hardware Information","title":"Grant Descriptions"},{"location":"resources/publications/#grant-descriptions","text":"","title":"Grant Descriptions"},{"location":"resources/publications/#short","text":"UAB IT Research Computing maintains high performance compute (HPC) and storage resources for investigators. The Cheaha high performance compute cluster provides 8192 CPU cores and 72 GPUs interconnected via an InfiniBand network, providing over 619 TFLOP/s of aggregate theoretical peak performance. A high-performance, 12PB raw GPFS storage on DDN SFA12KX hardware is also connected to these compute nodes via the Infiniband fabric, available to all UAB investigators.","title":"Short"},{"location":"resources/publications/#detailed","text":"Note Under construction.","title":"Detailed"},{"location":"resources/publications/#acknoweldgement-in-publications","text":"To acknowledge the use of Cheaha in published work, for compute time or substantial technical assistance, please consider adding the following to the acknowledgements section of your publication: The authors gratefully acknowledge the resources provided by the University of Alabama at Birmingham IT-Research Computing group for high performance computing (HPC) support and CPU time on the Cheaha compute cluster. If Globus was used to transfer data to/from Cheaha, please consider adding the following to the acknowledgements section of your publication: This work was supported in part by the National Science Foundation under Grants Nos. OAC-1541310, the University of Alabama at Birmingham, and the Alabama Innovation Fund. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation or the University of Alabama at Birmingham.","title":"Acknoweldgement in Publications"},{"location":"resources/publications/#detailed-hardware-information","text":"For more detailed information on compute hardware please see: Detailed Hardware Information","title":"Detailed Hardware Information"},{"location":"resources/support/","text":"How to Request Support \u00b6 How Do I Create a Support Ticket? \u00b6 To Create a support ticket, send a descriptive email to support@listserv.uab.edu to create a ticket. Bonus points for including the following details. General Issues \u00b6 What is your goal? What steps were taken? What was expected? What actually happened? How was the cluster accessed? Web Portal, SSH, VNC, etc.? What software were you using? Please be as specific as possible. The command module list can be helpful here. Outages \u00b6 What part of the cluster is affected? Please list any relevant affected nodes or other hardware that is not accessible. If you are unable to access the cluster please state that instead. What were you working on when you noticed the outage? How were you accessing the cluster? Web Portal, SSH, VNC, etc.? How Do I Request Or Change A Project Space? \u00b6 Projects are collaborative data and code storage spaces with controlled access. Any UAB investigator with a legitimate research need can request a project storage space. Please send an email with the following information, depending on what you need. New Projects \u00b6 What is the purpose of the project space? What should we name the project? Short, descriptive, memorable names work best. The name will be used as the project folder name in our file system, so alphanumeric, underscore and dash characters only please. Who should have access? Please provide a list of blazerids. The intended project owner will always have access. Access Management \u00b6 What is the name of the project? Who should be given access? Who should no longer have access? Storage \u00b6 What is the name of the project? How much additional or total space will be needed? Office Hours \u00b6 For our office hours links please see Contact Us","title":"How to Request Support"},{"location":"resources/support/#how-to-request-support","text":"","title":"How to Request Support"},{"location":"resources/support/#how-do-i-create-a-support-ticket","text":"To Create a support ticket, send a descriptive email to support@listserv.uab.edu to create a ticket. Bonus points for including the following details.","title":"How Do I Create a Support Ticket?"},{"location":"resources/support/#general-issues","text":"What is your goal? What steps were taken? What was expected? What actually happened? How was the cluster accessed? Web Portal, SSH, VNC, etc.? What software were you using? Please be as specific as possible. The command module list can be helpful here.","title":"General Issues"},{"location":"resources/support/#outages","text":"What part of the cluster is affected? Please list any relevant affected nodes or other hardware that is not accessible. If you are unable to access the cluster please state that instead. What were you working on when you noticed the outage? How were you accessing the cluster? Web Portal, SSH, VNC, etc.?","title":"Outages"},{"location":"resources/support/#how-do-i-request-or-change-a-project-space","text":"Projects are collaborative data and code storage spaces with controlled access. Any UAB investigator with a legitimate research need can request a project storage space. Please send an email with the following information, depending on what you need.","title":"How Do I Request Or Change A Project Space?"},{"location":"resources/support/#new-projects","text":"What is the purpose of the project space? What should we name the project? Short, descriptive, memorable names work best. The name will be used as the project folder name in our file system, so alphanumeric, underscore and dash characters only please. Who should have access? Please provide a list of blazerids. The intended project owner will always have access.","title":"New Projects"},{"location":"resources/support/#access-management","text":"What is the name of the project? Who should be given access? Who should no longer have access?","title":"Access Management"},{"location":"resources/support/#storage","text":"What is the name of the project? How much additional or total space will be needed?","title":"Storage"},{"location":"resources/support/#office-hours","text":"For our office hours links please see Contact Us","title":"Office Hours"},{"location":"uab_cloud/instance_setup_basic/","text":"Basic Instance Setup \u00b6 Instances are the basic unit of compute on OpenStack. Requesting an instance involves a number of steps, and requires that a Network has already been setup. It is also possible to attach persistent reusable Volumes to instances. Creating a Floating IP \u00b6 Floating IPs are required if you want an instance to talk to devices on the internet. These IPs are a shared resource, so they must be allocated when needed and released when no longer needed. Click \"Network\" in the left-hand navigation pane to open the fold-out menu. Click \"Floating IPs\". Click \"Allocate IP to Project\" to open a dialog box. Fill out the dialog box. Select \"uab-campus\" in the \"Pool\" drop down box. Enter a \"Description\". Leave \"DNS Domain\" empty. Leave \"DNS Name\" empty. Click \"Allocate IP\". Redirects to the \"Floating IPs\" page. There should be a new entry in the table. Creating a Key Pair \u00b6 A Key Pair is required for SSH access to OpenStack instances for security reasons. Using a password protected Key Pair is highly recommended for additional security, as it buys time to revoke a key if it is compromised by an attacker. Currently, this is only possible by uploading a custom public key generated on your local machine. Good practice is to only use one key pair per person and per local machine. So if you have two computers, each one will need its own key pair. If you have two users, each will need their own key pair. Private keys are secrets and should not be passed around. Copying the key increases the risk of the system being compromised by an attacker. Click \"Compute\" in the left-hand navigation pane to open the fold-out menu. Click \"Key Pairs\". Click \"+ Create Key Pair\" to open a dialog box. Fill out the dialog box. Enter a \"Key Pair Name\". Select \"SSH Key\" in the \"Key Type\" drop down box. Click \"+ Create Key Pair\" Opens a download file dialog box in your browser to download a pem file containing the secret private key. Download the pem file. For security reasons this will be your only chance to ever obtain the private key from OpenStack. Failing to download the pem file now means a new key pair will need to be created. Redirects to the \"Key Pairs\" page. There should be a new entry in the table. To use the private key on your local machine. mv the pem file to the .ssh directory under your home directory. If you are on a Windows machine, you'll need to install ssh by one of various means. cd to the .ssh directory under your home directory. ssh-add <pem_file> to add the private key to the ssh keyring for use by ssh. ssh-add -d <pem_file> to remove the key. Note It is alternately possible to use a custom key pair created on your local machine. We assume you know how to create a key pair on your local machine and have already done so. To upload a key pair, replace steps 3 and 4 above with the following, perform step 5 from above, and skip step 6. 3\\. Click \"Import Public Key\" to open a dialog box. 4\\. Fill out the dialog box. 1. Enter a \"Key Pair Name\". 2. Select \"SSH Key\" in the \"Key Type\" drop-down box. 3. Click \"Browse...\" to upload a public key file from your custom key pair **OR** copy-paste the content of that key file into the \"Public Key\" box. ![!Import Public Key dialog. The dialog form is empty.](./images/key_pairs_alt_002.png) Creating an Instance \u00b6 Creating an instance is possibly a step you'll perform often, depending on your workflow. There are many smaller steps to create an instance, so please take care to check all the fields when you create an instance. These instructions require that you've set up a Network and followed all of the instructions on the linked page. You should have a Network, Subnet, outer and SSH Security Group. You will also need to setup a Key Pair and a Floating IP . Click \"Compute\" in the left-hand navigation pane to open the fold-out menu. Click \"Instances\". Click \"Launch Instance\" to open a dialog box. Fill out the dialog box completely. There are several tabs that will need to be completed. \"Details\" tab. Enter an \"Instance Name\". Enter a \"Description\". Select \"nova\" in the \"Availability Zone\" drop down box. Select \"1\" in the \"Count\" field. Click \"Next >\" to move to the \"Source\" tab. \"Source\" tab. Sources determine what operating system or pre-defined image will be used as the starting point for your operating system (OS). Select \"Image\" in the \"Select Boot Source\" drop down box. Select \"Yes\" under \"Create New Volume\". Choose an appropriate \"Volume Size\" in GiB . Note that for many single-use instances, 20 GiB is more than enough. If you need more because you have persistent data, please create a persistent volume<volume_setup_basic> . Select \"Yes\" or \"No\" under \"Delete Volume on Instance Delete\" \"Yes\" is a good choice if the OS volume will be reused. \"No\" is a good choice if you don't care about reusing the OS. Pick an image from the list under the \"Available\" section. Use the search box to help find the image that best suits your research needs. When you find the best image, click the button with an up arrow next to the image. The image will move to the \"Allocated\" section above the \"Available\" section. Click \"Next >\" to move to the \"Flavor\" tab. \"Flavor\" tab. Flavors determine what hardware will be available to your instance, including cpus, memory and gpus. Pick an instance flavor form the list under the \"Available\" section. Use the search box to help find the flavor that best suits your needs. When you find the best flavor, click the button with an up arrow next to the flavor. The flavor will move to the \"Allocated\" section above the \"Available\" section. Click \"Next >\" to move to the \"Networks\" tab. \"Networks\" tab. Networks determine how your instance will talk to the internet and other instances. See Network for more information. Pick a network from the list under the \"Available' section. A Network may already be picked in the \"Allocated\" section. If this is not the correct Network, use the down arrow next to it to remove it from the \"Allocated\" section. If the Network is correct, skip (ii.) through (iv.). Use the search box to help find the Network that best suits your needs. When you find the best Network, click the button with an up arrow next to the Network. The Network will move to the \"Allocated\" section above the \"available\" section. Click \"Next >\" to move to the \"Network Ports\" tab. \"Network Ports\" tab. Coming Soon! Leave this tab empty. Click \"Next >\" to move to the \"Security Groups\" tab. \"Security Groups tab. Security Groups allow for fine-grained control over external access to your instance. For more information see Creating a Security Group for more information. Pick the \"ssh\" Security Group from the \"Available\" section by pressing the up arrow next to it. The \"default\" Security Group should already be in the \"Allocated\" section. Click \"Next >\" to move to the \"Key Pair\" tab. \"Key Pair\" tab. Key Pairs allow individual access rights to the instance via SSH. For more information see Creating a Key Pair . Pick one or more key pairs from the list under the \"Available\" section. A Key Pair may already be picked in the \"Allocated\" section. If this is not the correct \"Key Pair\", use the down arrow next to it to remove it form the \"Allocated\" section. If the Key Pair is correct, skip (ii.) through (iv.). Use the search box to help find the Key Pair that best suits your needs. When you find the best Key Pair(s), click the button with an up arrow next to the Key Pair(s). The Key Pair(s) will move to the \"Allocated\" section above the \"Available\" section. Click \"Next >\" to move to the \"Configuration\" tab. \"Configuration\" tab. Coming Soon! Skip this tab. Click \"Next >\" to move to the \"Server Groups\" tab. \"Server Groups\" tab. Coming Soon! Skip this tab. Click \"Next >\" to move to the \"Scheduler Hints\" tab. \"Scheduler Hints\" tab. Coming Soon! Skip this tab. Click \"Next >\" to move to the \"Metadata\" tab. \"Metadata\" tab. Coming Soon! Skip this tab. Click \"Launch Instance\" to launch the instance. Redirects to the \"Instances\" page. There should be a new entry in the table. The instance will take some time to build and boot. When the Status column entry says \"Active\" please move to the next steps. Associate Floating IP. In the \"Actions\" column entry, click the drop down triangle and select \"Associate Floating IP\". A dialog box will open. Select an IP address in the \"IP Address\" drop down box. Select a port in the \"Port to be associated\" drop down box. Click \"Associate\" to return to the \"Instances\" page and associate the selected IP. At this stage you should be able to SSH into your instance from on campus or on the UAB VPN. SSH Into the Instance \u00b6 If you are following the steps from top to bottom, then at this stage you should be able to SSH into your instance from on campus or on the UAB VPN. To do so be sure your local machine has ssh and then use the following command If you are using a different operating system, such as CentOS, replace the user ubuntu with centos or whatever is appropriate. ssh ubuntu@<floating ip> -i ~/.ssh/<keypair_name>.pem Note Reusing a floating IP for a new instance can result in a \"host key changed\" error. To resolve this issue, please use the command below with the hostname given by the error, which should be the affected floating IP. ``` ssh-keygen -R <hostname> ``` ![image showing host key changed error at terminal](images/instances_ssh_host_key_error.png) Danger Using the above command is potentially dangerous when connecting to machines or instances controlled by other people. Be absolutely certain you trust the source of the key change before using the command above.","title":"Basic Instance Setup"},{"location":"uab_cloud/instance_setup_basic/#basic-instance-setup","text":"Instances are the basic unit of compute on OpenStack. Requesting an instance involves a number of steps, and requires that a Network has already been setup. It is also possible to attach persistent reusable Volumes to instances.","title":"Basic Instance Setup"},{"location":"uab_cloud/instance_setup_basic/#creating-a-floating-ip","text":"Floating IPs are required if you want an instance to talk to devices on the internet. These IPs are a shared resource, so they must be allocated when needed and released when no longer needed. Click \"Network\" in the left-hand navigation pane to open the fold-out menu. Click \"Floating IPs\". Click \"Allocate IP to Project\" to open a dialog box. Fill out the dialog box. Select \"uab-campus\" in the \"Pool\" drop down box. Enter a \"Description\". Leave \"DNS Domain\" empty. Leave \"DNS Name\" empty. Click \"Allocate IP\". Redirects to the \"Floating IPs\" page. There should be a new entry in the table.","title":"Creating a Floating IP"},{"location":"uab_cloud/instance_setup_basic/#creating-a-key-pair","text":"A Key Pair is required for SSH access to OpenStack instances for security reasons. Using a password protected Key Pair is highly recommended for additional security, as it buys time to revoke a key if it is compromised by an attacker. Currently, this is only possible by uploading a custom public key generated on your local machine. Good practice is to only use one key pair per person and per local machine. So if you have two computers, each one will need its own key pair. If you have two users, each will need their own key pair. Private keys are secrets and should not be passed around. Copying the key increases the risk of the system being compromised by an attacker. Click \"Compute\" in the left-hand navigation pane to open the fold-out menu. Click \"Key Pairs\". Click \"+ Create Key Pair\" to open a dialog box. Fill out the dialog box. Enter a \"Key Pair Name\". Select \"SSH Key\" in the \"Key Type\" drop down box. Click \"+ Create Key Pair\" Opens a download file dialog box in your browser to download a pem file containing the secret private key. Download the pem file. For security reasons this will be your only chance to ever obtain the private key from OpenStack. Failing to download the pem file now means a new key pair will need to be created. Redirects to the \"Key Pairs\" page. There should be a new entry in the table. To use the private key on your local machine. mv the pem file to the .ssh directory under your home directory. If you are on a Windows machine, you'll need to install ssh by one of various means. cd to the .ssh directory under your home directory. ssh-add <pem_file> to add the private key to the ssh keyring for use by ssh. ssh-add -d <pem_file> to remove the key. Note It is alternately possible to use a custom key pair created on your local machine. We assume you know how to create a key pair on your local machine and have already done so. To upload a key pair, replace steps 3 and 4 above with the following, perform step 5 from above, and skip step 6. 3\\. Click \"Import Public Key\" to open a dialog box. 4\\. Fill out the dialog box. 1. Enter a \"Key Pair Name\". 2. Select \"SSH Key\" in the \"Key Type\" drop-down box. 3. Click \"Browse...\" to upload a public key file from your custom key pair **OR** copy-paste the content of that key file into the \"Public Key\" box. ![!Import Public Key dialog. The dialog form is empty.](./images/key_pairs_alt_002.png)","title":"Creating a Key Pair"},{"location":"uab_cloud/instance_setup_basic/#creating-an-instance","text":"Creating an instance is possibly a step you'll perform often, depending on your workflow. There are many smaller steps to create an instance, so please take care to check all the fields when you create an instance. These instructions require that you've set up a Network and followed all of the instructions on the linked page. You should have a Network, Subnet, outer and SSH Security Group. You will also need to setup a Key Pair and a Floating IP . Click \"Compute\" in the left-hand navigation pane to open the fold-out menu. Click \"Instances\". Click \"Launch Instance\" to open a dialog box. Fill out the dialog box completely. There are several tabs that will need to be completed. \"Details\" tab. Enter an \"Instance Name\". Enter a \"Description\". Select \"nova\" in the \"Availability Zone\" drop down box. Select \"1\" in the \"Count\" field. Click \"Next >\" to move to the \"Source\" tab. \"Source\" tab. Sources determine what operating system or pre-defined image will be used as the starting point for your operating system (OS). Select \"Image\" in the \"Select Boot Source\" drop down box. Select \"Yes\" under \"Create New Volume\". Choose an appropriate \"Volume Size\" in GiB . Note that for many single-use instances, 20 GiB is more than enough. If you need more because you have persistent data, please create a persistent volume<volume_setup_basic> . Select \"Yes\" or \"No\" under \"Delete Volume on Instance Delete\" \"Yes\" is a good choice if the OS volume will be reused. \"No\" is a good choice if you don't care about reusing the OS. Pick an image from the list under the \"Available\" section. Use the search box to help find the image that best suits your research needs. When you find the best image, click the button with an up arrow next to the image. The image will move to the \"Allocated\" section above the \"Available\" section. Click \"Next >\" to move to the \"Flavor\" tab. \"Flavor\" tab. Flavors determine what hardware will be available to your instance, including cpus, memory and gpus. Pick an instance flavor form the list under the \"Available\" section. Use the search box to help find the flavor that best suits your needs. When you find the best flavor, click the button with an up arrow next to the flavor. The flavor will move to the \"Allocated\" section above the \"Available\" section. Click \"Next >\" to move to the \"Networks\" tab. \"Networks\" tab. Networks determine how your instance will talk to the internet and other instances. See Network for more information. Pick a network from the list under the \"Available' section. A Network may already be picked in the \"Allocated\" section. If this is not the correct Network, use the down arrow next to it to remove it from the \"Allocated\" section. If the Network is correct, skip (ii.) through (iv.). Use the search box to help find the Network that best suits your needs. When you find the best Network, click the button with an up arrow next to the Network. The Network will move to the \"Allocated\" section above the \"available\" section. Click \"Next >\" to move to the \"Network Ports\" tab. \"Network Ports\" tab. Coming Soon! Leave this tab empty. Click \"Next >\" to move to the \"Security Groups\" tab. \"Security Groups tab. Security Groups allow for fine-grained control over external access to your instance. For more information see Creating a Security Group for more information. Pick the \"ssh\" Security Group from the \"Available\" section by pressing the up arrow next to it. The \"default\" Security Group should already be in the \"Allocated\" section. Click \"Next >\" to move to the \"Key Pair\" tab. \"Key Pair\" tab. Key Pairs allow individual access rights to the instance via SSH. For more information see Creating a Key Pair . Pick one or more key pairs from the list under the \"Available\" section. A Key Pair may already be picked in the \"Allocated\" section. If this is not the correct \"Key Pair\", use the down arrow next to it to remove it form the \"Allocated\" section. If the Key Pair is correct, skip (ii.) through (iv.). Use the search box to help find the Key Pair that best suits your needs. When you find the best Key Pair(s), click the button with an up arrow next to the Key Pair(s). The Key Pair(s) will move to the \"Allocated\" section above the \"Available\" section. Click \"Next >\" to move to the \"Configuration\" tab. \"Configuration\" tab. Coming Soon! Skip this tab. Click \"Next >\" to move to the \"Server Groups\" tab. \"Server Groups\" tab. Coming Soon! Skip this tab. Click \"Next >\" to move to the \"Scheduler Hints\" tab. \"Scheduler Hints\" tab. Coming Soon! Skip this tab. Click \"Next >\" to move to the \"Metadata\" tab. \"Metadata\" tab. Coming Soon! Skip this tab. Click \"Launch Instance\" to launch the instance. Redirects to the \"Instances\" page. There should be a new entry in the table. The instance will take some time to build and boot. When the Status column entry says \"Active\" please move to the next steps. Associate Floating IP. In the \"Actions\" column entry, click the drop down triangle and select \"Associate Floating IP\". A dialog box will open. Select an IP address in the \"IP Address\" drop down box. Select a port in the \"Port to be associated\" drop down box. Click \"Associate\" to return to the \"Instances\" page and associate the selected IP. At this stage you should be able to SSH into your instance from on campus or on the UAB VPN.","title":"Creating an Instance"},{"location":"uab_cloud/instance_setup_basic/#ssh-into-the-instance","text":"If you are following the steps from top to bottom, then at this stage you should be able to SSH into your instance from on campus or on the UAB VPN. To do so be sure your local machine has ssh and then use the following command If you are using a different operating system, such as CentOS, replace the user ubuntu with centos or whatever is appropriate. ssh ubuntu@<floating ip> -i ~/.ssh/<keypair_name>.pem Note Reusing a floating IP for a new instance can result in a \"host key changed\" error. To resolve this issue, please use the command below with the hostname given by the error, which should be the affected floating IP. ``` ssh-keygen -R <hostname> ``` ![image showing host key changed error at terminal](images/instances_ssh_host_key_error.png) Danger Using the above command is potentially dangerous when connecting to machines or instances controlled by other people. Be absolutely certain you trust the source of the key change before using the command above.","title":"SSH Into the Instance"},{"location":"uab_cloud/introduction/","text":"UAB Cloud \u00b6 Our OpenStack portal cloud.rc provides a home for more permanent research applications such as web pages and database hosting. In contrast with our High Performanc Computing (HPC) environment Cheaha, where all jobs must have a time limit, instances on cloud.rc are allowed to exist indefinitely. Resource quotas are set to ensure that every user has a fair share. Currently, access to cloud.rc must be made while on campus, or on the campus Virtual Private Network (VPN). For more information about using the VPN, please visit VPN - UAB IT . To get started using cloud.rc, please navigate to https://dashboard.cloud.rc.uab.edu/ . For a first time setup, it is highly recommended to visit the pages below in order. Network setup is a create-once, use-many set of instructions which provides a foundation for instances, volumes, and other features. Instances provide homes for services and are connected to the outside world, and each other, via the network. Volumes provide storage which can be moved among instances or held for future use.","title":"Introduction"},{"location":"uab_cloud/introduction/#uab-cloud","text":"Our OpenStack portal cloud.rc provides a home for more permanent research applications such as web pages and database hosting. In contrast with our High Performanc Computing (HPC) environment Cheaha, where all jobs must have a time limit, instances on cloud.rc are allowed to exist indefinitely. Resource quotas are set to ensure that every user has a fair share. Currently, access to cloud.rc must be made while on campus, or on the campus Virtual Private Network (VPN). For more information about using the VPN, please visit VPN - UAB IT . To get started using cloud.rc, please navigate to https://dashboard.cloud.rc.uab.edu/ . For a first time setup, it is highly recommended to visit the pages below in order. Network setup is a create-once, use-many set of instructions which provides a foundation for instances, volumes, and other features. Instances provide homes for services and are connected to the outside world, and each other, via the network. Volumes provide storage which can be moved among instances or held for future use.","title":"UAB Cloud"},{"location":"uab_cloud/network_setup_basic/","text":"Basic Network Setup \u00b6 Networking setup should be a one-time setup. Security Groups can and should be added as needed. While Floating IPs fall under the Networking fold-out, they should be allocated and released together with instances to maximize security. Creating a Network \u00b6 Click \"Network\" in the left-hand navigation pane to open the fold-out menu. Click \"Networks\" in the fold-out menu. The \"Networks\" page will open. The \"uab_campus\" network entry should already be in the table. Click \"+ Create Network\" to open a dialog box. Fill out the dialog box. Only the \"Network\" tab is important, we will create a subnet as a separate step. Enter a \"Network Name\". Leave \"Enable Admin State\" checked. Uncheck \"Create Subnet\". We will do this as a separate step. The other tabs should be removed. Leave the \"Availability Zone Hints\" box empty. Click \"Create\". Redirects to the \"Networks\" page. There should be a new entry in the table with the name given in (4.a) Creating a Subnet \u00b6 Click \"Network\" in the left-hand navigation pane to open the fold-out menu. Click \"Networks\" in the fold-out menu. The \"Networks\" page will open. The \"uab_campus\" network should already be an entry in the table. At least one other entry must be in the table. See Creating a Network . Under the \"Actions\" column, select the drop-down triangle button in the row corresponding to the network you want to add a subnet to. Click \"Create Subnet\" in the drop-down to open a dialog box. Fill out the dialog box. The \"Subnet\" tab. Enter a \"Subnet Name\". Enter 192.168.0.0/24 as the \"Network Address\". The trailing /24 allocates the entire range from 192.168.0.0 through 192.168.0.255 to the subnet. Ensure \"IPv4\" is selected in the \"IP Version\" drop-down box. Leave \"Gateway IP\" empty to use the default value of 192.168.0.0 . Leave \"Disable Gateway\" unchecked. Click the \"Next >>\" button to move to the \"Subnet Details\" tab. Note If you receive an error like ``` Failed to create subnet `192.168.0.0/24`... Invalid input for operation: Gateway is not valid on a subnet. ``` Try changing the gateway IP address to `192.168.0.1` and trying again. The \"Subnet Details\" tab. Leave \"Enable DHCP\" checked. Enter 192.168.0.20,192.168.0.100 in the \"Allocation Pools\" box. The IP addresses in that range will be assigned to instances on this subnet. Leave \"DNS Name Servers\" empty. Leave \"Host Routes\" empty. Click \"Create\". Redirects to the \"Overview\" page for the network the subnet was added to. Click the \"Subnets\" tab next to \"Overview\" to verify the subnet was added to the table for this network. Creating a Router \u00b6 To follow these directions for creating a router, a Network and Subnet must already exist. Click \"Network\" in the left-hand navigation pane to open the fold-out menu. Click \"Routers\" in the fold-out menu. Click \"+ Create Router\" to open a dialog box. Fill out the dialog box. Enter a \"Router Name\". Leave \"Enable Admin State\" checked. Select \"uab-campus\" in the \"External Network\" drop down box. Leave the \"Availability Zone Hints\" box empty. Click \"Create Router\". Redirects to the \"Routers\" page. There should be a new entry in the table with the name given in (4.a) Now we need to connect the router to our subnet. Click the name of the new entry under the \"Name\" column to open the router \"Overview\" page. Click the \"Interfaces\" tab. Click \"+ Add Interface\" to open a dialog box. Fill out the dialog box. Select an existing network-subnet pair in the \"Subnet\" drop down box. If this is your only router on the selected subnet, leave \"IP Address\" empty to use the subnet gateway. Click \"Submit\" Redirects to the \"Interfaces\" page for the router. There should be a new entry in the table. Creating a Security Group \u00b6 These instructions show you how to prepare to use SSH with your instances. Security Groups are used to set rules for how external devices can connect to our instances. Here we will create an SSH Security Group using a method that can be applied to other types of connections. The method used can be applied to other types of Security Groups as well. Click \"Networks\" in the left-hand navigation pane to open the fold-out menu. Click \"Security Groups\" in the fold out menu. Click \"+ Create Security Group\" to open a dialog box. Fill out the dialog box. Under \"Name\" enter ssh . Leave \"Description\" empty. Click \"Create Security Group\". Redirects to the \"Manage Security Group Rules: ssh\" page. There should be an entry for \"Egress IPv4\" and \"Egress IPv6\". Leave these alone. Click \"+ Add Rule\" to open a dialog box. Select \"SSH\" in the \"Rule\" drop down box. This will change the remaining fields. Leave \"Description\" empty. Select \"CIDR\" in the \"Remote\" drop down box. Type 0.0.0.0/0 in the \"CIDR\" box. WARNING! This is NOT good practice! For your research instances, you'll want to constrain the CIDR value further to a narrower range of IP addresses. The rule we have shown here leaves the SSH port open to all IP addresses world-wide. Click \"Add\". Redirects to the \"Manage Security Group Rules: ssh\" page. There should be a new entry in the table.","title":"Basic Network Setup"},{"location":"uab_cloud/network_setup_basic/#basic-network-setup","text":"Networking setup should be a one-time setup. Security Groups can and should be added as needed. While Floating IPs fall under the Networking fold-out, they should be allocated and released together with instances to maximize security.","title":"Basic Network Setup"},{"location":"uab_cloud/network_setup_basic/#creating-a-network","text":"Click \"Network\" in the left-hand navigation pane to open the fold-out menu. Click \"Networks\" in the fold-out menu. The \"Networks\" page will open. The \"uab_campus\" network entry should already be in the table. Click \"+ Create Network\" to open a dialog box. Fill out the dialog box. Only the \"Network\" tab is important, we will create a subnet as a separate step. Enter a \"Network Name\". Leave \"Enable Admin State\" checked. Uncheck \"Create Subnet\". We will do this as a separate step. The other tabs should be removed. Leave the \"Availability Zone Hints\" box empty. Click \"Create\". Redirects to the \"Networks\" page. There should be a new entry in the table with the name given in (4.a)","title":"Creating a Network"},{"location":"uab_cloud/network_setup_basic/#creating-a-subnet","text":"Click \"Network\" in the left-hand navigation pane to open the fold-out menu. Click \"Networks\" in the fold-out menu. The \"Networks\" page will open. The \"uab_campus\" network should already be an entry in the table. At least one other entry must be in the table. See Creating a Network . Under the \"Actions\" column, select the drop-down triangle button in the row corresponding to the network you want to add a subnet to. Click \"Create Subnet\" in the drop-down to open a dialog box. Fill out the dialog box. The \"Subnet\" tab. Enter a \"Subnet Name\". Enter 192.168.0.0/24 as the \"Network Address\". The trailing /24 allocates the entire range from 192.168.0.0 through 192.168.0.255 to the subnet. Ensure \"IPv4\" is selected in the \"IP Version\" drop-down box. Leave \"Gateway IP\" empty to use the default value of 192.168.0.0 . Leave \"Disable Gateway\" unchecked. Click the \"Next >>\" button to move to the \"Subnet Details\" tab. Note If you receive an error like ``` Failed to create subnet `192.168.0.0/24`... Invalid input for operation: Gateway is not valid on a subnet. ``` Try changing the gateway IP address to `192.168.0.1` and trying again. The \"Subnet Details\" tab. Leave \"Enable DHCP\" checked. Enter 192.168.0.20,192.168.0.100 in the \"Allocation Pools\" box. The IP addresses in that range will be assigned to instances on this subnet. Leave \"DNS Name Servers\" empty. Leave \"Host Routes\" empty. Click \"Create\". Redirects to the \"Overview\" page for the network the subnet was added to. Click the \"Subnets\" tab next to \"Overview\" to verify the subnet was added to the table for this network.","title":"Creating a Subnet"},{"location":"uab_cloud/network_setup_basic/#creating-a-router","text":"To follow these directions for creating a router, a Network and Subnet must already exist. Click \"Network\" in the left-hand navigation pane to open the fold-out menu. Click \"Routers\" in the fold-out menu. Click \"+ Create Router\" to open a dialog box. Fill out the dialog box. Enter a \"Router Name\". Leave \"Enable Admin State\" checked. Select \"uab-campus\" in the \"External Network\" drop down box. Leave the \"Availability Zone Hints\" box empty. Click \"Create Router\". Redirects to the \"Routers\" page. There should be a new entry in the table with the name given in (4.a) Now we need to connect the router to our subnet. Click the name of the new entry under the \"Name\" column to open the router \"Overview\" page. Click the \"Interfaces\" tab. Click \"+ Add Interface\" to open a dialog box. Fill out the dialog box. Select an existing network-subnet pair in the \"Subnet\" drop down box. If this is your only router on the selected subnet, leave \"IP Address\" empty to use the subnet gateway. Click \"Submit\" Redirects to the \"Interfaces\" page for the router. There should be a new entry in the table.","title":"Creating a Router"},{"location":"uab_cloud/network_setup_basic/#creating-a-security-group","text":"These instructions show you how to prepare to use SSH with your instances. Security Groups are used to set rules for how external devices can connect to our instances. Here we will create an SSH Security Group using a method that can be applied to other types of connections. The method used can be applied to other types of Security Groups as well. Click \"Networks\" in the left-hand navigation pane to open the fold-out menu. Click \"Security Groups\" in the fold out menu. Click \"+ Create Security Group\" to open a dialog box. Fill out the dialog box. Under \"Name\" enter ssh . Leave \"Description\" empty. Click \"Create Security Group\". Redirects to the \"Manage Security Group Rules: ssh\" page. There should be an entry for \"Egress IPv4\" and \"Egress IPv6\". Leave these alone. Click \"+ Add Rule\" to open a dialog box. Select \"SSH\" in the \"Rule\" drop down box. This will change the remaining fields. Leave \"Description\" empty. Select \"CIDR\" in the \"Remote\" drop down box. Type 0.0.0.0/0 in the \"CIDR\" box. WARNING! This is NOT good practice! For your research instances, you'll want to constrain the CIDR value further to a narrower range of IP addresses. The rule we have shown here leaves the SSH port open to all IP addresses world-wide. Click \"Add\". Redirects to the \"Manage Security Group Rules: ssh\" page. There should be a new entry in the table.","title":"Creating a Security Group"},{"location":"uab_cloud/volume_setup_basic/","text":"Basic Volume Setup \u00b6 These instructions are intended for users who want to setup a persistent volume for use across instances. To follow these instructions you'll need to have already setup an Instance . Creating a Volume \u00b6 Click the \"Volumes\" fold-out in the left-hand navigation pane - the fold-out should open. Click \"Volumes\" within the fold-out to open the \"Volumes\" table page. Click \"+ Create Volume\" to open a dialog box. Fill out the dialog box. Enter a \"Volume Name\". Enter a \"Description\". Select \"No source, empty volume\" in the \"Volume Source\" drop-down box to create an empty volume. Select \"__DEFAULT__\" in the \"Type\" drop down box. Select a size in GB appropriate for your needs. Select \"nova\" in the \"Availability Zone\" drop down box. Select \"No group\" in the \"Group\" drop down box. Click \"Create Volume\" Returns to the \"Volumes\" table page. There will be a new entry in the \"Volumes\" table. Attaching a Volume to a Running Instance \u00b6 To attach a volume you must have already created at least one using the OpenStack interface. More information can be found in [link] Open the instances table by clicking \"Compute\" in the left-hand navigation pane and clicking \"Instances\". In the \"Actions\" column entry, click the drop down triangle button and select \"Attach Volume\". A dialog box will open. Select a volume in the \"Volume ID\" drop down box. Click \"Attach Volume\". Now the volume should be attached to the instance. From here you may format the volume and mount it. Formatting a Volume \u00b6 To format a volume, you must have created a volume and attached it to an instance capable of formatting it correctly. These instructions assume a Linux operating system. Click \"Compute\" in the left-hand navigation pane, then open the \"Instances\" menu. Click the name of any instance you wish to use to format the volume. Then click \"Overview\". Scroll down to \"Volumes Attached\" and make note of the <mount> part of <volume-name> on <mount> for your attached volume as it will be used in later steps. SSH into the instance from your local machine or from Cheaha. Verify the volume is attached by using sudo fdisk -l | egrep \"<mount>\"\" Format the volume using sudo fdisk \"<mount>\" You will be in the fdisk utility. Enter n to create a new partition. Enter p to make it the primary partition. Enter numeral 1 to make it the first partition. Press enter to accept the default first sector. Press enter to accept the default last sector. Enter t to change partition type. Enter numerals 83 to change to Linux partition type. Enter p to display the partition setup. Note that the partition will be labeled <mount>1 . This literally whatever <mount> was from earlier followed by the numeral 1 . Further steps will refer to this as <pmount> Enter w to execute the setup prepared in the previous substeps. Verify the volume is not mounted using sudo mount | egrep \"<mount>\" . If there is no output, then move to the next step. If there is some output then use sudo umount -l \"<mount>\" to unmount the volume and verify again. Create the filesystem using sudo mkfs.ext4 \"<pmount>\" . Ensure that the output looks like the following: ubuntu@my-instance:~$ sudo mkfs.ext4 /dev/vdb1 mke2fs 1 .45.5 ( 07 -Jan-2020 ) Discarding device blocks: done Creating filesystem with 26214144 4k blocks and 6553600 inodes Filesystem UUID: 335704a9-2435-440a-aeea-8ae29438ac64 Superblock backups stored on blocks: 32768 , 98304 , 163840 , 229376 , 294912 , 819200 , 884736 , 1605632 , 654208 , 4096000 , 7962624 , 11239424 , 20480000 , 23887872 Allocating group tables: done Writing inode tables: done Creating journal ( 131072 blocks ) : done Writing superblocks and filesystem accounting information: done The volume is now formatted and ready for mounting within an attached instance OS. You will need to make note of <pmount> for when you are ready to mount the volume to an instance. Mounting a Volume in an Instance \u00b6 Mounting a volume needs to be done once per instance it will be attached to. It is assumed you've already created and formatted a volume and attached it to some instance. You'll need the <pmount> label from when you formatted the volume. SSH into the instance from your local machine or from Cheaha. Obtain the uuid of the volume using sudo blkid | egrep \"<pmount>\" . This will be referred to as <uuid> in future steps. Create a directory to mount the volume as. A good choice is sudo mkdir /mnt/<volume-name> where <volume-name> is something meaningful for you or your project. This directory will be referred to as <directory> in future steps. Mount the volume to the directory using sudo mount -U <uuid> <directory> . Verify the volume is mounted using df -h | egrep <pmount> Edit the fstab file to make mounting persistent across instance reboots. Edit the file using sudo nano /etc/fstab . Add the following line to the file: /dev/disk/by-uuid/<uuid> <directory> auto defaults,nofail 0 3 Verify fstab was modified correctly by soft rebooting the instance and verifying the mount again using df -h | egrep \"<pmount>\" . Set access control using the following commands: sudo apt install acl # or yum install, etc., if not already installed sudo setfacl -R -m u:<username>:rwx <directory> Verify the access controls were modified correctly by creating a test file and then listing files in <directory> to ensure the file was created. The following commands will achieve this: cd <directory> touch testfile ls The volume is now mounted to your instance and ready for use and re-use across sessions and reboots.","title":"Basic Volume Setup"},{"location":"uab_cloud/volume_setup_basic/#basic-volume-setup","text":"These instructions are intended for users who want to setup a persistent volume for use across instances. To follow these instructions you'll need to have already setup an Instance .","title":"Basic Volume Setup"},{"location":"uab_cloud/volume_setup_basic/#creating-a-volume","text":"Click the \"Volumes\" fold-out in the left-hand navigation pane - the fold-out should open. Click \"Volumes\" within the fold-out to open the \"Volumes\" table page. Click \"+ Create Volume\" to open a dialog box. Fill out the dialog box. Enter a \"Volume Name\". Enter a \"Description\". Select \"No source, empty volume\" in the \"Volume Source\" drop-down box to create an empty volume. Select \"__DEFAULT__\" in the \"Type\" drop down box. Select a size in GB appropriate for your needs. Select \"nova\" in the \"Availability Zone\" drop down box. Select \"No group\" in the \"Group\" drop down box. Click \"Create Volume\" Returns to the \"Volumes\" table page. There will be a new entry in the \"Volumes\" table.","title":"Creating a Volume"},{"location":"uab_cloud/volume_setup_basic/#attaching-a-volume-to-a-running-instance","text":"To attach a volume you must have already created at least one using the OpenStack interface. More information can be found in [link] Open the instances table by clicking \"Compute\" in the left-hand navigation pane and clicking \"Instances\". In the \"Actions\" column entry, click the drop down triangle button and select \"Attach Volume\". A dialog box will open. Select a volume in the \"Volume ID\" drop down box. Click \"Attach Volume\". Now the volume should be attached to the instance. From here you may format the volume and mount it.","title":"Attaching a Volume to a Running Instance"},{"location":"uab_cloud/volume_setup_basic/#formatting-a-volume","text":"To format a volume, you must have created a volume and attached it to an instance capable of formatting it correctly. These instructions assume a Linux operating system. Click \"Compute\" in the left-hand navigation pane, then open the \"Instances\" menu. Click the name of any instance you wish to use to format the volume. Then click \"Overview\". Scroll down to \"Volumes Attached\" and make note of the <mount> part of <volume-name> on <mount> for your attached volume as it will be used in later steps. SSH into the instance from your local machine or from Cheaha. Verify the volume is attached by using sudo fdisk -l | egrep \"<mount>\"\" Format the volume using sudo fdisk \"<mount>\" You will be in the fdisk utility. Enter n to create a new partition. Enter p to make it the primary partition. Enter numeral 1 to make it the first partition. Press enter to accept the default first sector. Press enter to accept the default last sector. Enter t to change partition type. Enter numerals 83 to change to Linux partition type. Enter p to display the partition setup. Note that the partition will be labeled <mount>1 . This literally whatever <mount> was from earlier followed by the numeral 1 . Further steps will refer to this as <pmount> Enter w to execute the setup prepared in the previous substeps. Verify the volume is not mounted using sudo mount | egrep \"<mount>\" . If there is no output, then move to the next step. If there is some output then use sudo umount -l \"<mount>\" to unmount the volume and verify again. Create the filesystem using sudo mkfs.ext4 \"<pmount>\" . Ensure that the output looks like the following: ubuntu@my-instance:~$ sudo mkfs.ext4 /dev/vdb1 mke2fs 1 .45.5 ( 07 -Jan-2020 ) Discarding device blocks: done Creating filesystem with 26214144 4k blocks and 6553600 inodes Filesystem UUID: 335704a9-2435-440a-aeea-8ae29438ac64 Superblock backups stored on blocks: 32768 , 98304 , 163840 , 229376 , 294912 , 819200 , 884736 , 1605632 , 654208 , 4096000 , 7962624 , 11239424 , 20480000 , 23887872 Allocating group tables: done Writing inode tables: done Creating journal ( 131072 blocks ) : done Writing superblocks and filesystem accounting information: done The volume is now formatted and ready for mounting within an attached instance OS. You will need to make note of <pmount> for when you are ready to mount the volume to an instance.","title":"Formatting a Volume"},{"location":"uab_cloud/volume_setup_basic/#mounting-a-volume-in-an-instance","text":"Mounting a volume needs to be done once per instance it will be attached to. It is assumed you've already created and formatted a volume and attached it to some instance. You'll need the <pmount> label from when you formatted the volume. SSH into the instance from your local machine or from Cheaha. Obtain the uuid of the volume using sudo blkid | egrep \"<pmount>\" . This will be referred to as <uuid> in future steps. Create a directory to mount the volume as. A good choice is sudo mkdir /mnt/<volume-name> where <volume-name> is something meaningful for you or your project. This directory will be referred to as <directory> in future steps. Mount the volume to the directory using sudo mount -U <uuid> <directory> . Verify the volume is mounted using df -h | egrep <pmount> Edit the fstab file to make mounting persistent across instance reboots. Edit the file using sudo nano /etc/fstab . Add the following line to the file: /dev/disk/by-uuid/<uuid> <directory> auto defaults,nofail 0 3 Verify fstab was modified correctly by soft rebooting the instance and verifying the mount again using df -h | egrep \"<pmount>\" . Set access control using the following commands: sudo apt install acl # or yum install, etc., if not already installed sudo setfacl -R -m u:<username>:rwx <directory> Verify the access controls were modified correctly by creating a test file and then listing files in <directory> to ensure the file was created. The following commands will achieve this: cd <directory> touch testfile ls The volume is now mounted to your instance and ready for use and re-use across sessions and reboots.","title":"Mounting a Volume in an Instance"},{"location":"welcome/rc_days/","text":"UAB Research Computing Day \u00b6 Research Computing Day is a dialog within the UAB research communityabout leveraging the power of computers to grow the depth of our investigation into the nature of the world that surrounds us. The annual event welcomes discussions on science, engineering, the arts and humanities focused on the drive to open new research frontiers with advances in technology. Whether computers are used to increase the accuracy of a model, interpret the ever-growing stream of data from new image collections and instruments, or engage with peers around the globe, UAB's status as a leading research community depends on the ability to incorporate these capabilities into the research process. By participating in the dialog of Research Computing Day at UAB, researchers can share how they are using these methods to enhance their research, gain new insights from peers, and contribute their voices to the growth of research at UAB. Background \u00b6 Since 2007, The Office of the Vice President for Information Technology has sponsored an annual dialog on the role of technology in research. These events joined UAB with national dialogs on the role of Cyberinfrastructure in research held at campuses across the country. Previous UAB Research Computing Days \u00b6 2007 -- Co-hosted along with the ASA site visit, providing an overview of new services and upcoming launch of the UABgrid pilot. (No web record) 2008 -- Focus on grid computing and collaboration technologies, in particular the caBIG program with guest speakers from Booz Allen Hamilton who managed the NCI caBIG program and SURA (agenda currently offline) 2010 -- Featured introduction to Galaxy platform for genetic sequencing by Dell staff scientist (agenda currently offline) 2011 -- Understanding growth of research computing support at peer institutions UNC and Emory 2012 -- Growing data sciences at UAB 2013 -- OpenStack at UAB 2016 -- HPC Expansion 2017 -- GPU expansion Research Computing Day 2018","title":"UAB Research Computing Day"},{"location":"welcome/rc_days/#uab-research-computing-day","text":"Research Computing Day is a dialog within the UAB research communityabout leveraging the power of computers to grow the depth of our investigation into the nature of the world that surrounds us. The annual event welcomes discussions on science, engineering, the arts and humanities focused on the drive to open new research frontiers with advances in technology. Whether computers are used to increase the accuracy of a model, interpret the ever-growing stream of data from new image collections and instruments, or engage with peers around the globe, UAB's status as a leading research community depends on the ability to incorporate these capabilities into the research process. By participating in the dialog of Research Computing Day at UAB, researchers can share how they are using these methods to enhance their research, gain new insights from peers, and contribute their voices to the growth of research at UAB.","title":"UAB Research Computing Day"},{"location":"welcome/rc_days/#background","text":"Since 2007, The Office of the Vice President for Information Technology has sponsored an annual dialog on the role of technology in research. These events joined UAB with national dialogs on the role of Cyberinfrastructure in research held at campuses across the country.","title":"Background"},{"location":"welcome/rc_days/#previous-uab-research-computing-days","text":"2007 -- Co-hosted along with the ASA site visit, providing an overview of new services and upcoming launch of the UABgrid pilot. (No web record) 2008 -- Focus on grid computing and collaboration technologies, in particular the caBIG program with guest speakers from Booz Allen Hamilton who managed the NCI caBIG program and SURA (agenda currently offline) 2010 -- Featured introduction to Galaxy platform for genetic sequencing by Dell staff scientist (agenda currently offline) 2011 -- Understanding growth of research computing support at peer institutions UNC and Emory 2012 -- Growing data sciences at UAB 2013 -- OpenStack at UAB 2016 -- HPC Expansion 2017 -- GPU expansion Research Computing Day 2018","title":"Previous UAB Research Computing Days"},{"location":"welcome/welcome/","text":"Welcome \u00b6 Welcome to the Research Computing System The Research Computing System (RCS) provides a framework for sharing data, accessing compute power, and collaborating with peers on campus and around the globe. Our goal is to construct a dynamic \"network of services\" that you can use to organize your data, study it, and share outcomes. The Research Computing System is designed to provide services to researchers in three core areas: Data Analysis : using the High Performance Computing (HPC) fabric we call Cheaha for analyzing data and running simulations. Many applications are already available or you can install your own Data Sharing : supporting the trusted exchange of information using virtual data containers to spark new ideas Application Development: providing virtual machines and web-hosted development tools empowering you to serve others with your research Support and Development \u00b6 The Research Computing System is developed and supported by UAB IT's Research Computing Group. We are also developing a core set of applications to help you to easily incorporate our services into your research processes and this documentation collection to help you leverage the resources already available. We follow the best practices of the Open Source community and develop the RCS openly. The Research Computing System is an out growth of the UABgrid pilot, launched in September 2007 which has focused on demonstrating the utility of unlimited analysis, storage, and application for research. RCS is being built on the same technology foundations used by major cloud vendors and decades of distributed systems computing research, technology that powered the last ten years of large scale systems serving prominent national and international initiatives like the Open Science Grid , XSEDE , the LHC Computing Grid , and NCIP . Outreach \u00b6 The UAB IT Research Computing Group has collaborated with a number of prominent research projects at UAB to identify use cases and develop the requirements for the RCS. Our collaborators include the Center for Clinical and Translational Science (CCTS), Heflin Genomics Center, the Comprehensive Cancer Center (CCC), the Department of Computer and Information Sciences (CIS), the Department of Mechanical Engineering (ME), Lister Hill Library, the School of Optometry's Center for the Development of Functional Imaging, and Health System Information Services (HSIS). As part of the process of building this research computing platform, the UAB IT Research Computing Group has hosted an annual campus symposium on research computing and cyber-infrastructure (CI) developments and accomplishments. Starting as CyberInfrastructure (CI) Days in 2007, the name was changed to UAB Research Computing Day in 2011 to reflect the broader mission to support research. IT Research Computing also participates in other campus wide symposiums including UAB Research Core Day. Data Backups \u00b6 Users of Cheaha are solely responsible for backing up their files. This includes files under /data/user , /data/project , and /home . There is no automatic back up of any user data on the cluster in home, data, or scratch. For more information, please see backups . Personnel \u00b6 UAB IT Research Computing currently maintains a support staff of 13 FTE staff and 6 interns lead by Ralph Zottola,the Assistant Vice President for Research Computing, and managed by John-Paul Robinson, HPC Architect Manager, and Blake Joyce, Data Science Manager. Laura Dabbs is the program coordinator. Research Computing is made up of three teams: The Development Team with 4 FTE software developers The Operations Team with 3 FTE system analysts The Data Science Team with 3 FTE scientists and 6 intern positions.","title":"Welcome"},{"location":"welcome/welcome/#welcome","text":"Welcome to the Research Computing System The Research Computing System (RCS) provides a framework for sharing data, accessing compute power, and collaborating with peers on campus and around the globe. Our goal is to construct a dynamic \"network of services\" that you can use to organize your data, study it, and share outcomes. The Research Computing System is designed to provide services to researchers in three core areas: Data Analysis : using the High Performance Computing (HPC) fabric we call Cheaha for analyzing data and running simulations. Many applications are already available or you can install your own Data Sharing : supporting the trusted exchange of information using virtual data containers to spark new ideas Application Development: providing virtual machines and web-hosted development tools empowering you to serve others with your research","title":"Welcome"},{"location":"welcome/welcome/#support-and-development","text":"The Research Computing System is developed and supported by UAB IT's Research Computing Group. We are also developing a core set of applications to help you to easily incorporate our services into your research processes and this documentation collection to help you leverage the resources already available. We follow the best practices of the Open Source community and develop the RCS openly. The Research Computing System is an out growth of the UABgrid pilot, launched in September 2007 which has focused on demonstrating the utility of unlimited analysis, storage, and application for research. RCS is being built on the same technology foundations used by major cloud vendors and decades of distributed systems computing research, technology that powered the last ten years of large scale systems serving prominent national and international initiatives like the Open Science Grid , XSEDE , the LHC Computing Grid , and NCIP .","title":"Support and Development"},{"location":"welcome/welcome/#outreach","text":"The UAB IT Research Computing Group has collaborated with a number of prominent research projects at UAB to identify use cases and develop the requirements for the RCS. Our collaborators include the Center for Clinical and Translational Science (CCTS), Heflin Genomics Center, the Comprehensive Cancer Center (CCC), the Department of Computer and Information Sciences (CIS), the Department of Mechanical Engineering (ME), Lister Hill Library, the School of Optometry's Center for the Development of Functional Imaging, and Health System Information Services (HSIS). As part of the process of building this research computing platform, the UAB IT Research Computing Group has hosted an annual campus symposium on research computing and cyber-infrastructure (CI) developments and accomplishments. Starting as CyberInfrastructure (CI) Days in 2007, the name was changed to UAB Research Computing Day in 2011 to reflect the broader mission to support research. IT Research Computing also participates in other campus wide symposiums including UAB Research Core Day.","title":"Outreach"},{"location":"welcome/welcome/#data-backups","text":"Users of Cheaha are solely responsible for backing up their files. This includes files under /data/user , /data/project , and /home . There is no automatic back up of any user data on the cluster in home, data, or scratch. For more information, please see backups .","title":"Data Backups"},{"location":"welcome/welcome/#personnel","text":"UAB IT Research Computing currently maintains a support staff of 13 FTE staff and 6 interns lead by Ralph Zottola,the Assistant Vice President for Research Computing, and managed by John-Paul Robinson, HPC Architect Manager, and Blake Joyce, Data Science Manager. Laura Dabbs is the program coordinator. Research Computing is made up of three teams: The Development Team with 4 FTE software developers The Operations Team with 3 FTE system analysts The Data Science Team with 3 FTE scientists and 6 intern positions.","title":"Personnel"}]}